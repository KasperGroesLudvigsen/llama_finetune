{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'swerec',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.7632411631619961,\n",
       "      'macro_f1': 0.713263857944391},\n",
       "     {'mcc': 0.7546156425407411, 'macro_f1': 0.6998441891698756},\n",
       "     {'mcc': 0.7753821652443857, 'macro_f1': 0.6897325170899221},\n",
       "     {'mcc': 0.8100709411625724, 'macro_f1': 0.7814970546519401},\n",
       "     {'mcc': 0.7306769410774258, 'macro_f1': 0.6160563286221415},\n",
       "     {'mcc': 0.7567565310991968, 'macro_f1': 0.7064619944288874},\n",
       "     {'mcc': 0.7764128852546965, 'macro_f1': 0.7300789777321789},\n",
       "     {'mcc': 0.7759392333123692, 'macro_f1': 0.7514587564194685},\n",
       "     {'mcc': 0.7675303731147312, 'macro_f1': 0.6657242799149489},\n",
       "     {'mcc': 0.7868790013144131, 'macro_f1': 0.7842388068461238}]},\n",
       "   'total': {'test_mcc': 76.97504877282529,\n",
       "    'test_mcc_se': 1.3075610283923544,\n",
       "    'test_macro_f1': 71.38356762819878,\n",
       "    'test_macro_f1_se': 3.1953900405412945}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.399072095776686,\n",
       "      'macro_f1': 0.4956553080344501},\n",
       "     {'mcc': 0.4152435268624868, 'macro_f1': 0.5279818535078712},\n",
       "     {'mcc': 0.4725509003311654, 'macro_f1': 0.6134480203206284},\n",
       "     {'mcc': 0.4450589416808148, 'macro_f1': 0.586510862433019},\n",
       "     {'mcc': 0.4817215855063483, 'macro_f1': 0.6211363548687684},\n",
       "     {'mcc': 0.44321075474024424, 'macro_f1': 0.5515259492902045},\n",
       "     {'mcc': 0.444891680376046, 'macro_f1': 0.5740848637429616},\n",
       "     {'mcc': 0.4292713028314237, 'macro_f1': 0.5250211388231241},\n",
       "     {'mcc': 0.3221088910654179, 'macro_f1': 0.3917474516983129},\n",
       "     {'mcc': 0.42367754777904576, 'macro_f1': 0.5826489283257223}]},\n",
       "   'total': {'test_mcc': 42.768072269496784,\n",
       "    'test_mcc_se': 2.7649398203380207,\n",
       "    'test_macro_f1': 54.697607310450614,\n",
       "    'test_macro_f1_se': 4.187553369717499}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'norec',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['nb', 'nn', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.42687354483398093,\n",
       "      'macro_f1': 0.615133954516642},\n",
       "     {'mcc': 0.45786901368589694, 'macro_f1': 0.6151626832347602},\n",
       "     {'mcc': 0.42933201238141316, 'macro_f1': 0.5741198849104404},\n",
       "     {'mcc': 0.4987482981175477, 'macro_f1': 0.6607873685687576},\n",
       "     {'mcc': 0.4122372239754492, 'macro_f1': 0.5835747407709193},\n",
       "     {'mcc': 0.38960596999656755, 'macro_f1': 0.5471449074961574},\n",
       "     {'mcc': 0.5018619386100225, 'macro_f1': 0.6567634298473779},\n",
       "     {'mcc': 0.44766576288656307, 'macro_f1': 0.5904603754313674},\n",
       "     {'mcc': 0.36666100860478645, 'macro_f1': 0.5099896068699068},\n",
       "     {'mcc': 0.48182858418983704, 'macro_f1': 0.6563055368801076}]},\n",
       "   'total': {'test_mcc': 44.12683357282064,\n",
       "    'test_mcc_se': 2.799814907186832,\n",
       "    'test_macro_f1': 60.094424885264374,\n",
       "    'test_macro_f1_se': 3.0965269195651484}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'sb10k',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5263632377901644,\n",
       "      'macro_f1': 0.6535179156621208},\n",
       "     {'mcc': 0.5336010077951835, 'macro_f1': 0.6512171830560601},\n",
       "     {'mcc': 0.4641555862200793, 'macro_f1': 0.5422863101976921},\n",
       "     {'mcc': 0.4510916017376896, 'macro_f1': 0.6076436945931389},\n",
       "     {'mcc': 0.5381482395157077, 'macro_f1': 0.6562727058313906},\n",
       "     {'mcc': 0.4924504450293825, 'macro_f1': 0.5828058407629721},\n",
       "     {'mcc': 0.5248759145946802, 'macro_f1': 0.6528519810447487},\n",
       "     {'mcc': 0.5620983708430101, 'macro_f1': 0.654199399810668},\n",
       "     {'mcc': 0.46877605450741294, 'macro_f1': 0.5798069544487294},\n",
       "     {'mcc': 0.4906949153296875, 'macro_f1': 0.6580787009171929}]},\n",
       "   'total': {'test_mcc': 50.52255373362997,\n",
       "    'test_mcc_se': 2.2891536897336633,\n",
       "    'test_macro_f1': 62.386806863247145,\n",
       "    'test_macro_f1_se': 2.6258696538849184}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'dutch-social',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.12842761521159515,\n",
       "      'macro_f1': 0.385894483867601},\n",
       "     {'mcc': 0.09785289685345999, 'macro_f1': 0.3545215763378195},\n",
       "     {'mcc': 0.11953709613642809, 'macro_f1': 0.3879978404992488},\n",
       "     {'mcc': 0.16309648336494623, 'macro_f1': 0.4073904248447237},\n",
       "     {'mcc': 0.13400453346634456, 'macro_f1': 0.33943857971169633},\n",
       "     {'mcc': 0.1426755105877787, 'macro_f1': 0.3628458993313086},\n",
       "     {'mcc': 0.15858394054912964, 'macro_f1': 0.38149600628781694},\n",
       "     {'mcc': 0.12324241903962806, 'macro_f1': 0.32891750838673534},\n",
       "     {'mcc': 0.11210498237503322, 'macro_f1': 0.3823034790443671},\n",
       "     {'mcc': 0.10776931340128468, 'macro_f1': 0.3925777627854465}]},\n",
       "   'total': {'test_mcc': 12.872947909856283,\n",
       "    'test_mcc_se': 1.3194199656381653,\n",
       "    'test_macro_f1': 37.23383561096764,\n",
       "    'test_macro_f1_se': 1.5496186720345828}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'sst5',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.678825382332653,\n",
       "      'macro_f1': 0.7147301822357218},\n",
       "     {'mcc': 0.645994697826103, 'macro_f1': 0.6979712964319087},\n",
       "     {'mcc': 0.6632420143908082, 'macro_f1': 0.7043472442317321},\n",
       "     {'mcc': 0.6463534943546901, 'macro_f1': 0.7167156150605861},\n",
       "     {'mcc': 0.6828324718047131, 'macro_f1': 0.7171584314305689},\n",
       "     {'mcc': 0.6465468092401774, 'macro_f1': 0.6654606486637632},\n",
       "     {'mcc': 0.681253608452132, 'macro_f1': 0.7251872775019484},\n",
       "     {'mcc': 0.6579354351306118, 'macro_f1': 0.7026860531959161},\n",
       "     {'mcc': 0.6837581445130559, 'macro_f1': 0.6991617544948219},\n",
       "     {'mcc': 0.6130261061784783, 'macro_f1': 0.7033024820582853}]},\n",
       "   'total': {'test_mcc': 65.99768164223423,\n",
       "    'test_mcc_se': 1.412856626542079,\n",
       "    'test_macro_f1': 70.46720985305252,\n",
       "    'test_macro_f1_se': 1.0208990538810823}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'suc3',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.38148788927335636,\n",
       "      'micro_f1': 0.30680218921032054},\n",
       "     {'micro_f1_no_misc': 0.44143723751749886,\n",
       "      'micro_f1': 0.30749842470069316},\n",
       "     {'micro_f1_no_misc': 0.4495816820783795, 'micro_f1': 0.3869596031183558},\n",
       "     {'micro_f1_no_misc': 0.42835265806169326,\n",
       "      'micro_f1': 0.32641221374045803},\n",
       "     {'micro_f1_no_misc': 0.4262425447316104, 'micro_f1': 0.33172932330827065},\n",
       "     {'micro_f1_no_misc': 0.4347826086956522, 'micro_f1': 0.3827591945415211},\n",
       "     {'micro_f1_no_misc': 0.5202284626368396, 'micro_f1': 0.3861185983827493},\n",
       "     {'micro_f1_no_misc': 0.37607573149741824,\n",
       "      'micro_f1': 0.27114210985178727},\n",
       "     {'micro_f1_no_misc': 0.4757536041939711, 'micro_f1': 0.3901382642012327},\n",
       "     {'micro_f1_no_misc': 0.4398375721307972,\n",
       "      'micro_f1': 0.34757468679730164}]},\n",
       "   'total': {'test_micro_f1_no_misc': 43.737799908172164,\n",
       "    'test_micro_f1_no_misc_se': 2.5806424133895067,\n",
       "    'test_micro_f1': 34.371346078526905,\n",
       "    'test_micro_f1_se': 2.5925637979218137}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.49785038693035255,\n",
       "      'micro_f1': 0.38921599008366903},\n",
       "     {'micro_f1_no_misc': 0.4097273397199705, 'micro_f1': 0.3515554213228632},\n",
       "     {'micro_f1_no_misc': 0.38207200587803086, 'micro_f1': 0.3264340626848019},\n",
       "     {'micro_f1_no_misc': 0.36854866643574646, 'micro_f1': 0.3087248322147651},\n",
       "     {'micro_f1_no_misc': 0.48003227107704716,\n",
       "      'micro_f1': 0.38395245170876674},\n",
       "     {'micro_f1_no_misc': 0.4091097308488613, 'micro_f1': 0.32336790726052467},\n",
       "     {'micro_f1_no_misc': 0.3548732595501607, 'micro_f1': 0.25571875752468093},\n",
       "     {'micro_f1_no_misc': 0.38550826591628556, 'micro_f1': 0.276997578692494},\n",
       "     {'micro_f1_no_misc': 0.3483825097760398, 'micro_f1': 0.2873722022658193},\n",
       "     {'micro_f1_no_misc': 0.47626774847870174,\n",
       "      'micro_f1': 0.346797461050202}]},\n",
       "   'total': {'test_micro_f1_no_misc': 41.12372184611197,\n",
       "    'test_micro_f1_no_misc_se': 3.390597785070832,\n",
       "    'test_micro_f1': 32.50136664808586,\n",
       "    'test_micro_f1_se': 2.738470519394666}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'norne-nb',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['nb', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.48303186907838075,\n",
       "      'micro_f1': 0.3824583075972823},\n",
       "     {'micro_f1_no_misc': 0.49772074962012497,\n",
       "      'micro_f1': 0.44428871758934835},\n",
       "     {'micro_f1_no_misc': 0.46096291476903056,\n",
       "      'micro_f1': 0.33023412120533213},\n",
       "     {'micro_f1_no_misc': 0.5143249270886945, 'micro_f1': 0.403911244828883},\n",
       "     {'micro_f1_no_misc': 0.47797645006541656, 'micro_f1': 0.424330900243309},\n",
       "     {'micro_f1_no_misc': 0.4776559174987723, 'micro_f1': 0.388515577275504},\n",
       "     {'micro_f1_no_misc': 0.513619954053167, 'micro_f1': 0.45094894413258485},\n",
       "     {'micro_f1_no_misc': 0.5115264797507788, 'micro_f1': 0.3339595074097266},\n",
       "     {'micro_f1_no_misc': 0.47109067017082784, 'micro_f1': 0.3700061462814997},\n",
       "     {'micro_f1_no_misc': 0.5584574934268186,\n",
       "      'micro_f1': 0.4019502913545011}]},\n",
       "   'total': {'test_micro_f1_no_misc': 49.663674255220116,\n",
       "    'test_micro_f1_no_misc_se': 1.7850210381146883,\n",
       "    'test_micro_f1': 39.306037579179716,\n",
       "    'test_micro_f1_se': 2.551737546519978}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'norne-nn',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['nn'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.5036496350364963,\n",
       "      'micro_f1': 0.440620863915293},\n",
       "     {'micro_f1_no_misc': 0.5532886723507917, 'micro_f1': 0.46334241383394525},\n",
       "     {'micro_f1_no_misc': 0.48470588235294115, 'micro_f1': 0.4326934984520123},\n",
       "     {'micro_f1_no_misc': 0.5184388444990782, 'micro_f1': 0.3372004564473184},\n",
       "     {'micro_f1_no_misc': 0.4966078697421981, 'micro_f1': 0.33074792243767315},\n",
       "     {'micro_f1_no_misc': 0.5439474507350641, 'micro_f1': 0.4640365648304065},\n",
       "     {'micro_f1_no_misc': 0.5055605650736399, 'micro_f1': 0.46756550496056987},\n",
       "     {'micro_f1_no_misc': 0.5205351586807716, 'micro_f1': 0.4482003891050583},\n",
       "     {'micro_f1_no_misc': 0.5114803625377644, 'micro_f1': 0.44171031794372034},\n",
       "     {'micro_f1_no_misc': 0.5601640119854914,\n",
       "      'micro_f1': 0.42212976498369503}]},\n",
       "   'total': {'test_micro_f1_no_misc': 51.98378452994237,\n",
       "    'test_micro_f1_no_misc_se': 1.5513753294819665,\n",
       "    'test_micro_f1': 42.482476969096915,\n",
       "    'test_micro_f1_se': 3.1008672620851705}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mim-gold-ner',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['is'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.3122942607700014,\n",
       "      'micro_f1': 0.21774046358824606},\n",
       "     {'micro_f1_no_misc': 0.30607561299673874, 'micro_f1': 0.2695363572362466},\n",
       "     {'micro_f1_no_misc': 0.28886581884246043,\n",
       "      'micro_f1': 0.22982975573649148},\n",
       "     {'micro_f1_no_misc': 0.24806895779693272,\n",
       "      'micro_f1': 0.22442918136253945},\n",
       "     {'micro_f1_no_misc': 0.25406787540678755,\n",
       "      'micro_f1': 0.21166191155492153},\n",
       "     {'micro_f1_no_misc': 0.31602768903088385,\n",
       "      'micro_f1': 0.24470633323752033},\n",
       "     {'micro_f1_no_misc': 0.261994473750314, 'micro_f1': 0.22023476802683067},\n",
       "     {'micro_f1_no_misc': 0.2502768549280177, 'micro_f1': 0.21597633136094677},\n",
       "     {'micro_f1_no_misc': 0.25011579434923575, 'micro_f1': 0.2113567562608935},\n",
       "     {'micro_f1_no_misc': 0.2688122250520954,\n",
       "      'micro_f1': 0.20679320679320679}]},\n",
       "   'total': {'test_micro_f1_no_misc': 27.565995629234674,\n",
       "    'test_micro_f1_no_misc_se': 1.7073210285581408,\n",
       "    'test_micro_f1': 22.52265065157843,\n",
       "    'test_micro_f1_se': 1.177329676367647}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'fone',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['fo'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.5021744106202792,\n",
       "      'micro_f1': 0.37561359917580756},\n",
       "     {'micro_f1_no_misc': 0.5390037221826245, 'micro_f1': 0.43123312923826457},\n",
       "     {'micro_f1_no_misc': 0.5987734300768766, 'micro_f1': 0.40811808118081183},\n",
       "     {'micro_f1_no_misc': 0.5700508051321795, 'micro_f1': 0.4478378565974873},\n",
       "     {'micro_f1_no_misc': 0.6130723523243621, 'micro_f1': 0.46321450734330827},\n",
       "     {'micro_f1_no_misc': 0.5213247930010936, 'micro_f1': 0.4460617603047205},\n",
       "     {'micro_f1_no_misc': 0.6039943177070276, 'micro_f1': 0.5159231048240841},\n",
       "     {'micro_f1_no_misc': 0.6664885088188136, 'micro_f1': 0.6173793992107595},\n",
       "     {'micro_f1_no_misc': 0.6774574270780643, 'micro_f1': 0.5926307273663308},\n",
       "     {'micro_f1_no_misc': 0.5318334505116787,\n",
       "      'micro_f1': 0.44632504831078823}]},\n",
       "   'total': {'test_micro_f1_no_misc': 58.24173217452999,\n",
       "    'test_micro_f1_no_misc_se': 3.7269232239835643,\n",
       "    'test_micro_f1': 47.44337213552362,\n",
       "    'test_micro_f1_se': 4.8268519707174145}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'germeval',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.5501664289110795,\n",
       "      'micro_f1': 0.48989706443004194},\n",
       "     {'micro_f1_no_misc': 0.5845232611699678, 'micro_f1': 0.4673444769946579},\n",
       "     {'micro_f1_no_misc': 0.5644394110985278, 'micro_f1': 0.4492630865661528},\n",
       "     {'micro_f1_no_misc': 0.5519287833827893, 'micro_f1': 0.44889357218124337},\n",
       "     {'micro_f1_no_misc': 0.5817998487522058, 'micro_f1': 0.41869557490669984},\n",
       "     {'micro_f1_no_misc': 0.5404818754069893, 'micro_f1': 0.472654835204636},\n",
       "     {'micro_f1_no_misc': 0.5178219986879511, 'micro_f1': 0.4207044815611047},\n",
       "     {'micro_f1_no_misc': 0.6005323009920155, 'micro_f1': 0.5270606234461657},\n",
       "     {'micro_f1_no_misc': 0.5713032031592805, 'micro_f1': 0.5037974683544304},\n",
       "     {'micro_f1_no_misc': 0.4889490302210194,\n",
       "      'micro_f1': 0.4200426439232409}]},\n",
       "   'total': {'test_micro_f1_no_misc': 55.51946141781826,\n",
       "    'test_micro_f1_no_misc_se': 2.066648301392786,\n",
       "    'test_micro_f1': 46.18353827568373,\n",
       "    'test_micro_f1_se': 2.316801201481415}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'conll-nl',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.44666923373122835,\n",
       "      'micro_f1': 0.41420118343195267},\n",
       "     {'micro_f1_no_misc': 0.43954372623574145, 'micro_f1': 0.4231611893583725},\n",
       "     {'micro_f1_no_misc': 0.4554951943167572, 'micro_f1': 0.4268723882995821},\n",
       "     {'micro_f1_no_misc': 0.39088905216752395, 'micro_f1': 0.3630843958712811},\n",
       "     {'micro_f1_no_misc': 0.4309210526315789, 'micro_f1': 0.37780548628428934},\n",
       "     {'micro_f1_no_misc': 0.4395161290322581, 'micro_f1': 0.4003777148253069},\n",
       "     {'micro_f1_no_misc': 0.42512783053323594,\n",
       "      'micro_f1': 0.37530201342281877},\n",
       "     {'micro_f1_no_misc': 0.3947655398037077, 'micro_f1': 0.39581464872944694},\n",
       "     {'micro_f1_no_misc': 0.5074626865671641, 'micro_f1': 0.45633802816901403},\n",
       "     {'micro_f1_no_misc': 0.4353083434099153,\n",
       "      'micro_f1': 0.3903037741638539}]},\n",
       "   'total': {'test_micro_f1_no_misc': 43.65698788429111,\n",
       "    'test_micro_f1_no_misc_se': 2.0139460451621383,\n",
       "    'test_micro_f1': 40.23260822555918,\n",
       "    'test_micro_f1_se': 1.7478506680213506}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'conll-en',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.6699196326061998,\n",
       "      'micro_f1': 0.5391575200237319},\n",
       "     {'micro_f1_no_misc': 0.685576566555432, 'micro_f1': 0.6366903468449644},\n",
       "     {'micro_f1_no_misc': 0.7229476667678915, 'micro_f1': 0.5877693282636248},\n",
       "     {'micro_f1_no_misc': 0.6558209516644724, 'micro_f1': 0.5470764617691154},\n",
       "     {'micro_f1_no_misc': 0.6938241614500609, 'micro_f1': 0.6105313092979128},\n",
       "     {'micro_f1_no_misc': 0.683188211654387, 'micro_f1': 0.5611392782582761},\n",
       "     {'micro_f1_no_misc': 0.6765871098656874, 'micro_f1': 0.5791026238161775},\n",
       "     {'micro_f1_no_misc': 0.670175120225025, 'micro_f1': 0.5055224579958498},\n",
       "     {'micro_f1_no_misc': 0.69105222734255, 'micro_f1': 0.5561232156273479},\n",
       "     {'micro_f1_no_misc': 0.6949596969991259,\n",
       "      'micro_f1': 0.5572687224669604}]},\n",
       "   'total': {'test_micro_f1_no_misc': 68.44051345130832,\n",
       "    'test_micro_f1_no_misc_se': 1.1359700272037216,\n",
       "    'test_micro_f1': 56.80381264363962,\n",
       "    'test_micro_f1_se': 2.3115234574845704}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-sv',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.1983356821544958,\n",
       "      'macro_f1': 0.5886111986219216},\n",
       "     {'mcc': 0.1660396342464956, 'macro_f1': 0.47781353686946915},\n",
       "     {'mcc': 0.1570022003444398, 'macro_f1': 0.4786738602311827},\n",
       "     {'mcc': 0.14855414929809418, 'macro_f1': 0.5509702687198339},\n",
       "     {'mcc': 0.21304074513090104, 'macro_f1': 0.5567338282078473},\n",
       "     {'mcc': 0.12809183272736183, 'macro_f1': 0.4190994044676694},\n",
       "     {'mcc': 0.12435967308303233, 'macro_f1': 0.451274149257646},\n",
       "     {'mcc': 0.12409156080483984, 'macro_f1': 0.5469485165442902},\n",
       "     {'mcc': 0.21246669200220739, 'macro_f1': 0.558456072567105},\n",
       "     {'mcc': 0.12853088922031627, 'macro_f1': 0.553983418917015}]},\n",
       "   'total': {'test_mcc': 16.00513059012184,\n",
       "    'test_mcc_se': 2.2423927704785074,\n",
       "    'test_macro_f1': 51.825642544039795,\n",
       "    'test_macro_f1_se': 3.5023366934927114}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.12125042746401757,\n",
       "      'macro_f1': 0.47322067821889313},\n",
       "     {'mcc': 0.10052477241292339, 'macro_f1': 0.43733740019736256},\n",
       "     {'mcc': 0.02480578826087154, 'macro_f1': 0.3783652743875743},\n",
       "     {'mcc': 0.1676475925141546, 'macro_f1': 0.5640943587798624},\n",
       "     {'mcc': 0.06504230158521394, 'macro_f1': 0.4566036266129767},\n",
       "     {'mcc': 0.13579783296949066, 'macro_f1': 0.5113258400363045},\n",
       "     {'mcc': 0.14294570424682812, 'macro_f1': 0.5237700988704463},\n",
       "     {'mcc': 0.19180423003059308, 'macro_f1': 0.5956969558251316},\n",
       "     {'mcc': 0.09456945317594954, 'macro_f1': 0.5472845960785249},\n",
       "     {'mcc': 0.10771122500247611, 'macro_f1': 0.4494790491679266}]},\n",
       "   'total': {'test_mcc': 11.520993276625184,\n",
       "    'test_mcc_se': 3.0105576801811313,\n",
       "    'test_macro_f1': 49.37177878175003,\n",
       "    'test_macro_f1_se': 4.115212254632394}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-nb',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['nb', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': -0.0009775171065493646,\n",
       "      'macro_f1': 0.32714662790538496},\n",
       "     {'mcc': -0.02175978876390385, 'macro_f1': 0.33657272432782637},\n",
       "     {'mcc': 0.001161034336867612, 'macro_f1': 0.3423892371260792},\n",
       "     {'mcc': 0.032614924844069575, 'macro_f1': 0.3387957245400119},\n",
       "     {'mcc': 0.026640647490867732, 'macro_f1': 0.3431052058068825},\n",
       "     {'mcc': 0.010225884896290194, 'macro_f1': 0.3391689334959197},\n",
       "     {'mcc': 0.006767406673349301, 'macro_f1': 0.33074455029455724},\n",
       "     {'mcc': 0.029806278561545795, 'macro_f1': 0.3393967968618745},\n",
       "     {'mcc': 0.0027100026044701007, 'macro_f1': 0.34081099375312696},\n",
       "     {'mcc': -0.0202821641791121, 'macro_f1': 0.34247610585803806}]},\n",
       "   'total': {'test_mcc': 0.66906709357895,\n",
       "    'test_mcc_se': 1.179459329546404,\n",
       "    'test_macro_f1': 33.80606899969701,\n",
       "    'test_macro_f1_se': 0.3264404581051393}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-nn',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['nn'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.03668946531255659,\n",
       "      'macro_f1': 0.3267680625969396},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.33571196886149857},\n",
       "     {'mcc': 0.031326394704867255, 'macro_f1': 0.3359375},\n",
       "     {'mcc': 0.021443193919187108, 'macro_f1': 0.327591706539075},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.32653732324893125},\n",
       "     {'mcc': 0.02141867674399123, 'macro_f1': 0.3405513438882324},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.3361426256077796},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.32230311052283256},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.32230311052283256},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.3289646133682831}]},\n",
       "   'total': {'test_mcc': 1.1087773068060218,\n",
       "    'test_mcc_se': 0.9277892406390903,\n",
       "    'test_macro_f1': 33.02811365156405,\n",
       "    'test_macro_f1_se': 0.39414170616753236}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-is',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['is'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.0, 'macro_f1': 0.3278634722678044},\n",
       "     {'mcc': -0.02584423691392005, 'macro_f1': 0.3315356301753012},\n",
       "     {'mcc': 0.015680786060850473, 'macro_f1': 0.43070593208548996},\n",
       "     {'mcc': -0.03542504762563007, 'macro_f1': 0.32857228374366754},\n",
       "     {'mcc': -0.023029235724798227, 'macro_f1': 0.33730228902642695},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.3359273670557717},\n",
       "     {'mcc': -0.054453048348505804, 'macro_f1': 0.3236964584069943},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.33159268929503916},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.33871488537294153},\n",
       "     {'mcc': -0.01551403154663551, 'macro_f1': 0.3542739631620803}]},\n",
       "   'total': {'test_mcc': -1.3858481409863919,\n",
       "    'test_mcc_se': 1.3041056889451377,\n",
       "    'test_macro_f1': 34.40184970591517,\n",
       "    'test_macro_f1_se': 1.9579699522828848}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-fo',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['fo'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.01648270609949152,\n",
       "      'macro_f1': 0.46293706293706294},\n",
       "     {'mcc': 0.044237625380796106, 'macro_f1': 0.45506762917690025},\n",
       "     {'mcc': -0.03163097111740883, 'macro_f1': 0.45027124773960214},\n",
       "     {'mcc': -0.01997921972915381, 'macro_f1': 0.4605919653328563},\n",
       "     {'mcc': 0.0, 'macro_f1': 0.3397807865892972},\n",
       "     {'mcc': 0.0604245641870935, 'macro_f1': 0.5068874412197264},\n",
       "     {'mcc': 0.027052036856800587, 'macro_f1': 0.34873493721450854},\n",
       "     {'mcc': 0.04935369384616507, 'macro_f1': 0.524311990926703},\n",
       "     {'mcc': 0.05325292049935875, 'macro_f1': 0.526312526527128},\n",
       "     {'mcc': -0.02252217449696758, 'macro_f1': 0.46953397890282356}]},\n",
       "   'total': {'test_mcc': 1.7667118152617531,\n",
       "    'test_mcc_se': 2.134002465164145,\n",
       "    'test_macro_f1': 45.44429566566609,\n",
       "    'test_macro_f1_se': 3.9994691073078252}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-de',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.13230351312800437,\n",
       "      'macro_f1': 0.4287308228730823},\n",
       "     {'mcc': 0.05456249904029655, 'macro_f1': 0.4112392387507344},\n",
       "     {'mcc': 0.06242902745048135, 'macro_f1': 0.373248127588774},\n",
       "     {'mcc': 0.10358015771688918, 'macro_f1': 0.40805319720256095},\n",
       "     {'mcc': 0.12556962143309278, 'macro_f1': 0.41967590542814137},\n",
       "     {'mcc': 0.03268042088421983, 'macro_f1': 0.37684901641678137},\n",
       "     {'mcc': 0.20027285680841228, 'macro_f1': 0.5648854652176911},\n",
       "     {'mcc': 0.08058786244002157, 'macro_f1': 0.37167559491438723},\n",
       "     {'mcc': 0.08655388185951726, 'macro_f1': 0.39869622629714463},\n",
       "     {'mcc': 0.10846936380315701, 'macro_f1': 0.4669541685043915}]},\n",
       "   'total': {'test_mcc': 9.870092045640924,\n",
       "    'test_mcc_se': 2.9498082676479918,\n",
       "    'test_macro_f1': 42.200077631936885,\n",
       "    'test_macro_f1_se': 3.5956557240191533}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-nl',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.22830832848761948,\n",
       "      'macro_f1': 0.602893131921401},\n",
       "     {'mcc': 0.16952675746597953, 'macro_f1': 0.5333615938957186},\n",
       "     {'mcc': 0.1072819045586079, 'macro_f1': 0.46312644085083426},\n",
       "     {'mcc': 0.18413954529718157, 'macro_f1': 0.5917964857067926},\n",
       "     {'mcc': 0.18962177934945937, 'macro_f1': 0.5894631084864739},\n",
       "     {'mcc': 0.11229751638314982, 'macro_f1': 0.43301642178046673},\n",
       "     {'mcc': 0.25978091620807414, 'macro_f1': 0.6214703274845939},\n",
       "     {'mcc': 0.1795774811057875, 'macro_f1': 0.5891571147817214},\n",
       "     {'mcc': 0.25065688953043197, 'macro_f1': 0.6085195639366041},\n",
       "     {'mcc': 0.11257697610753242, 'macro_f1': 0.5548469815224958}]},\n",
       "   'total': {'test_mcc': 17.937680944938236,\n",
       "    'test_mcc_se': 3.4770713783699163,\n",
       "    'test_macro_f1': 55.87651170367103,\n",
       "    'test_macro_f1_se': 3.9704192346412537}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-en',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.2694146319264918,\n",
       "      'macro_f1': 0.6335342850626093},\n",
       "     {'mcc': 0.2617350051257287, 'macro_f1': 0.6307315580042853},\n",
       "     {'mcc': 0.38070172696403226, 'macro_f1': 0.6888009455892579},\n",
       "     {'mcc': 0.3571608013417317, 'macro_f1': 0.6776455302793987},\n",
       "     {'mcc': 0.35476690993599985, 'macro_f1': 0.6771622728622311},\n",
       "     {'mcc': 0.2774595324241904, 'macro_f1': 0.6387259525124109},\n",
       "     {'mcc': 0.23698465795480259, 'macro_f1': 0.5996569925685801},\n",
       "     {'mcc': 0.3425099845198039, 'macro_f1': 0.6633251522431327},\n",
       "     {'mcc': 0.32389298230113656, 'macro_f1': 0.6562234859459106},\n",
       "     {'mcc': 0.39938890241854585, 'macro_f1': 0.696098657292687}]},\n",
       "   'total': {'test_mcc': 32.04015134912464,\n",
       "    'test_mcc_se': 3.4417790206050967,\n",
       "    'test_macro_f1': 65.61904832360503,\n",
       "    'test_macro_f1_se': 1.8787905878629527}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 50.50348567002324,\n",
       "      'f1': 59.82029714154704},\n",
       "     {'em': 49.457364341085274, 'f1': 58.4479733204106},\n",
       "     {'em': 51.931993817619784, 'f1': 60.562023388416634},\n",
       "     {'em': 50.07788161993769, 'f1': 60.144487366660755},\n",
       "     {'em': 48.803088803088805, 'f1': 59.467244094400094},\n",
       "     {'em': 50.038550501156514, 'f1': 60.28719460099559},\n",
       "     {'em': 54.290053151100985, 'f1': 61.60697022307276},\n",
       "     {'em': 52.598913886733904, 'f1': 60.8856297408514},\n",
       "     {'em': 52.15686274509804, 'f1': 59.65325807090506},\n",
       "     {'em': 51.5527950310559, 'f1': 60.88737056780961}]},\n",
       "   'total': {'test_em': 51.14109895669001,\n",
       "    'test_em_se': 1.0313931861768566,\n",
       "    'test_f1': 60.17624485150695,\n",
       "    'test_f1_se': 0.5508132314011689}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'norquad',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['nb', 'nn', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 39.1232423490488,\n",
       "      'f1': 67.17950156232162},\n",
       "     {'em': 27.81954887218045, 'f1': 55.49784893190784},\n",
       "     {'em': 33.751044277360066, 'f1': 62.12244635782577},\n",
       "     {'em': 27.70885028949545, 'f1': 58.84912160247672},\n",
       "     {'em': 29.498767460969596, 'f1': 56.48602009489551},\n",
       "     {'em': 20.214521452145213, 'f1': 46.073062137506845},\n",
       "     {'em': 20.115416323165704, 'f1': 49.09414272433031},\n",
       "     {'em': 38.30141548709409, 'f1': 65.33333192104425},\n",
       "     {'em': 23.893065998329156, 'f1': 54.37857855090921},\n",
       "     {'em': 25.79564489112228, 'f1': 54.1167325565849}]},\n",
       "   'total': {'test_em': 28.622151740091077,\n",
       "    'test_em_se': 4.162505173443879,\n",
       "    'test_f1': 56.91307864398029,\n",
       "    'test_f1_se': 4.143679261148459}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scandiqa-sv',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 47.09527498063517,\n",
       "      'f1': 57.33949168280794},\n",
       "     {'em': 49.6124031007752, 'f1': 57.805639035407175},\n",
       "     {'em': 48.145285935085006, 'f1': 56.62609753589909},\n",
       "     {'em': 47.741433021806856, 'f1': 56.678581035750156},\n",
       "     {'em': 52.12355212355212, 'f1': 60.77094056527927},\n",
       "     {'em': 49.73014649190439, 'f1': 59.122339161790684},\n",
       "     {'em': 49.278663629460894, 'f1': 56.82494593596374},\n",
       "     {'em': 41.272304111714504, 'f1': 55.78719874494052},\n",
       "     {'em': 50.11764705882353, 'f1': 59.909163413934785},\n",
       "     {'em': 48.68012422360248, 'f1': 57.441455341744685}]},\n",
       "   'total': {'test_em': 48.37968346773602,\n",
       "    'test_em_se': 1.776126053871472,\n",
       "    'test_f1': 57.83058524535181,\n",
       "    'test_f1_se': 0.9906710561210017}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'nqii',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['is'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 19.6048632218845,\n",
       "      'f1': 45.767214625693036},\n",
       "     {'em': 13.615023474178404, 'f1': 47.405608043721955},\n",
       "     {'em': 23.02936630602782, 'f1': 52.838829719920774},\n",
       "     {'em': 21.792890262751158, 'f1': 52.59980019986381},\n",
       "     {'em': 25.80128205128205, 'f1': 52.76572990495529},\n",
       "     {'em': 26.033690658499236, 'f1': 53.71734302619124},\n",
       "     {'em': 22.580645161290324, 'f1': 50.93345395915304},\n",
       "     {'em': 26.371951219512194, 'f1': 49.9749737428489},\n",
       "     {'em': 26.50231124807396, 'f1': 49.728385046085705},\n",
       "     {'em': 24.430955993930198, 'f1': 51.6280265478057}]},\n",
       "   'total': {'test_em': 22.976297959742983,\n",
       "    'test_em_se': 2.4789440824629247,\n",
       "    'test_f1': 50.73593648162394,\n",
       "    'test_f1_se': 1.5884647007981765}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'germanquad',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 19.519752130131682,\n",
       "      'f1': 44.63290224978412},\n",
       "     {'em': 26.434108527131784, 'f1': 58.40932063467007},\n",
       "     {'em': 22.256568778979908, 'f1': 45.420043643813756},\n",
       "     {'em': 22.97507788161994, 'f1': 46.899050325803586},\n",
       "     {'em': 23.706563706563706, 'f1': 52.28733756932006},\n",
       "     {'em': 23.515805705474172, 'f1': 52.457312094928206},\n",
       "     {'em': 16.932422171602127, 'f1': 40.10357265224115},\n",
       "     {'em': 7.292474786656323, 'f1': 28.34070679449817},\n",
       "     {'em': 19.372549019607842, 'f1': 48.397758220778115},\n",
       "     {'em': 19.953416149068325, 'f1': 53.24727627622949}]},\n",
       "   'total': {'test_em': 20.19587388568358,\n",
       "    'test_em_se': 3.2834437533976675,\n",
       "    'test_f1': 47.01952804620667,\n",
       "    'test_f1_se': 5.19689072754445}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'squad',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 54.918667699457785,\n",
       "      'f1': 78.74034361270203},\n",
       "     {'em': 55.42635658914729, 'f1': 77.98477740361675},\n",
       "     {'em': 49.92272024729521, 'f1': 76.28104514937965},\n",
       "     {'em': 46.80685358255452, 'f1': 73.55360447268899},\n",
       "     {'em': 47.87644787644788, 'f1': 75.16856160778343},\n",
       "     {'em': 46.954510408635315, 'f1': 74.18197080696586},\n",
       "     {'em': 54.97342444950645, 'f1': 76.70776663712358},\n",
       "     {'em': 51.20248254460822, 'f1': 74.29344257072374},\n",
       "     {'em': 48.470588235294116, 'f1': 76.29232855439349},\n",
       "     {'em': 38.81987577639752, 'f1': 69.42336777333094}]},\n",
       "   'total': {'test_em': 49.53719274093443,\n",
       "    'test_em_se': 3.1264478873814663,\n",
       "    'test_f1': 75.26272085887084,\n",
       "    'test_f1_se': 1.6375640130986882}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'squad-nl',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'em': 47.1727343144849,\n",
       "      'f1': 63.66918353708149},\n",
       "     {'em': 50.23255813953488, 'f1': 66.13573113607373},\n",
       "     {'em': 52.31839258114374, 'f1': 67.67424247373307},\n",
       "     {'em': 46.10591900311527, 'f1': 62.12431731502419},\n",
       "     {'em': 47.95366795366795, 'f1': 64.71872997565721},\n",
       "     {'em': 50.886661526599845, 'f1': 66.0994534694959},\n",
       "     {'em': 48.747152619589976, 'f1': 66.92141564227789},\n",
       "     {'em': 47.323506594259115, 'f1': 63.3055977448994},\n",
       "     {'em': 43.21568627450981, 'f1': 61.87871088218913},\n",
       "     {'em': 43.7111801242236, 'f1': 61.84956404315601}]},\n",
       "   'total': {'test_em': 47.76674591311291,\n",
       "    'test_em_se': 1.8246038824606758,\n",
       "    'test_f1': 64.4376946219588,\n",
       "    'test_f1_se': 1.3522366301050937}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6667006455245428,\n",
       "      'rouge_l': 0.20254902039373546},\n",
       "     {'bertscore': 0.6700816130032763, 'rouge_l': 0.21113012530844547},\n",
       "     {'bertscore': 0.6463267653016374, 'rouge_l': 0.20389814454513322},\n",
       "     {'bertscore': 0.6569811394438148, 'rouge_l': 0.18356329175182168},\n",
       "     {'bertscore': 0.6288783310010331, 'rouge_l': 0.18606152130802328},\n",
       "     {'bertscore': 0.6610827566764783, 'rouge_l': 0.1928020854975715},\n",
       "     {'bertscore': 0.6547049144865014, 'rouge_l': 0.176301386052293},\n",
       "     {'bertscore': 0.6486691315076314, 'rouge_l': 0.16105149738595306},\n",
       "     {'bertscore': 0.6444895903114229, 'rouge_l': 0.15885647054833252},\n",
       "     {'bertscore': 0.6406220135831973, 'rouge_l': 0.15735569835124974}]},\n",
       "   'total': {'test_bertscore': 65.18536900839536,\n",
       "    'test_bertscore_se': 0.7788711917637351,\n",
       "    'test_rouge_l': 18.335692411425587,\n",
       "    'test_rouge_l_se': 1.2191007697717509}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mlsum',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6572601597436005,\n",
       "      'rouge_l': 0.19065836731136718},\n",
       "     {'bertscore': 0.6486432485107798, 'rouge_l': 0.18548902272389955},\n",
       "     {'bertscore': 0.6479701580683468, 'rouge_l': 0.1816986903512896},\n",
       "     {'bertscore': 0.6557764685130678, 'rouge_l': 0.1935672666996609},\n",
       "     {'bertscore': 0.6661524995870423, 'rouge_l': 0.21439955928275065},\n",
       "     {'bertscore': 0.6579766930808546, 'rouge_l': 0.19014522773441841},\n",
       "     {'bertscore': 0.6582229511841433, 'rouge_l': 0.18793108718097118},\n",
       "     {'bertscore': 0.6874221376638161, 'rouge_l': 0.26410159520006643},\n",
       "     {'bertscore': 0.6962312074610963, 'rouge_l': 0.29209192712456156},\n",
       "     {'bertscore': 0.6639197426557075, 'rouge_l': 0.2206184913943664}]},\n",
       "   'total': {'test_bertscore': 66.39575266468455,\n",
       "    'test_bertscore_se': 0.9838169639635429,\n",
       "    'test_rouge_l': 21.20701235003352,\n",
       "    'test_rouge_l_se': 2.3266791520329533}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'rrn',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['is'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.5684296062972862,\n",
       "      'rouge_l': 0.0641368778320143},\n",
       "     {'bertscore': 0.6572779958951287, 'rouge_l': 0.1663572896196256},\n",
       "     {'bertscore': 0.6312546561821364, 'rouge_l': 0.15262350837334165},\n",
       "     {'bertscore': 0.6276354398869444, 'rouge_l': 0.15378341750478897},\n",
       "     {'bertscore': 0.633071401680354, 'rouge_l': 0.15972675770846384},\n",
       "     {'bertscore': 0.6381342280656099, 'rouge_l': 0.161919272090832},\n",
       "     {'bertscore': 0.5623300054576248, 'rouge_l': 0.11947063056951325},\n",
       "     {'bertscore': 0.6234669584664516, 'rouge_l': 0.14795681322045529},\n",
       "     {'bertscore': 0.6382019013690297, 'rouge_l': 0.16567150777865364},\n",
       "     {'bertscore': 0.6201257784268819, 'rouge_l': 0.14856128848824146}]},\n",
       "   'total': {'test_bertscore': 61.99927971727448,\n",
       "    'test_bertscore_se': 1.8938786806326138,\n",
       "    'test_rouge_l': 14.402073631859302,\n",
       "    'test_rouge_l_se': 1.9297435889925714}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'no-sammendrag',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['nb', 'nn', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6203160089498851,\n",
       "      'rouge_l': 0.12003965541708109},\n",
       "     {'bertscore': 0.5908669547352474, 'rouge_l': 0.09861127132299424},\n",
       "     {'bertscore': 0.6151381525342003, 'rouge_l': 0.12023232597821182},\n",
       "     {'bertscore': 0.589563453104347, 'rouge_l': 0.08953554183214238},\n",
       "     {'bertscore': 0.6119919738266617, 'rouge_l': 0.11262790811180619},\n",
       "     {'bertscore': 0.6125971630972344, 'rouge_l': 0.11439584448264056},\n",
       "     {'bertscore': 0.6080509232560871, 'rouge_l': 0.10967707801952853},\n",
       "     {'bertscore': 0.6127445206802804, 'rouge_l': 0.11594088309504014},\n",
       "     {'bertscore': 0.6004212239786284, 'rouge_l': 0.10886817793742896},\n",
       "     {'bertscore': 0.5886952621585806, 'rouge_l': 0.10098989613020928}]},\n",
       "   'total': {'test_bertscore': 60.503856363211526,\n",
       "    'test_bertscore_se': 0.7269569652773957,\n",
       "    'test_rouge_l': 10.909185823270832,\n",
       "    'test_rouge_l_se': 0.6162965964017622}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'wiki-lingua-nl',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6734188263071701,\n",
       "      'rouge_l': 0.19149446285861088},\n",
       "     {'bertscore': 0.676835489430232, 'rouge_l': 0.1945246988556536},\n",
       "     {'bertscore': 0.6851447897352045, 'rouge_l': 0.20699045443415026},\n",
       "     {'bertscore': 0.6892951170593733, 'rouge_l': 0.2116664638513699},\n",
       "     {'bertscore': 0.6609905855584657, 'rouge_l': 0.15247847134205664},\n",
       "     {'bertscore': 0.6535734770732233, 'rouge_l': 0.1655810393035364},\n",
       "     {'bertscore': 0.6515676246053772, 'rouge_l': 0.15925402562579308},\n",
       "     {'bertscore': 0.6742871557653416, 'rouge_l': 0.18649695313407255},\n",
       "     {'bertscore': 0.6715891211351845, 'rouge_l': 0.19707473041320417},\n",
       "     {'bertscore': 0.6377062897372525, 'rouge_l': 0.16751739099197438}]},\n",
       "   'total': {'test_bertscore': 66.74408476406825,\n",
       "    'test_bertscore_se': 1.0013550461667269,\n",
       "    'test_rouge_l': 18.33078690810422,\n",
       "    'test_rouge_l_se': 1.2819705109119683}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'swedn',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6553081804013345,\n",
       "      'rouge_l': 0.18012750488067839},\n",
       "     {'bertscore': 0.6522780133673223, 'rouge_l': 0.17399943236103566},\n",
       "     {'bertscore': 0.6519677524629515, 'rouge_l': 0.17820977640043595},\n",
       "     {'bertscore': 0.6439909693435766, 'rouge_l': 0.17969059449344593},\n",
       "     {'bertscore': 0.6315512987202965, 'rouge_l': 0.1594059246497883},\n",
       "     {'bertscore': 0.6519816382497083, 'rouge_l': 0.17435901468283016},\n",
       "     {'bertscore': 0.6516590343089774, 'rouge_l': 0.1752726170430428},\n",
       "     {'bertscore': 0.6600494420708856, 'rouge_l': 0.19014964760914232},\n",
       "     {'bertscore': 0.6506283837225055, 'rouge_l': 0.17280404317306305},\n",
       "     {'bertscore': 0.648635004501557, 'rouge_l': 0.16854230877210644}]},\n",
       "   'total': {'test_bertscore': 64.98049717149115,\n",
       "    'test_bertscore_se': 0.47259511057879566,\n",
       "    'test_rouge_l': 17.525608640655694,\n",
       "    'test_rouge_l_se': 0.49697893623908246}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'cnn-dailymail',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6929191083327169,\n",
       "      'rouge_l': 0.25314053474503906},\n",
       "     {'bertscore': 0.690638622851111, 'rouge_l': 0.24832522045613536},\n",
       "     {'bertscore': 0.6922211278579198, 'rouge_l': 0.2427959674539935},\n",
       "     {'bertscore': 0.6974540348164737, 'rouge_l': 0.2589379992940616},\n",
       "     {'bertscore': 0.691610451642191, 'rouge_l': 0.2438733498386353},\n",
       "     {'bertscore': 0.6936923325120006, 'rouge_l': 0.2431688276329187},\n",
       "     {'bertscore': 0.6945487826451426, 'rouge_l': 0.2522663550927843},\n",
       "     {'bertscore': 0.6873442440992221, 'rouge_l': 0.2525576446707924},\n",
       "     {'bertscore': 0.6941907504224218, 'rouge_l': 0.25033813387009785},\n",
       "     {'bertscore': 0.6883417303906754, 'rouge_l': 0.2381969538358613}]},\n",
       "   'total': {'test_bertscore': 69.22961185569875,\n",
       "    'test_bertscore_se': 0.1859270692499287,\n",
       "    'test_rouge_l': 24.83600986890319,\n",
       "    'test_rouge_l_se': 0.3880964436649091}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.50727662667166,\n",
       "      'accuracy': 0.6298828125},\n",
       "     {'mcc': 0.5163283724966924, 'accuracy': 0.6376953125},\n",
       "     {'mcc': 0.5092657703874478, 'accuracy': 0.6279296875},\n",
       "     {'mcc': 0.4522225947452629, 'accuracy': 0.587890625},\n",
       "     {'mcc': 0.48470086601411067, 'accuracy': 0.61328125},\n",
       "     {'mcc': 0.5022384297450002, 'accuracy': 0.6259765625},\n",
       "     {'mcc': 0.4983432355972783, 'accuracy': 0.623046875},\n",
       "     {'mcc': 0.46266886333959967, 'accuracy': 0.5986328125},\n",
       "     {'mcc': 0.5139678458235615, 'accuracy': 0.6357421875},\n",
       "     {'mcc': 0.5306663881750331, 'accuracy': 0.6484375}]},\n",
       "   'total': {'test_mcc': 49.77678992995646,\n",
       "    'test_mcc_se': 1.5195075543924272,\n",
       "    'test_accuracy': 62.28515624999999,\n",
       "    'test_accuracy_se': 1.1366086418130459}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.47480702838261335,\n",
       "      'accuracy': 0.650390625},\n",
       "     {'mcc': 0.4276505495005222, 'accuracy': 0.619140625},\n",
       "     {'mcc': 0.5217851299802405, 'accuracy': 0.677734375},\n",
       "     {'mcc': 0.49377291566141374, 'accuracy': 0.662109375},\n",
       "     {'mcc': 0.4370844254087689, 'accuracy': 0.625},\n",
       "     {'mcc': 0.48179035841849505, 'accuracy': 0.66015625},\n",
       "     {'mcc': 0.46780883404363943, 'accuracy': 0.642578125},\n",
       "     {'mcc': 0.4629384557169037, 'accuracy': 0.642578125},\n",
       "     {'mcc': 0.3824433614579479, 'accuracy': 0.587890625},\n",
       "     {'mcc': 0.4380057459295673, 'accuracy': 0.62890625}]},\n",
       "   'total': {'test_mcc': 45.880868045001115,\n",
       "    'test_mcc_se': 2.4250805604625025,\n",
       "    'test_accuracy': 63.96484375,\n",
       "    'test_accuracy_se': 1.5919866376749494}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mmlu-no',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['nb', 'nn', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.2795473567286385,\n",
       "      'accuracy': 0.4609375},\n",
       "     {'mcc': 0.2898406467526693, 'accuracy': 0.46923828125},\n",
       "     {'mcc': 0.28651724108938126, 'accuracy': 0.466796875},\n",
       "     {'mcc': 0.2844247433092799, 'accuracy': 0.466796875},\n",
       "     {'mcc': 0.23885584996233883, 'accuracy': 0.42919921875},\n",
       "     {'mcc': 0.26752324327792015, 'accuracy': 0.45458984375},\n",
       "     {'mcc': 0.26037013145863963, 'accuracy': 0.44873046875},\n",
       "     {'mcc': 0.24909338564666056, 'accuracy': 0.4384765625},\n",
       "     {'mcc': 0.25252656491768444, 'accuracy': 0.44189453125},\n",
       "     {'mcc': 0.2732865166417855, 'accuracy': 0.45556640625}]},\n",
       "   'total': {'test_mcc': 26.81985679784998,\n",
       "    'test_mcc_se': 1.0844702820818146,\n",
       "    'test_accuracy': 45.322265625,\n",
       "    'test_accuracy_se': 0.8353932061076171}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mmlu-sv',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.3019151645281718,\n",
       "      'accuracy': 0.47802734375},\n",
       "     {'mcc': 0.29201935191649514, 'accuracy': 0.47021484375},\n",
       "     {'mcc': 0.28885425715099033, 'accuracy': 0.466796875},\n",
       "     {'mcc': 0.2946566598914336, 'accuracy': 0.4716796875},\n",
       "     {'mcc': 0.3106696201943348, 'accuracy': 0.484375},\n",
       "     {'mcc': 0.28384585600903944, 'accuracy': 0.46337890625},\n",
       "     {'mcc': 0.3093267531234359, 'accuracy': 0.4833984375},\n",
       "     {'mcc': 0.28922193579854033, 'accuracy': 0.46826171875},\n",
       "     {'mcc': 0.2819270000813208, 'accuracy': 0.46337890625},\n",
       "     {'mcc': 0.29113929057481247, 'accuracy': 0.47119140625}]},\n",
       "   'total': {'test_mcc': 29.435758892685747,\n",
       "    'test_mcc_se': 0.6145735123463092,\n",
       "    'test_accuracy': 47.20703125,\n",
       "    'test_accuracy_se': 0.4679351098266335}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mmlu-de',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.33839326401349046,\n",
       "      'accuracy': 0.50439453125},\n",
       "     {'mcc': 0.33574200892725364, 'accuracy': 0.50146484375},\n",
       "     {'mcc': 0.33478735699727324, 'accuracy': 0.50244140625},\n",
       "     {'mcc': 0.3486289611015788, 'accuracy': 0.51220703125},\n",
       "     {'mcc': 0.3382290602844435, 'accuracy': 0.50439453125},\n",
       "     {'mcc': 0.34312659695412406, 'accuracy': 0.5068359375},\n",
       "     {'mcc': 0.33139583975056885, 'accuracy': 0.49951171875},\n",
       "     {'mcc': 0.33130117891269056, 'accuracy': 0.50048828125},\n",
       "     {'mcc': 0.32702267018060244, 'accuracy': 0.49609375},\n",
       "     {'mcc': 0.32928551594512334, 'accuracy': 0.49951171875}]},\n",
       "   'total': {'test_mcc': 33.57912453067149,\n",
       "    'test_mcc_se': 0.40854532432282875,\n",
       "    'test_accuracy': 50.27343749999999,\n",
       "    'test_accuracy_se': 0.2800032043273679}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mmlu-nl',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.3435782180292054,\n",
       "      'accuracy': 0.5078125},\n",
       "     {'mcc': 0.3280335002576642, 'accuracy': 0.49609375},\n",
       "     {'mcc': 0.31858260302425484, 'accuracy': 0.490234375},\n",
       "     {'mcc': 0.3486791784713766, 'accuracy': 0.51123046875},\n",
       "     {'mcc': 0.3377879873217268, 'accuracy': 0.5029296875},\n",
       "     {'mcc': 0.33079688419891845, 'accuracy': 0.49658203125},\n",
       "     {'mcc': 0.33336395571648836, 'accuracy': 0.498046875},\n",
       "     {'mcc': 0.3239732166216306, 'accuracy': 0.49267578125},\n",
       "     {'mcc': 0.3598540765682543, 'accuracy': 0.5185546875},\n",
       "     {'mcc': 0.3548925788371235, 'accuracy': 0.515625}]},\n",
       "   'total': {'test_mcc': 33.79542199046643,\n",
       "    'test_mcc_se': 0.8404010558567104,\n",
       "    'test_accuracy': 50.29785156249999,\n",
       "    'test_accuracy_se': 0.6112109713412395}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'mmlu',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.4496367419204388,\n",
       "      'accuracy': 0.5849609375},\n",
       "     {'mcc': 0.46651418340316836, 'accuracy': 0.59765625},\n",
       "     {'mcc': 0.4690632159030179, 'accuracy': 0.599609375},\n",
       "     {'mcc': 0.45072160543606726, 'accuracy': 0.5859375},\n",
       "     {'mcc': 0.4532966166866431, 'accuracy': 0.58837890625},\n",
       "     {'mcc': 0.47440313697742037, 'accuracy': 0.60595703125},\n",
       "     {'mcc': 0.43536861197975574, 'accuracy': 0.57470703125},\n",
       "     {'mcc': 0.4517875035627989, 'accuracy': 0.5869140625},\n",
       "     {'mcc': 0.4560357583775518, 'accuracy': 0.5908203125},\n",
       "     {'mcc': 0.4430204603265598, 'accuracy': 0.58154296875}]},\n",
       "   'total': {'test_mcc': 45.49847834573421,\n",
       "    'test_mcc_se': 0.7440816394514115,\n",
       "    'test_accuracy': 58.96484374999999,\n",
       "    'test_accuracy_se': 0.5712335598929011}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'arc-is',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['is'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.142197102749231,\n",
       "      'accuracy': 0.3583984375},\n",
       "     {'mcc': 0.15415998149772644, 'accuracy': 0.369140625},\n",
       "     {'mcc': 0.14242106768461874, 'accuracy': 0.3603515625},\n",
       "     {'mcc': 0.11910521277545326, 'accuracy': 0.345703125},\n",
       "     {'mcc': 0.13704230325879801, 'accuracy': 0.359375},\n",
       "     {'mcc': 0.10300822152483201, 'accuracy': 0.330078125},\n",
       "     {'mcc': 0.1414370499139691, 'accuracy': 0.36328125},\n",
       "     {'mcc': 0.1002896080159889, 'accuracy': 0.328125},\n",
       "     {'mcc': 0.15866873765195572, 'accuracy': 0.37109375},\n",
       "     {'mcc': 0.1350614455719346, 'accuracy': 0.3564453125}]},\n",
       "   'total': {'test_mcc': 13.333907306445075,\n",
       "    'test_mcc_se': 1.2280473001579804,\n",
       "    'test_accuracy': 35.419921875,\n",
       "    'test_accuracy_se': 0.9268007546433636}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.2011163809825723,\n",
       "      'accuracy': 0.396484375},\n",
       "     {'mcc': 0.2255900432259065, 'accuracy': 0.4189453125},\n",
       "     {'mcc': 0.21435175122197078, 'accuracy': 0.40869140625},\n",
       "     {'mcc': 0.18716646390764308, 'accuracy': 0.38427734375},\n",
       "     {'mcc': 0.2488120726720305, 'accuracy': 0.43359375},\n",
       "     {'mcc': 0.237411576968545, 'accuracy': 0.42626953125},\n",
       "     {'mcc': 0.16021578764947905, 'accuracy': 0.36474609375},\n",
       "     {'mcc': 0.23827437046781313, 'accuracy': 0.427734375},\n",
       "     {'mcc': 0.24658063812975856, 'accuracy': 0.4326171875},\n",
       "     {'mcc': 0.22936634354039012, 'accuracy': 0.4228515625}]},\n",
       "   'total': {'test_mcc': 21.88885428766109,\n",
       "    'test_mcc_se': 1.7677577467745245,\n",
       "    'test_accuracy': 41.162109375,\n",
       "    'test_accuracy_se': 1.4254447793144365}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-no',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['nb', 'nn', 'no'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.18836511123348948,\n",
       "      'accuracy': 0.384765625},\n",
       "     {'mcc': 0.20519381307175685, 'accuracy': 0.4013671875},\n",
       "     {'mcc': 0.2405125925327349, 'accuracy': 0.42919921875},\n",
       "     {'mcc': 0.2356963402587648, 'accuracy': 0.42333984375},\n",
       "     {'mcc': 0.20280381151946067, 'accuracy': 0.4013671875},\n",
       "     {'mcc': 0.18734366204305264, 'accuracy': 0.3876953125},\n",
       "     {'mcc': 0.18284127968869276, 'accuracy': 0.3798828125},\n",
       "     {'mcc': 0.24350349555762021, 'accuracy': 0.43115234375},\n",
       "     {'mcc': 0.2015592388952731, 'accuracy': 0.3896484375},\n",
       "     {'mcc': 0.21039052239459097, 'accuracy': 0.4052734375}]},\n",
       "   'total': {'test_mcc': 20.98209867195436,\n",
       "    'test_mcc_se': 1.3980022988280933,\n",
       "    'test_accuracy': 40.3369140625,\n",
       "    'test_accuracy_se': 1.1652791609899236}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-sv',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['sv'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.26855918037555715,\n",
       "      'accuracy': 0.44970703125},\n",
       "     {'mcc': 0.22988189838661524, 'accuracy': 0.421875},\n",
       "     {'mcc': 0.23963487338800096, 'accuracy': 0.43017578125},\n",
       "     {'mcc': 0.22478078772685273, 'accuracy': 0.416015625},\n",
       "     {'mcc': 0.1837471531012148, 'accuracy': 0.38232421875},\n",
       "     {'mcc': 0.17216700221782677, 'accuracy': 0.37158203125},\n",
       "     {'mcc': 0.20249191830175897, 'accuracy': 0.39892578125},\n",
       "     {'mcc': 0.2503880337332657, 'accuracy': 0.4345703125},\n",
       "     {'mcc': 0.24871562297227584, 'accuracy': 0.42529296875},\n",
       "     {'mcc': 0.22181789045662617, 'accuracy': 0.41455078125}]},\n",
       "   'total': {'test_mcc': 22.421843606599943,\n",
       "    'test_mcc_se': 1.8874663071683486,\n",
       "    'test_accuracy': 41.4501953125,\n",
       "    'test_accuracy_se': 1.4871121468125852}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'winogrande-is',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['is'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.03233404162249172,\n",
       "      'accuracy': 0.5044642857142857},\n",
       "     {'mcc': 0.022480545378992193, 'accuracy': 0.5301339285714286},\n",
       "     {'mcc': -0.022168866977949855, 'accuracy': 0.49776785714285715},\n",
       "     {'mcc': 0.010382954263242152, 'accuracy': 0.5189732142857143},\n",
       "     {'mcc': 0.0278173350028741, 'accuracy': 0.5178571428571429},\n",
       "     {'mcc': -0.0019953072350231303, 'accuracy': 0.5167410714285714},\n",
       "     {'mcc': -0.003495679491884857, 'accuracy': 0.4966517857142857},\n",
       "     {'mcc': -0.01143508951419146, 'accuracy': 0.49330357142857145},\n",
       "     {'mcc': 0.01599448556393008, 'accuracy': 0.5111607142857143},\n",
       "     {'mcc': 0.004246264752811902, 'accuracy': 0.5044642857142857}]},\n",
       "   'total': {'test_mcc': 0.7416068336529283,\n",
       "    'test_mcc_se': 1.0922142148599303,\n",
       "    'test_accuracy': 50.91517857142858,\n",
       "    'test_accuracy_se': 0.7319322553275608}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-de',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['de'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.30927485232248636,\n",
       "      'accuracy': 0.47802734375},\n",
       "     {'mcc': 0.26155876388070604, 'accuracy': 0.4423828125},\n",
       "     {'mcc': 0.30525521514246245, 'accuracy': 0.47802734375},\n",
       "     {'mcc': 0.28967575237817006, 'accuracy': 0.46337890625},\n",
       "     {'mcc': 0.2641843323982274, 'accuracy': 0.44287109375},\n",
       "     {'mcc': 0.285387515978579, 'accuracy': 0.4638671875},\n",
       "     {'mcc': 0.2866243649980086, 'accuracy': 0.462890625},\n",
       "     {'mcc': 0.3053769383320988, 'accuracy': 0.47607421875},\n",
       "     {'mcc': 0.2929082629854515, 'accuracy': 0.46875},\n",
       "     {'mcc': 0.29692363708768604, 'accuracy': 0.46826171875}]},\n",
       "   'total': {'test_mcc': 28.971696355038766,\n",
       "    'test_mcc_se': 1.0130697698418172,\n",
       "    'test_accuracy': 46.4453125,\n",
       "    'test_accuracy_se': 0.7983932784795416}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-nl',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['nl'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.2123658045721719,\n",
       "      'accuracy': 0.4052734375},\n",
       "     {'mcc': 0.19103249768111663, 'accuracy': 0.38134765625},\n",
       "     {'mcc': 0.2073757919511386, 'accuracy': 0.39892578125},\n",
       "     {'mcc': 0.17600872624329497, 'accuracy': 0.376953125},\n",
       "     {'mcc': 0.25305006945585823, 'accuracy': 0.4384765625},\n",
       "     {'mcc': 0.20339287689881347, 'accuracy': 0.3994140625},\n",
       "     {'mcc': 0.22759832114627288, 'accuracy': 0.41845703125},\n",
       "     {'mcc': 0.19899926680027044, 'accuracy': 0.39501953125},\n",
       "     {'mcc': 0.21488379836861082, 'accuracy': 0.404296875},\n",
       "     {'mcc': 0.21701169849485386, 'accuracy': 0.4091796875}]},\n",
       "   'total': {'test_mcc': 21.01718851612402,\n",
       "    'test_mcc_se': 1.2948624762698997,\n",
       "    'test_accuracy': 40.2734375,\n",
       "    'test_accuracy_se': 1.0897649843351085}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['en'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.43004764881389856,\n",
       "      'accuracy': 0.56640625},\n",
       "     {'mcc': 0.4658109471103639, 'accuracy': 0.59521484375},\n",
       "     {'mcc': 0.4878673597357317, 'accuracy': 0.60986328125},\n",
       "     {'mcc': 0.45222485711089155, 'accuracy': 0.58544921875},\n",
       "     {'mcc': 0.45965480302592676, 'accuracy': 0.5908203125},\n",
       "     {'mcc': 0.461954109019371, 'accuracy': 0.595703125},\n",
       "     {'mcc': 0.5252385935276342, 'accuracy': 0.64013671875},\n",
       "     {'mcc': 0.47899830424562667, 'accuracy': 0.60888671875},\n",
       "     {'mcc': 0.46399934571737506, 'accuracy': 0.59423828125},\n",
       "     {'mcc': 0.4244858001941005, 'accuracy': 0.556640625}]},\n",
       "   'total': {'test_mcc': 46.5028176850092,\n",
       "    'test_mcc_se': 1.7788585766485387,\n",
       "    'test_accuracy': 59.43359375,\n",
       "    'test_accuracy_se': 1.4381533051325175}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results': {'raw': {'test': [{'test_speed': 2455.9,\n",
       "      'test_speed_short': 384.09999999999997},\n",
       "     {'test_speed': 5252.04, 'test_speed_short': 704.6999999999999},\n",
       "     {'test_speed': 7482.64, 'test_speed_short': 1327.36},\n",
       "     {'test_speed': 9392.74, 'test_speed_short': 1625.82},\n",
       "     {'test_speed': 10596.72, 'test_speed_short': 1920.4999999999998},\n",
       "     {'test_speed': 12310.279999999999, 'test_speed_short': 2393.82},\n",
       "     {'test_speed': 13291.3, 'test_speed_short': 2664.74},\n",
       "     {'test_speed': 13366.44, 'test_speed_short': 2949.54},\n",
       "     {'test_speed': 14707.140000000001,\n",
       "      'test_speed_short': 3239.1000000000004},\n",
       "     {'test_speed': 15382.36, 'test_speed_short': 3595.62}]},\n",
       "   'total': {'test_speed': 10423.756,\n",
       "    'test_speed_se': 2640.572186637397,\n",
       "    'test_speed_short': 2080.5299999999997,\n",
       "    'test_speed_short_se': 666.3625683611522}},\n",
       "  'num_model_parameters': 3212749824,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.48607447615711563,\n",
       "      'macro_f1': 0.5720512786752403},\n",
       "     {'mcc': 0.44677122352585574, 'macro_f1': 0.5117949240813008},\n",
       "     {'mcc': 0.4637436728544096, 'macro_f1': 0.5757500318375831},\n",
       "     {'mcc': 0.4702884959871552, 'macro_f1': 0.5702270184576633},\n",
       "     {'mcc': 0.4632321879478897, 'macro_f1': 0.5666522021856718},\n",
       "     {'mcc': 0.4614647527520791, 'macro_f1': 0.5564511037013116},\n",
       "     {'mcc': 0.46727071029689643, 'macro_f1': 0.5464387144134899},\n",
       "     {'mcc': 0.47981884751804177, 'macro_f1': 0.5539951903707129},\n",
       "     {'mcc': 0.4402752800232859, 'macro_f1': 0.5193531597907536},\n",
       "     {'mcc': 0.4293657449302353, 'macro_f1': 0.5399258420940433}]},\n",
       "   'total': {'test_mcc': 46.083053919929654,\n",
       "    'test_mcc_se': 1.0841423969450124,\n",
       "    'test_macro_f1': 55.126394656077714,\n",
       "    'test_macro_f1_se': 1.3689448899330048}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.5630630630630631,\n",
       "      'micro_f1': 0.35518945634266885},\n",
       "     {'micro_f1_no_misc': 0.5272914521112256, 'micro_f1': 0.3776559287183002},\n",
       "     {'micro_f1_no_misc': 0.574798927613941, 'micro_f1': 0.3647514525500323},\n",
       "     {'micro_f1_no_misc': 0.5212876427829699, 'micro_f1': 0.304950495049505},\n",
       "     {'micro_f1_no_misc': 0.5913134484563056, 'micro_f1': 0.3859987154784843},\n",
       "     {'micro_f1_no_misc': 0.5370871683811586, 'micro_f1': 0.33191489361702126},\n",
       "     {'micro_f1_no_misc': 0.5230769230769231, 'micro_f1': 0.32760180995475113},\n",
       "     {'micro_f1_no_misc': 0.5785288270377733, 'micro_f1': 0.38890680425669133},\n",
       "     {'micro_f1_no_misc': 0.5911542610571737, 'micro_f1': 0.4025378921395841},\n",
       "     {'micro_f1_no_misc': 0.5671641791044777,\n",
       "      'micro_f1': 0.36665581243894496}]},\n",
       "   'total': {'test_micro_f1_no_misc': 55.74765892685012,\n",
       "    'test_micro_f1_no_misc_se': 1.7245134864535188,\n",
       "    'test_micro_f1': 36.061632605459835,\n",
       "    'test_micro_f1_se': 1.9145925733527132}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8320,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.25296199196444846,\n",
       "      'macro_f1': 0.5397851538407907},\n",
       "     {'mcc': 0.13683009122559472, 'macro_f1': 0.397836816129371},\n",
       "     {'mcc': 0.21963424796200956, 'macro_f1': 0.4597041853181965},\n",
       "     {'mcc': 0.16911539949122434, 'macro_f1': 0.41925084840072185},\n",
       "     {'mcc': 0.2590476762057309, 'macro_f1': 0.5262672078366597},\n",
       "     {'mcc': 0.2809911476997076, 'macro_f1': 0.5289792291275277},\n",
       "     {'mcc': 0.21553590991178423, 'macro_f1': 0.4726558322289647},\n",
       "     {'mcc': 0.1951363251303547, 'macro_f1': 0.4655138177341299},\n",
       "     {'mcc': 0.20593977132027785, 'macro_f1': 0.46077206999919496},\n",
       "     {'mcc': 0.2822185928562783, 'macro_f1': 0.5637982353849512}]},\n",
       "   'total': {'test_mcc': 22.174111537674108,\n",
       "    'test_mcc_se': 2.9591314541471165,\n",
       "    'test_macro_f1': 48.34563396000508,\n",
       "    'test_macro_f1_se': 3.363444350545693}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'em': 58.40433772269559,\n",
       "      'f1': 63.40359614565649},\n",
       "     {'em': 58.29457364341085, 'f1': 63.252927368522414},\n",
       "     {'em': 58.809891808346215, 'f1': 63.875100084528185},\n",
       "     {'em': 58.25545171339564, 'f1': 64.34806321282402},\n",
       "     {'em': 56.447876447876446, 'f1': 62.50125635839917},\n",
       "     {'em': 55.82112567463377, 'f1': 61.617433216598656},\n",
       "     {'em': 56.87167805618831, 'f1': 63.56082245603879},\n",
       "     {'em': 59.1155934833204, 'f1': 64.30880342827585},\n",
       "     {'em': 57.1764705882353, 'f1': 62.483099906629285},\n",
       "     {'em': 58.307453416149066, 'f1': 63.920139531438366}]},\n",
       "   'total': {'test_em': 57.750445255425156,\n",
       "    'test_em_se': 0.6788267145856897,\n",
       "    'test_f1': 63.327124170891125,\n",
       "    'test_f1_se': 0.5482319784284982}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8224,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6725231672171503,\n",
       "      'rouge_l': 0.22214115864519107},\n",
       "     {'bertscore': 0.6807525188487489, 'rouge_l': 0.23987588833778262},\n",
       "     {'bertscore': 0.6469005684921285, 'rouge_l': 0.19265978398040187},\n",
       "     {'bertscore': 0.6722417559794849, 'rouge_l': 0.22222401911917505},\n",
       "     {'bertscore': 0.6398101585073164, 'rouge_l': 0.19918474855866947},\n",
       "     {'bertscore': 0.6713841050368501, 'rouge_l': 0.2203194409046185},\n",
       "     {'bertscore': 0.655872098839609, 'rouge_l': 0.18823205882569174},\n",
       "     {'bertscore': 0.6621481580368709, 'rouge_l': 0.20064560479351934},\n",
       "     {'bertscore': 0.665483837670763, 'rouge_l': 0.20867867151332561},\n",
       "     {'bertscore': 0.6691103563207434, 'rouge_l': 0.21422348712289946}]},\n",
       "   'total': {'test_bertscore': 66.36226724949665,\n",
       "    'test_bertscore_se': 0.7866273486113065,\n",
       "    'test_rouge_l': 21.08184861801275,\n",
       "    'test_rouge_l_se': 0.9881932262855728}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8448,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5936370783194204, 'accuracy': 0.6875},\n",
       "     {'mcc': 0.6180047679683889, 'accuracy': 0.70703125},\n",
       "     {'mcc': 0.5758209643136233, 'accuracy': 0.671875},\n",
       "     {'mcc': 0.5760329246623337, 'accuracy': 0.6748046875},\n",
       "     {'mcc': 0.6227981772884429, 'accuracy': 0.7099609375},\n",
       "     {'mcc': 0.6345755865987616, 'accuracy': 0.71875},\n",
       "     {'mcc': 0.6092349285437448, 'accuracy': 0.6962890625},\n",
       "     {'mcc': 0.5764940037351817, 'accuracy': 0.6767578125},\n",
       "     {'mcc': 0.5829244980797267, 'accuracy': 0.67578125},\n",
       "     {'mcc': 0.5923885874296083, 'accuracy': 0.6884765625}]},\n",
       "   'total': {'test_mcc': 59.81911516939233,\n",
       "    'test_mcc_se': 1.3379041285178823,\n",
       "    'test_accuracy': 69.072265625,\n",
       "    'test_accuracy_se': 1.0319580195888751}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5645610326108025,\n",
       "      'accuracy': 0.7109375},\n",
       "     {'mcc': 0.5395510414706138, 'accuracy': 0.693359375},\n",
       "     {'mcc': 0.5061889395703927, 'accuracy': 0.671875},\n",
       "     {'mcc': 0.5052771759208201, 'accuracy': 0.669921875},\n",
       "     {'mcc': 0.537499232602917, 'accuracy': 0.69140625},\n",
       "     {'mcc': 0.5122599780100019, 'accuracy': 0.673828125},\n",
       "     {'mcc': 0.5780890906035653, 'accuracy': 0.716796875},\n",
       "     {'mcc': 0.5397937416493188, 'accuracy': 0.68359375},\n",
       "     {'mcc': 0.5523111298970127, 'accuracy': 0.69921875},\n",
       "     {'mcc': 0.5730487911618126, 'accuracy': 0.708984375}]},\n",
       "   'total': {'test_mcc': 54.085801534972575,\n",
       "    'test_mcc_se': 1.6547937495395109,\n",
       "    'test_accuracy': 69.19921875,\n",
       "    'test_accuracy_se': 1.055418374589436}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.3556580527694889,\n",
       "      'accuracy': 0.5029296875},\n",
       "     {'mcc': 0.40938896772591676, 'accuracy': 0.55029296875},\n",
       "     {'mcc': 0.38949398090870463, 'accuracy': 0.52880859375},\n",
       "     {'mcc': 0.3845702260929847, 'accuracy': 0.529296875},\n",
       "     {'mcc': 0.4038746651746102, 'accuracy': 0.5439453125},\n",
       "     {'mcc': 0.3907604067136275, 'accuracy': 0.5361328125},\n",
       "     {'mcc': 0.44488927012577495, 'accuracy': 0.578125},\n",
       "     {'mcc': 0.41144370372558886, 'accuracy': 0.5419921875},\n",
       "     {'mcc': 0.43839853366616427, 'accuracy': 0.56396484375},\n",
       "     {'mcc': 0.4156590440989671, 'accuracy': 0.5625}]},\n",
       "   'total': {'test_mcc': 40.441368510018286,\n",
       "    'test_mcc_se': 1.6233789038835866,\n",
       "    'test_accuracy': 54.3798828125,\n",
       "    'test_accuracy_se': 1.330013307649838}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results': {'raw': {'test': [{'test_speed': 2128.7200000000003,\n",
       "      'test_speed_short': 304.6},\n",
       "     {'test_speed': 3805.3799999999997, 'test_speed_short': 527.4},\n",
       "     {'test_speed': 5389.34, 'test_speed_short': 1003.68},\n",
       "     {'test_speed': 6204.94, 'test_speed_short': 1151.22},\n",
       "     {'test_speed': 6705.36, 'test_speed_short': 1372.5},\n",
       "     {'test_speed': 7832.5, 'test_speed_short': 1739.1000000000001},\n",
       "     {'test_speed': 7778.08, 'test_speed_short': 1925.48},\n",
       "     {'test_speed': 8211.18, 'test_speed_short': 2132.82},\n",
       "     {'test_speed': 9025.0, 'test_speed_short': 2345.4},\n",
       "     {'test_speed': 8813.98, 'test_speed_short': 2560.74}]},\n",
       "   'total': {'test_speed': 6589.447999999999,\n",
       "    'test_speed_se': 1396.959974435267,\n",
       "    'test_speed_short': 1506.294,\n",
       "    'test_speed_short_se': 472.81236162017854}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5184707385073467,\n",
       "      'macro_f1': 0.6679957645105746},\n",
       "     {'mcc': 0.5332368057632823, 'macro_f1': 0.6677638417696129},\n",
       "     {'mcc': 0.5136245359141334, 'macro_f1': 0.6696546017286815},\n",
       "     {'mcc': 0.509936563354307, 'macro_f1': 0.6603766983162923},\n",
       "     {'mcc': 0.5481813783107395, 'macro_f1': 0.696000267065509},\n",
       "     {'mcc': 0.5619295910123131, 'macro_f1': 0.6997646049622124},\n",
       "     {'mcc': 0.5249631251196811, 'macro_f1': 0.6600191396984878},\n",
       "     {'mcc': 0.530552042705224, 'macro_f1': 0.6631966558979637},\n",
       "     {'mcc': 0.46553855284916823, 'macro_f1': 0.5959032466152633},\n",
       "     {'mcc': 0.4958317775325244, 'macro_f1': 0.6465772250571682}]},\n",
       "   'total': {'test_mcc': 52.02265111068719,\n",
       "    'test_mcc_se': 1.67301420422098,\n",
       "    'test_macro_f1': 66.27252045621765,\n",
       "    'test_macro_f1_se': 1.7675440422275706}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.5799903334944416,\n",
       "      'micro_f1': 0.30550529852675107},\n",
       "     {'micro_f1_no_misc': 0.4573705179282868, 'micro_f1': 0.23663810689514483},\n",
       "     {'micro_f1_no_misc': 0.40209508460918614,\n",
       "      'micro_f1': 0.19987934848180172},\n",
       "     {'micro_f1_no_misc': 0.498067840274796, 'micro_f1': 0.22386895475819035},\n",
       "     {'micro_f1_no_misc': 0.5826001955034212, 'micro_f1': 0.2754098360655738},\n",
       "     {'micro_f1_no_misc': 0.5693430656934306, 'micro_f1': 0.2647610121836926},\n",
       "     {'micro_f1_no_misc': 0.4892812105926861, 'micro_f1': 0.22568553955415271},\n",
       "     {'micro_f1_no_misc': 0.5227177990829512, 'micro_f1': 0.29519610118356926},\n",
       "     {'micro_f1_no_misc': 0.46493837654058645,\n",
       "      'micro_f1': 0.25406551967947205},\n",
       "     {'micro_f1_no_misc': 0.5701624815361891,\n",
       "      'micro_f1': 0.2779179087365283}]},\n",
       "   'total': {'test_micro_f1_no_misc': 51.365669052559745,\n",
       "    'test_micro_f1_no_misc_se': 3.829342393679035,\n",
       "    'test_micro_f1': 25.589276260648763,\n",
       "    'test_micro_f1_se': 2.1069781159123466}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8320,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.13964896768511326,\n",
       "      'macro_f1': 0.4050693685689698},\n",
       "     {'mcc': 0.1499919623383007, 'macro_f1': 0.4975951710141911},\n",
       "     {'mcc': 0.23969023837551093, 'macro_f1': 0.6197524669077719},\n",
       "     {'mcc': 0.1997907528291508, 'macro_f1': 0.5468871237640577},\n",
       "     {'mcc': 0.15936994626060677, 'macro_f1': 0.5481036280434582},\n",
       "     {'mcc': 0.19521600080464485, 'macro_f1': 0.5782537067545305},\n",
       "     {'mcc': 0.17839154509749688, 'macro_f1': 0.465764160224877},\n",
       "     {'mcc': 0.23674444380531495, 'macro_f1': 0.5545028932794456},\n",
       "     {'mcc': 0.130557378033124, 'macro_f1': 0.4320518359039449},\n",
       "     {'mcc': 0.22054084621718514, 'macro_f1': 0.5698846931886267}]},\n",
       "   'total': {'test_mcc': 18.499420814464482,\n",
       "    'test_mcc_se': 2.4620910957393303,\n",
       "    'test_macro_f1': 52.17865047649873,\n",
       "    'test_macro_f1_se': 4.278771174980301}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'em': 51.7428350116189,\n",
       "      'f1': 61.406561851952944},\n",
       "     {'em': 55.968992248062015, 'f1': 63.853849348793666},\n",
       "     {'em': 52.936630602782074, 'f1': 62.283343201263925},\n",
       "     {'em': 50.07788161993769, 'f1': 61.19203918269331},\n",
       "     {'em': 53.204633204633204, 'f1': 63.03484777770486},\n",
       "     {'em': 49.65304548959136, 'f1': 60.85574281796322},\n",
       "     {'em': 53.53075170842825, 'f1': 62.11281069060598},\n",
       "     {'em': 51.04732350659426, 'f1': 61.08039217357879},\n",
       "     {'em': 54.11764705882353, 'f1': 62.2211544446838},\n",
       "     {'em': 52.09627329192546, 'f1': 62.806307305530844}]},\n",
       "   'total': {'test_em': 52.437601374239684,\n",
       "    'test_em_se': 1.1900664774077505,\n",
       "    'test_f1': 62.08470487947712,\n",
       "    'test_f1_se': 0.5983599306487652}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8224,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.669816038251156,\n",
       "      'rouge_l': 0.2173166505142002},\n",
       "     {'bertscore': 0.6715888144826749, 'rouge_l': 0.2245842152450252},\n",
       "     {'bertscore': 0.639368471558555, 'rouge_l': 0.20413198783281256},\n",
       "     {'bertscore': 0.6699016774946358, 'rouge_l': 0.22083904345670727},\n",
       "     {'bertscore': 0.6335730952268932, 'rouge_l': 0.18587823012542173},\n",
       "     {'bertscore': 0.6682230423029978, 'rouge_l': 0.21309382709570962},\n",
       "     {'bertscore': 0.6690013941406505, 'rouge_l': 0.2150999992927722},\n",
       "     {'bertscore': 0.6684635696728947, 'rouge_l': 0.21707413950146887},\n",
       "     {'bertscore': 0.6614573605911573, 'rouge_l': 0.20112701510678455},\n",
       "     {'bertscore': 0.6661325375753222, 'rouge_l': 0.21097765373762356}]},\n",
       "   'total': {'test_bertscore': 66.17526001296937,\n",
       "    'test_bertscore_se': 0.8473285218049452,\n",
       "    'test_rouge_l': 21.101227619085254,\n",
       "    'test_rouge_l_se': 0.7021661106099834}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8448,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.41780716959842024,\n",
       "      'accuracy': 0.556640625},\n",
       "     {'mcc': 0.41852714960361687, 'accuracy': 0.5546875},\n",
       "     {'mcc': 0.3912882072468906, 'accuracy': 0.5380859375},\n",
       "     {'mcc': 0.41102740827108575, 'accuracy': 0.5556640625},\n",
       "     {'mcc': 0.38863685684932764, 'accuracy': 0.5341796875},\n",
       "     {'mcc': 0.43182528857328034, 'accuracy': 0.5703125},\n",
       "     {'mcc': 0.4399543066514609, 'accuracy': 0.572265625},\n",
       "     {'mcc': 0.4195925180495246, 'accuracy': 0.560546875},\n",
       "     {'mcc': 0.3901253719943335, 'accuracy': 0.5361328125},\n",
       "     {'mcc': 0.4264675562506547, 'accuracy': 0.56640625}]},\n",
       "   'total': {'test_mcc': 41.35251833088594,\n",
       "    'test_mcc_se': 1.1219023189164776,\n",
       "    'test_accuracy': 55.44921874999999,\n",
       "    'test_accuracy_se': 0.8691145926969096}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5284380115281809,\n",
       "      'accuracy': 0.681640625},\n",
       "     {'mcc': 0.5050169057281477, 'accuracy': 0.66796875},\n",
       "     {'mcc': 0.5355531954319913, 'accuracy': 0.6875},\n",
       "     {'mcc': 0.5223241200295258, 'accuracy': 0.6796875},\n",
       "     {'mcc': 0.47758233323104565, 'accuracy': 0.650390625},\n",
       "     {'mcc': 0.5383439687521514, 'accuracy': 0.693359375},\n",
       "     {'mcc': 0.5732457577402537, 'accuracy': 0.71484375},\n",
       "     {'mcc': 0.5199737748554207, 'accuracy': 0.6796875},\n",
       "     {'mcc': 0.5166038399356004, 'accuracy': 0.67578125},\n",
       "     {'mcc': 0.5067678386092972, 'accuracy': 0.669921875}]},\n",
       "   'total': {'test_mcc': 52.23849745841614,\n",
       "    'test_mcc_se': 1.5520772610806033,\n",
       "    'test_accuracy': 68.0078125,\n",
       "    'test_accuracy_se': 1.0519413837820024}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.3639091287007454,\n",
       "      'accuracy': 0.5224609375},\n",
       "     {'mcc': 0.387467636298574, 'accuracy': 0.54052734375},\n",
       "     {'mcc': 0.36445995022282335, 'accuracy': 0.52392578125},\n",
       "     {'mcc': 0.36805710904758987, 'accuracy': 0.52587890625},\n",
       "     {'mcc': 0.3804143497056206, 'accuracy': 0.53515625},\n",
       "     {'mcc': 0.36030133163332995, 'accuracy': 0.52001953125},\n",
       "     {'mcc': 0.3844231258443388, 'accuracy': 0.53857421875},\n",
       "     {'mcc': 0.39720828910230804, 'accuracy': 0.54736328125},\n",
       "     {'mcc': 0.3912360736173816, 'accuracy': 0.54345703125},\n",
       "     {'mcc': 0.37049951249423135, 'accuracy': 0.52880859375}]},\n",
       "   'total': {'test_mcc': 37.679765066669425,\n",
       "    'test_mcc_se': 0.8045990852383786,\n",
       "    'test_accuracy': 53.26171875,\n",
       "    'test_accuracy_se': 0.5976317680624773}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results': {'raw': {'test': [{'test_speed': 2168.44,\n",
       "      'test_speed_short': 296.12},\n",
       "     {'test_speed': 3874.7799999999997, 'test_speed_short': 522.8},\n",
       "     {'test_speed': 4700.16, 'test_speed_short': 955.6999999999999},\n",
       "     {'test_speed': 6132.280000000001, 'test_speed_short': 1188.6299999999999},\n",
       "     {'test_speed': 6373.2, 'test_speed_short': 1313.2},\n",
       "     {'test_speed': 7111.04, 'test_speed_short': 1825.5800000000002},\n",
       "     {'test_speed': 7735.68, 'test_speed_short': 2001.1299999999999},\n",
       "     {'test_speed': 8346.32, 'test_speed_short': 2197.88},\n",
       "     {'test_speed': 8314.880000000001, 'test_speed_short': 2386.63},\n",
       "     {'test_speed': 8659.199999999999, 'test_speed_short': 2589.4}]},\n",
       "   'total': {'test_speed': 6341.598,\n",
       "    'test_speed_se': 1339.876715978997,\n",
       "    'test_speed_short': 1527.707,\n",
       "    'test_speed_short_se': 490.729158830796}},\n",
       "  'num_model_parameters': 8028033024,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.550739651578351,\n",
       "      'macro_f1': 0.6937341958454922},\n",
       "     {'mcc': 0.5592335509989161, 'macro_f1': 0.6928691114239345},\n",
       "     {'mcc': 0.5795910100277558, 'macro_f1': 0.7210187506584175},\n",
       "     {'mcc': 0.5544155965121577, 'macro_f1': 0.6975815813434307},\n",
       "     {'mcc': 0.5627459350196324, 'macro_f1': 0.7011979604082371},\n",
       "     {'mcc': 0.5779243378666301, 'macro_f1': 0.7155890249764215},\n",
       "     {'mcc': 0.5793943965946543, 'macro_f1': 0.7049626581976242},\n",
       "     {'mcc': 0.5464403722672116, 'macro_f1': 0.6613892426579002},\n",
       "     {'mcc': 0.5790197695251713, 'macro_f1': 0.7120874019649576},\n",
       "     {'mcc': 0.5497976815782402, 'macro_f1': 0.682484781513993}]},\n",
       "   'total': {'test_mcc': 56.393023019687206,\n",
       "    'test_mcc_se': 0.8522268784800228,\n",
       "    'test_macro_f1': 69.82914708990407,\n",
       "    'test_macro_f1_se': 1.0777654312545752}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.6502095947834188,\n",
       "      'micro_f1': 0.43341553637484587},\n",
       "     {'micro_f1_no_misc': 0.5958527295810411, 'micro_f1': 0.43728018757327086},\n",
       "     {'micro_f1_no_misc': 0.5117289313640313, 'micro_f1': 0.3550869193502423},\n",
       "     {'micro_f1_no_misc': 0.6422018348623854, 'micro_f1': 0.4118476727785613},\n",
       "     {'micro_f1_no_misc': 0.6257283729269385, 'micro_f1': 0.4024289263041679},\n",
       "     {'micro_f1_no_misc': 0.6816059757236228, 'micro_f1': 0.45161290322580644},\n",
       "     {'micro_f1_no_misc': 0.5535858178887993, 'micro_f1': 0.346487962273517},\n",
       "     {'micro_f1_no_misc': 0.6540934419202743, 'micro_f1': 0.43101482326111745},\n",
       "     {'micro_f1_no_misc': 0.6002716161158895, 'micro_f1': 0.43205128205128207},\n",
       "     {'micro_f1_no_misc': 0.5997334517992003,\n",
       "      'micro_f1': 0.39497206703910615}]},\n",
       "   'total': {'test_micro_f1_no_misc': 61.15011766965601,\n",
       "    'test_micro_f1_no_misc_se': 3.1462063606859267,\n",
       "    'test_micro_f1': 40.96198280231917,\n",
       "    'test_micro_f1_se': 2.1948855029981384}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8320,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.3774114381456481,\n",
       "      'macro_f1': 0.6676666472137085},\n",
       "     {'mcc': 0.37567817444669904, 'macro_f1': 0.6796130986668736},\n",
       "     {'mcc': 0.4045784988666319, 'macro_f1': 0.691437526898076},\n",
       "     {'mcc': 0.3813209226022132, 'macro_f1': 0.6823769165135904},\n",
       "     {'mcc': 0.3186138812659614, 'macro_f1': 0.6388565709146112},\n",
       "     {'mcc': 0.3945177358329048, 'macro_f1': 0.6919741210132607},\n",
       "     {'mcc': 0.3637828952926766, 'macro_f1': 0.6357623434739981},\n",
       "     {'mcc': 0.40618279753192976, 'macro_f1': 0.70267131242741},\n",
       "     {'mcc': 0.36262090932768615, 'macro_f1': 0.6511583757602134},\n",
       "     {'mcc': 0.3905777309119322, 'macro_f1': 0.694587639627731}]},\n",
       "   'total': {'test_mcc': 37.75284984224283,\n",
       "    'test_mcc_se': 1.5885028292400456,\n",
       "    'test_macro_f1': 67.36104552509474,\n",
       "    'test_macro_f1_se': 1.4944382323737466}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'em': 54.6862896979086,\n",
       "      'f1': 63.87511314990903},\n",
       "     {'em': 60.0, 'f1': 66.44821355714862},\n",
       "     {'em': 58.34621329211747, 'f1': 66.26433742780438},\n",
       "     {'em': 55.45171339563863, 'f1': 65.55055830035205},\n",
       "     {'em': 59.45945945945946, 'f1': 66.78519617571203},\n",
       "     {'em': 55.66692367000771, 'f1': 63.93712338671046},\n",
       "     {'em': 59.757023538344725, 'f1': 66.29748546513814},\n",
       "     {'em': 59.73622963537626, 'f1': 66.84195943699427},\n",
       "     {'em': 59.13725490196079, 'f1': 66.42987861811386},\n",
       "     {'em': 58.69565217391305, 'f1': 66.2405060838564}]},\n",
       "   'total': {'test_em': 58.09367597647266,\n",
       "    'test_em_se': 1.2560106089820373,\n",
       "    'test_f1': 65.86703716017392,\n",
       "    'test_f1_se': 0.6765437970353189}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8224,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6819774847681401,\n",
       "      'rouge_l': 0.23979752068164994},\n",
       "     {'bertscore': 0.6834043916896917, 'rouge_l': 0.24726260283829063},\n",
       "     {'bertscore': 0.6514953300793422, 'rouge_l': 0.22500362869555263},\n",
       "     {'bertscore': 0.6861067005520454, 'rouge_l': 0.24987755585800364},\n",
       "     {'bertscore': 0.6415311851014849, 'rouge_l': 0.20084544271044297},\n",
       "     {'bertscore': 0.6833887189714005, 'rouge_l': 0.24351679843823637},\n",
       "     {'bertscore': 0.6831773575104307, 'rouge_l': 0.24307646609025685},\n",
       "     {'bertscore': 0.6852605931781, 'rouge_l': 0.24308060586493907},\n",
       "     {'bertscore': 0.6808077077730559, 'rouge_l': 0.23406317515993924},\n",
       "     {'bertscore': 0.6823581127973739, 'rouge_l': 0.23832750463601665}]},\n",
       "   'total': {'test_bertscore': 67.59507582421065,\n",
       "    'test_bertscore_se': 0.9770906139371104,\n",
       "    'test_rouge_l': 23.64851300973328,\n",
       "    'test_rouge_l_se': 0.8896245200666768}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8448,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.6588921895172084,\n",
       "      'accuracy': 0.7412109375},\n",
       "     {'mcc': 0.662629834397691, 'accuracy': 0.744140625},\n",
       "     {'mcc': 0.6586217042692106, 'accuracy': 0.7421875},\n",
       "     {'mcc': 0.6278037406460693, 'accuracy': 0.71875},\n",
       "     {'mcc': 0.6725641979462537, 'accuracy': 0.7490234375},\n",
       "     {'mcc': 0.6954686375373209, 'accuracy': 0.76953125},\n",
       "     {'mcc': 0.6376026041948465, 'accuracy': 0.7265625},\n",
       "     {'mcc': 0.6541184897028299, 'accuracy': 0.73828125},\n",
       "     {'mcc': 0.6700231062545792, 'accuracy': 0.7490234375},\n",
       "     {'mcc': 0.6752394426663887, 'accuracy': 0.7548828125}]},\n",
       "   'total': {'test_mcc': 66.12963947132397,\n",
       "    'test_mcc_se': 1.1894718417774748,\n",
       "    'test_accuracy': 74.3359375,\n",
       "    'test_accuracy_se': 0.8770408058276452}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.7596927487439394,\n",
       "      'accuracy': 0.83984375},\n",
       "     {'mcc': 0.6964373111955477, 'accuracy': 0.798828125},\n",
       "     {'mcc': 0.7745205780705804, 'accuracy': 0.849609375},\n",
       "     {'mcc': 0.7481547195356397, 'accuracy': 0.83203125},\n",
       "     {'mcc': 0.6850227685435433, 'accuracy': 0.791015625},\n",
       "     {'mcc': 0.7569716630135677, 'accuracy': 0.83984375},\n",
       "     {'mcc': 0.7527150251593753, 'accuracy': 0.8359375},\n",
       "     {'mcc': 0.7466582678481238, 'accuracy': 0.83203125},\n",
       "     {'mcc': 0.7150726213132608, 'accuracy': 0.810546875},\n",
       "     {'mcc': 0.7315846891760063, 'accuracy': 0.822265625}]},\n",
       "   'total': {'test_mcc': 73.66830392599584,\n",
       "    'test_mcc_se': 1.8061315888363954,\n",
       "    'test_accuracy': 82.51953125,\n",
       "    'test_accuracy_se': 1.1905543971939927}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.6931808568976738,\n",
       "      'accuracy': 0.76904296875},\n",
       "     {'mcc': 0.6961541244324991, 'accuracy': 0.7705078125},\n",
       "     {'mcc': 0.6883562358538876, 'accuracy': 0.76611328125},\n",
       "     {'mcc': 0.7031279604287183, 'accuracy': 0.7763671875},\n",
       "     {'mcc': 0.7205249323951286, 'accuracy': 0.78857421875},\n",
       "     {'mcc': 0.6525453571209248, 'accuracy': 0.73779296875},\n",
       "     {'mcc': 0.6631087110456444, 'accuracy': 0.74462890625},\n",
       "     {'mcc': 0.6867062887608667, 'accuracy': 0.76318359375},\n",
       "     {'mcc': 0.7015329062953098, 'accuracy': 0.77294921875},\n",
       "     {'mcc': 0.7175428008296935, 'accuracy': 0.78857421875}]},\n",
       "   'total': {'test_mcc': 69.22780174060347,\n",
       "    'test_mcc_se': 1.3279501525741395,\n",
       "    'test_accuracy': 76.77734375,\n",
       "    'test_accuracy_se': 1.0191571525239858}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results': {'raw': {'test': [{'test_speed': 1142.64,\n",
       "      'test_speed_short': 148.28},\n",
       "     {'test_speed': 1672.58, 'test_speed_short': 265.59999999999997},\n",
       "     {'test_speed': 1901.28, 'test_speed_short': 500.84},\n",
       "     {'test_speed': 2410.92, 'test_speed_short': 615.23},\n",
       "     {'test_speed': 2404.6400000000003, 'test_speed_short': 722.4},\n",
       "     {'test_speed': 2493.2, 'test_speed_short': 933.88},\n",
       "     {'test_speed': 2812.4, 'test_speed_short': 1020.0699999999999},\n",
       "     {'test_speed': 2714.72, 'test_speed_short': 1129.76},\n",
       "     {'test_speed': 2622.7599999999998, 'test_speed_short': 1233.21},\n",
       "     {'test_speed': 2706.0, 'test_speed_short': 1336.5}]},\n",
       "   'total': {'test_speed': 2288.1139999999996,\n",
       "    'test_speed_se': 336.6308078017931,\n",
       "    'test_speed_short': 790.577,\n",
       "    'test_speed_short_se': 252.16400874360798}},\n",
       "  'num_model_parameters': 32296476672,\n",
       "  'max_sequence_length': 8193,\n",
       "  'vocabulary_size': 256000,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.4042605139096028,\n",
       "      'macro_f1': 0.45123413905724713},\n",
       "     {'mcc': 0.4073461133903323, 'macro_f1': 0.4530478592062736},\n",
       "     {'mcc': 0.3882688581405336, 'macro_f1': 0.4463134465593425},\n",
       "     {'mcc': 0.3906864934830422, 'macro_f1': 0.44551947309604273},\n",
       "     {'mcc': 0.3804565633960835, 'macro_f1': 0.43838368304193615},\n",
       "     {'mcc': 0.3926070755341691, 'macro_f1': 0.4447659232469359},\n",
       "     {'mcc': 0.39299487295639873, 'macro_f1': 0.44650229215710563},\n",
       "     {'mcc': 0.3926476505911303, 'macro_f1': 0.4466560559768129},\n",
       "     {'mcc': 0.4119672504320519, 'macro_f1': 0.4546389373649837},\n",
       "     {'mcc': 0.4039656251540077, 'macro_f1': 0.45072407598378184}]},\n",
       "   'total': {'test_mcc': 39.65201016987352,\n",
       "    'test_mcc_se': 0.610806532847957,\n",
       "    'test_macro_f1': 44.77785885690462,\n",
       "    'test_macro_f1_se': 0.294309068867731}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.32814197754436797,\n",
       "      'micro_f1': 0.27224249228178504},\n",
       "     {'micro_f1_no_misc': 0.24715647094989243,\n",
       "      'micro_f1': 0.22709056906224953},\n",
       "     {'micro_f1_no_misc': 0.19264069264069264,\n",
       "      'micro_f1': 0.18482309124767227},\n",
       "     {'micro_f1_no_misc': 0.2653006201132381, 'micro_f1': 0.2570642660665166},\n",
       "     {'micro_f1_no_misc': 0.3626647666547916, 'micro_f1': 0.3349374398460058},\n",
       "     {'micro_f1_no_misc': 0.3628972653362897, 'micro_f1': 0.327433628318584},\n",
       "     {'micro_f1_no_misc': 0.2823061630218688, 'micro_f1': 0.2274230475705927},\n",
       "     {'micro_f1_no_misc': 0.2767801857585139, 'micro_f1': 0.21422060164083861},\n",
       "     {'micro_f1_no_misc': 0.24257899776571976,\n",
       "      'micro_f1': 0.23522595596755505},\n",
       "     {'micro_f1_no_misc': 0.3325396825396825,\n",
       "      'micro_f1': 0.28980679546968685}]},\n",
       "   'total': {'test_micro_f1_no_misc': 28.930068223250576,\n",
       "    'test_micro_f1_no_misc_se': 3.4731839280874492,\n",
       "    'test_micro_f1': 25.702678874714863,\n",
       "    'test_micro_f1_se': 3.0383034076124344}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131200,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.08375344713902443,\n",
       "      'macro_f1': 0.37656934189623703},\n",
       "     {'mcc': 0.07490666127435873, 'macro_f1': 0.3991168865223947},\n",
       "     {'mcc': 0.1251288725632889, 'macro_f1': 0.4828603199621763},\n",
       "     {'mcc': 0.10010320608166931, 'macro_f1': 0.40153609831029186},\n",
       "     {'mcc': 0.09842359647067078, 'macro_f1': 0.4290872950045883},\n",
       "     {'mcc': 0.11826952056921543, 'macro_f1': 0.4522235699780573},\n",
       "     {'mcc': 0.07323047848821716, 'macro_f1': 0.3710482881525421},\n",
       "     {'mcc': 0.151174108525155, 'macro_f1': 0.4781085530226424},\n",
       "     {'mcc': 0.10100744276021359, 'macro_f1': 0.3998294970161978},\n",
       "     {'mcc': 0.13007312186251677, 'macro_f1': 0.4692922696105245}]},\n",
       "   'total': {'test_mcc': 10.5607045573433,\n",
       "    'test_mcc_se': 1.571775547246954,\n",
       "    'test_macro_f1': 42.596721194756526,\n",
       "    'test_macro_f1_se': 2.6124327421270124}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'em': 53.29202168861348,\n",
       "      'f1': 61.01037904143104},\n",
       "     {'em': 54.8062015503876, 'f1': 62.472972579855664},\n",
       "     {'em': 52.936630602782074, 'f1': 60.77260112065308},\n",
       "     {'em': 53.271028037383175, 'f1': 61.34313043308365},\n",
       "     {'em': 53.05019305019305, 'f1': 61.049514463048226},\n",
       "     {'em': 51.734772552043175, 'f1': 59.36478820278297},\n",
       "     {'em': 52.69552012148823, 'f1': 61.05221754290486},\n",
       "     {'em': 53.76260667183863, 'f1': 61.590797247527064},\n",
       "     {'em': 53.568627450980394, 'f1': 60.634220876016485},\n",
       "     {'em': 53.41614906832298, 'f1': 61.197839060119804}]},\n",
       "   'total': {'test_em': 53.253375079403284,\n",
       "    'test_em_se': 0.4870396139496962,\n",
       "    'test_f1': 61.048846056742285,\n",
       "    'test_f1_se': 0.4852475755344001}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131104,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6710519481130177,\n",
       "      'rouge_l': 0.22441745295235063},\n",
       "     {'bertscore': 0.6726573065388948, 'rouge_l': 0.22955770886154359},\n",
       "     {'bertscore': 0.627757709895377, 'rouge_l': 0.1883878760495149},\n",
       "     {'bertscore': 0.6555991127243033, 'rouge_l': 0.209461944371444},\n",
       "     {'bertscore': 0.6493648399628, 'rouge_l': 0.20527205777480362},\n",
       "     {'bertscore': 0.667895835445961, 'rouge_l': 0.22073521814733577},\n",
       "     {'bertscore': 0.6607330682018073, 'rouge_l': 0.20345244164692067},\n",
       "     {'bertscore': 0.6686129025183618, 'rouge_l': 0.21914255280720715},\n",
       "     {'bertscore': 0.6531475613155635, 'rouge_l': 0.19733424912973707},\n",
       "     {'bertscore': 0.668442035879707, 'rouge_l': 0.22167672018376622}]},\n",
       "   'total': {'test_bertscore': 65.95262320595793,\n",
       "    'test_bertscore_se': 0.8537033683733533,\n",
       "    'test_rouge_l': 21.19438221924624,\n",
       "    'test_rouge_l_se': 0.8214294452915314}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131328,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5249109035011036,\n",
       "      'accuracy': 0.642578125},\n",
       "     {'mcc': 0.5536390805637154, 'accuracy': 0.6640625},\n",
       "     {'mcc': 0.5896033139185197, 'accuracy': 0.6884765625},\n",
       "     {'mcc': 0.5142384429566149, 'accuracy': 0.6318359375},\n",
       "     {'mcc': 0.519988339578778, 'accuracy': 0.6396484375},\n",
       "     {'mcc': 0.5559706359644475, 'accuracy': 0.6650390625},\n",
       "     {'mcc': 0.5411657902441624, 'accuracy': 0.654296875},\n",
       "     {'mcc': 0.550446733476786, 'accuracy': 0.662109375},\n",
       "     {'mcc': 0.5641377513489577, 'accuracy': 0.673828125},\n",
       "     {'mcc': 0.5479191627115648, 'accuracy': 0.65625}]},\n",
       "   'total': {'test_mcc': 54.6202015426465,\n",
       "    'test_mcc_se': 1.3958367240786267,\n",
       "    'test_accuracy': 65.78125,\n",
       "    'test_accuracy_se': 1.0449526945740508}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.33076906970295716,\n",
       "      'accuracy': 0.552734375},\n",
       "     {'mcc': 0.3299903888728159, 'accuracy': 0.552734375},\n",
       "     {'mcc': 0.29723530232811873, 'accuracy': 0.529296875},\n",
       "     {'mcc': 0.34704472602201497, 'accuracy': 0.56640625},\n",
       "     {'mcc': 0.3740852853736171, 'accuracy': 0.58203125},\n",
       "     {'mcc': 0.25972090498142975, 'accuracy': 0.51953125},\n",
       "     {'mcc': 0.3332938277849021, 'accuracy': 0.5546875},\n",
       "     {'mcc': 0.35868701367318573, 'accuracy': 0.57421875},\n",
       "     {'mcc': 0.2949348427100541, 'accuracy': 0.525390625},\n",
       "     {'mcc': 0.3635097679851021, 'accuracy': 0.58203125}]},\n",
       "   'total': {'test_mcc': 32.89271129434198,\n",
       "    'test_mcc_se': 2.208040137534972,\n",
       "    'test_accuracy': 55.39062500000001,\n",
       "    'test_accuracy_se': 1.424602085647271}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.20866456557091573,\n",
       "      'accuracy': 0.39599609375},\n",
       "     {'mcc': 0.18854351880840026, 'accuracy': 0.37158203125},\n",
       "     {'mcc': 0.19210681042644198, 'accuracy': 0.388671875},\n",
       "     {'mcc': 0.21459632070310916, 'accuracy': 0.3955078125},\n",
       "     {'mcc': 0.21480638682639372, 'accuracy': 0.40087890625},\n",
       "     {'mcc': 0.22988565218214668, 'accuracy': 0.4208984375},\n",
       "     {'mcc': 0.2288768475011086, 'accuracy': 0.40771484375},\n",
       "     {'mcc': 0.27406638353167734, 'accuracy': 0.44140625},\n",
       "     {'mcc': 0.22108762951487718, 'accuracy': 0.38232421875},\n",
       "     {'mcc': 0.17787403257753853, 'accuracy': 0.3720703125}]},\n",
       "   'total': {'test_mcc': 21.505081476426092,\n",
       "    'test_mcc_se': 1.676247565015713,\n",
       "    'test_accuracy': 39.7705078125,\n",
       "    'test_accuracy_se': 1.3426700875631101}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results': {'raw': {'test': [{'test_speed': 1885.1799999999998,\n",
       "      'test_speed_short': 306.5},\n",
       "     {'test_speed': 3789.1800000000003, 'test_speed_short': 523.98},\n",
       "     {'test_speed': 5435.320000000001, 'test_speed_short': 1006.4000000000001},\n",
       "     {'test_speed': 6227.48, 'test_speed_short': 1154.58},\n",
       "     {'test_speed': 6661.14, 'test_speed_short': 1370.0},\n",
       "     {'test_speed': 6993.82, 'test_speed_short': 1732.5},\n",
       "     {'test_speed': 7839.9, 'test_speed_short': 1942.5},\n",
       "     {'test_speed': 8204.76, 'test_speed_short': 2150.04},\n",
       "     {'test_speed': 9089.98, 'test_speed_short': 2357.1},\n",
       "     {'test_speed': 8741.800000000001, 'test_speed_short': 2538.2}]},\n",
       "   'total': {'test_speed': 6486.856,\n",
       "    'test_speed_se': 1409.6901482265052,\n",
       "    'test_speed_short': 1508.1799999999998,\n",
       "    'test_speed_short_se': 472.9852795231468}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 131073,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.0.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.4297958079894842,\n",
       "      'macro_f1': 0.5006008933767355},\n",
       "     {'mcc': 0.44723496082654435, 'macro_f1': 0.5424047598923557},\n",
       "     {'mcc': 0.425430855191408, 'macro_f1': 0.5064192832176623},\n",
       "     {'mcc': 0.43420726317659364, 'macro_f1': 0.5486705629589991},\n",
       "     {'mcc': 0.4119183198195351, 'macro_f1': 0.4930312001055908},\n",
       "     {'mcc': 0.4263151422373012, 'macro_f1': 0.48886545100148737},\n",
       "     {'mcc': 0.42257107006299854, 'macro_f1': 0.491935797686096},\n",
       "     {'mcc': 0.41238095694532056, 'macro_f1': 0.4784265519312962},\n",
       "     {'mcc': 0.45469017653027377, 'macro_f1': 0.5207416631184058},\n",
       "     {'mcc': 0.41548270498972245, 'macro_f1': 0.49334926735038076}]},\n",
       "   'total': {'test_mcc': 42.800272577691814,\n",
       "    'test_mcc_se': 0.8819453985487221,\n",
       "    'test_macro_f1': 50.644454306390095,\n",
       "    'test_macro_f1_se': 1.4566067010584074}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.3622828784119107,\n",
       "      'micro_f1': 0.20763087843833186},\n",
       "     {'micro_f1_no_misc': 0.25911286780852, 'micro_f1': 0.17121019108280258},\n",
       "     {'micro_f1_no_misc': 0.2843545508625818, 'micro_f1': 0.18521714121368998},\n",
       "     {'micro_f1_no_misc': 0.27356746765249534,\n",
       "      'micro_f1': 0.15932807330109444},\n",
       "     {'micro_f1_no_misc': 0.325895875591616, 'micro_f1': 0.21396895787139686},\n",
       "     {'micro_f1_no_misc': 0.3226116178588574, 'micro_f1': 0.23640661938534277},\n",
       "     {'micro_f1_no_misc': 0.3163972286374134, 'micro_f1': 0.17060855700239172},\n",
       "     {'micro_f1_no_misc': 0.3283735248845561, 'micro_f1': 0.20257150354237732},\n",
       "     {'micro_f1_no_misc': 0.40045248868778277, 'micro_f1': 0.2486631016042781},\n",
       "     {'micro_f1_no_misc': 0.2924095771777891,\n",
       "      'micro_f1': 0.18290598290598292}]},\n",
       "   'total': {'test_micro_f1_no_misc': 31.65458077573523,\n",
       "    'test_micro_f1_no_misc_se': 2.6264374186768866,\n",
       "    'test_micro_f1': 19.78511006347689,\n",
       "    'test_micro_f1_se': 1.8205611812410185}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.17075250298825773,\n",
       "      'macro_f1': 0.4696934974364505},\n",
       "     {'mcc': 0.09633155875489084, 'macro_f1': 0.39289961150023206},\n",
       "     {'mcc': 0.05401894027792268, 'macro_f1': 0.35468560058543547},\n",
       "     {'mcc': 0.12069019559202158, 'macro_f1': 0.43338813871760007},\n",
       "     {'mcc': 0.07567865836805936, 'macro_f1': 0.41311655250981},\n",
       "     {'mcc': 0.044895029194798465, 'macro_f1': 0.3448760235922028},\n",
       "     {'mcc': 0.10250311387711489, 'macro_f1': 0.5095968058917231},\n",
       "     {'mcc': 0.09463828542415405, 'macro_f1': 0.3815649892954269},\n",
       "     {'mcc': 0.09489926330885465, 'macro_f1': 0.4143154143154143},\n",
       "     {'mcc': 0.06792774600711955, 'macro_f1': 0.3808661800486618}]},\n",
       "   'total': {'test_mcc': 9.223352937931939,\n",
       "    'test_mcc_se': 2.232477527396482,\n",
       "    'test_macro_f1': 40.95002813892957,\n",
       "    'test_macro_f1_se': 3.1540676490267705}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'em': 51.123160340821066,\n",
       "      'f1': 59.39025404653717},\n",
       "     {'em': 52.248062015503876, 'f1': 59.869112841969006},\n",
       "     {'em': 51.31375579598145, 'f1': 59.08045733490985},\n",
       "     {'em': 50.700934579439256, 'f1': 58.78222507468615},\n",
       "     {'em': 50.03861003861004, 'f1': 58.678458530072824},\n",
       "     {'em': 49.03623747108713, 'f1': 57.659365796862},\n",
       "     {'em': 50.49354593773728, 'f1': 58.86556240784923},\n",
       "     {'em': 51.66795965865012, 'f1': 59.410064549707634},\n",
       "     {'em': 51.76470588235294, 'f1': 58.28515893207203},\n",
       "     {'em': 51.31987577639752, 'f1': 59.34177790462988}]},\n",
       "   'total': {'test_em': 50.97068474965807,\n",
       "    'test_em_se': 0.5815221459593318,\n",
       "    'test_f1': 58.93624374192958,\n",
       "    'test_f1_se': 0.39393515101160603}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6612957950565033,\n",
       "      'rouge_l': 0.20419179626672992},\n",
       "     {'bertscore': 0.6691455908876378, 'rouge_l': 0.22272012508010824},\n",
       "     {'bertscore': 0.6015252338838764, 'rouge_l': 0.13024475327389884},\n",
       "     {'bertscore': 0.6483679931261577, 'rouge_l': 0.1909993912107458},\n",
       "     {'bertscore': 0.6605145923967939, 'rouge_l': 0.2193594238656582},\n",
       "     {'bertscore': 0.661794777639443, 'rouge_l': 0.2033517931728982},\n",
       "     {'bertscore': 0.6482174948905595, 'rouge_l': 0.18692875908851034},\n",
       "     {'bertscore': 0.6652867156808497, 'rouge_l': 0.2106219742560641},\n",
       "     {'bertscore': 0.6307133732771035, 'rouge_l': 0.16533442240320181},\n",
       "     {'bertscore': 0.6560078280890593, 'rouge_l': 0.20235974518172953}]},\n",
       "   'total': {'test_bertscore': 65.02869394927984,\n",
       "    'test_bertscore_se': 1.2635531007374514,\n",
       "    'test_rouge_l': 19.36112183799545,\n",
       "    'test_rouge_l_se': 1.722297636999743}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.4728647320118968,\n",
       "      'accuracy': 0.59375},\n",
       "     {'mcc': 0.4775832453219492, 'accuracy': 0.5810546875},\n",
       "     {'mcc': 0.5221950784826344, 'accuracy': 0.625},\n",
       "     {'mcc': 0.4557105443648413, 'accuracy': 0.57421875},\n",
       "     {'mcc': 0.5288125861928081, 'accuracy': 0.6298828125},\n",
       "     {'mcc': 0.5273534933552464, 'accuracy': 0.634765625},\n",
       "     {'mcc': 0.5095376696319519, 'accuracy': 0.615234375},\n",
       "     {'mcc': 0.5174173850477336, 'accuracy': 0.6201171875},\n",
       "     {'mcc': 0.5464852757381814, 'accuracy': 0.6552734375},\n",
       "     {'mcc': 0.47309734301329204, 'accuracy': 0.5771484375}]},\n",
       "   'total': {'test_mcc': 50.31057353160534,\n",
       "    'test_mcc_se': 1.8996052999039441,\n",
       "    'test_accuracy': 61.06445312499999,\n",
       "    'test_accuracy_se': 1.7124769173680692}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.4440537914313171,\n",
       "      'accuracy': 0.609375},\n",
       "     {'mcc': 0.3525975114098117, 'accuracy': 0.55859375},\n",
       "     {'mcc': 0.3690262043079482, 'accuracy': 0.55859375},\n",
       "     {'mcc': 0.3626408683557293, 'accuracy': 0.564453125},\n",
       "     {'mcc': 0.32278983045138365, 'accuracy': 0.537109375},\n",
       "     {'mcc': 0.3180999254028049, 'accuracy': 0.5546875},\n",
       "     {'mcc': 0.3736619370035536, 'accuracy': 0.560546875},\n",
       "     {'mcc': 0.386282203774435, 'accuracy': 0.583984375},\n",
       "     {'mcc': 0.35574152313592017, 'accuracy': 0.544921875},\n",
       "     {'mcc': 0.3996058022698986, 'accuracy': 0.595703125}]},\n",
       "   'total': {'test_mcc': 36.84499597542802,\n",
       "    'test_mcc_se': 2.272495351283666,\n",
       "    'test_accuracy': 56.6796875,\n",
       "    'test_accuracy_se': 1.4057323507127084}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.27523398688625306,\n",
       "      'accuracy': 0.4541015625},\n",
       "     {'mcc': 0.24730692511521035, 'accuracy': 0.4267578125},\n",
       "     {'mcc': 0.23739351507910275, 'accuracy': 0.41748046875},\n",
       "     {'mcc': 0.24198564675605366, 'accuracy': 0.43017578125},\n",
       "     {'mcc': 0.2697815079648646, 'accuracy': 0.44970703125},\n",
       "     {'mcc': 0.24446446736087818, 'accuracy': 0.4267578125},\n",
       "     {'mcc': 0.2586016000912217, 'accuracy': 0.435546875},\n",
       "     {'mcc': 0.2740087530637766, 'accuracy': 0.4462890625},\n",
       "     {'mcc': 0.2760385716592192, 'accuracy': 0.4453125},\n",
       "     {'mcc': 0.261135742854816, 'accuracy': 0.43408203125}]},\n",
       "   'total': {'test_mcc': 25.859507168313968,\n",
       "    'test_mcc_se': 0.9245941857352619,\n",
       "    'test_accuracy': 43.662109375,\n",
       "    'test_accuracy_se': 0.7321688683379249}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results': {'raw': {'test': [{'test_speed': 1899.94,\n",
       "      'test_speed_short': 283.6},\n",
       "     {'test_speed': 3534.84, 'test_speed_short': 480.42},\n",
       "     {'test_speed': 5009.4, 'test_speed_short': 913.92},\n",
       "     {'test_speed': 5818.54, 'test_speed_short': 1066.8},\n",
       "     {'test_speed': 6415.92, 'test_speed_short': 1271.0},\n",
       "     {'test_speed': 7403.5199999999995, 'test_speed_short': 1601.16},\n",
       "     {'test_speed': 7587.0, 'test_speed_short': 1827.0600000000002},\n",
       "     {'test_speed': 8031.42, 'test_speed_short': 2017.2},\n",
       "     {'test_speed': 8815.62, 'test_speed_short': 2194.2},\n",
       "     {'test_speed': 8493.18, 'test_speed_short': 2377.48}]},\n",
       "   'total': {'test_speed': 6300.938,\n",
       "    'test_speed_se': 1400.1444233782067,\n",
       "    'test_speed_short': 1403.284,\n",
       "    'test_speed_short_se': 445.3130599323848}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.5495897567510795,\n",
       "      'macro_f1': 0.6898214913866506},\n",
       "     {'mcc': 0.5579236653447454, 'macro_f1': 0.6907709682979141},\n",
       "     {'mcc': 0.5899287715663997, 'macro_f1': 0.7292980351662576},\n",
       "     {'mcc': 0.5448407361820337, 'macro_f1': 0.6883722623230781},\n",
       "     {'mcc': 0.5721655391717717, 'macro_f1': 0.7099371453480767},\n",
       "     {'mcc': 0.5375389629372438, 'macro_f1': 0.6575139369379834},\n",
       "     {'mcc': 0.5331932954353217, 'macro_f1': 0.6653207459315597},\n",
       "     {'mcc': 0.5424096335807079, 'macro_f1': 0.6691065817207624},\n",
       "     {'mcc': 0.5366751880376028, 'macro_f1': 0.6608698754027474},\n",
       "     {'mcc': 0.5213254191589243, 'macro_f1': 0.668101566086261}]},\n",
       "   'total': {'test_mcc': 54.8559096816583,\n",
       "    'test_mcc_se': 1.2481172523958692,\n",
       "    'test_macro_f1': 68.29112608601291,\n",
       "    'test_macro_f1_se': 1.442025111841886}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'micro_f1_no_misc': 0.6026986506746627,\n",
       "      'micro_f1': 0.48550997365449755},\n",
       "     {'micro_f1_no_misc': 0.6120114394661582, 'micro_f1': 0.47075306479859896},\n",
       "     {'micro_f1_no_misc': 0.5401897154268598, 'micro_f1': 0.42259563818376833},\n",
       "     {'micro_f1_no_misc': 0.5492479378942261, 'micro_f1': 0.4353099730458221},\n",
       "     {'micro_f1_no_misc': 0.5885214007782101, 'micro_f1': 0.49247706422018345},\n",
       "     {'micro_f1_no_misc': 0.6207238472979674, 'micro_f1': 0.5060606060606061},\n",
       "     {'micro_f1_no_misc': 0.564673157162726, 'micro_f1': 0.4451158106747231},\n",
       "     {'micro_f1_no_misc': 0.5938220378054404, 'micro_f1': 0.4809946714031971},\n",
       "     {'micro_f1_no_misc': 0.5831600831600833, 'micro_f1': 0.4879189399844115},\n",
       "     {'micro_f1_no_misc': 0.5804901489668429,\n",
       "      'micro_f1': 0.47180243273129385}]},\n",
       "   'total': {'test_micro_f1_no_misc': 58.35538418633177,\n",
       "    'test_micro_f1_no_misc_se': 1.6151272650587505,\n",
       "    'test_micro_f1': 46.98538174757102,\n",
       "    'test_micro_f1_se': 1.6735427301813162}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.6754696030930898,\n",
       "      'macro_f1': 0.834687710105646},\n",
       "     {'mcc': 0.7202826614279519, 'macro_f1': 0.8598605748907485},\n",
       "     {'mcc': 0.7211605674419305, 'macro_f1': 0.8597330145447301},\n",
       "     {'mcc': 0.6984701911627172, 'macro_f1': 0.8471992653810836},\n",
       "     {'mcc': 0.7008152978949584, 'macro_f1': 0.8489395390072192},\n",
       "     {'mcc': 0.7185560595644939, 'macro_f1': 0.8562522293500203},\n",
       "     {'mcc': 0.6925592909687853, 'macro_f1': 0.8456912050128995},\n",
       "     {'mcc': 0.7138700445679367, 'macro_f1': 0.8568448193967941},\n",
       "     {'mcc': 0.7021227661826218, 'macro_f1': 0.8496560124706389},\n",
       "     {'mcc': 0.7278709130045625, 'macro_f1': 0.8631930527722111}]},\n",
       "   'total': {'test_mcc': 70.71177395309049,\n",
       "    'test_mcc_se': 0.9974075986195828,\n",
       "    'test_macro_f1': 85.22057422931992,\n",
       "    'test_macro_f1_se': 0.5329482481216669}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'em': 61.81254841208366,\n",
       "      'f1': 66.78666715847191},\n",
       "     {'em': 61.24031007751938, 'f1': 65.85615848406545},\n",
       "     {'em': 61.90108191653787, 'f1': 66.45923799710505},\n",
       "     {'em': 60.59190031152648, 'f1': 65.76168224299059},\n",
       "     {'em': 61.46718146718147, 'f1': 66.894588466017},\n",
       "     {'em': 60.215882806476486, 'f1': 64.69721334948778},\n",
       "     {'em': 60.89597570235384, 'f1': 66.04881604162263},\n",
       "     {'em': 61.21024049650892, 'f1': 65.77350474712767},\n",
       "     {'em': 61.411764705882355, 'f1': 65.85938375350138},\n",
       "     {'em': 60.40372670807454, 'f1': 65.4199201419698}]},\n",
       "   'total': {'test_em': 61.11506126041449,\n",
       "    'test_em_se': 0.35648894454895436,\n",
       "    'test_f1': 65.95571723823592,\n",
       "    'test_f1_se': 0.4024825582039535}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'bertscore': 0.6785116900573485,\n",
       "      'rouge_l': 0.23085897475472228},\n",
       "     {'bertscore': 0.681801812039339, 'rouge_l': 0.24149072304871455},\n",
       "     {'bertscore': 0.6470574361592298, 'rouge_l': 0.1968759837388298},\n",
       "     {'bertscore': 0.680841738867457, 'rouge_l': 0.23925302970691342},\n",
       "     {'bertscore': 0.6299839817656903, 'rouge_l': 0.19026651901332509},\n",
       "     {'bertscore': 0.6757893494650489, 'rouge_l': 0.2269502308380293},\n",
       "     {'bertscore': 0.6778886965767015, 'rouge_l': 0.23256843346881534},\n",
       "     {'bertscore': 0.6778021158170304, 'rouge_l': 0.22903617051069552},\n",
       "     {'bertscore': 0.6731881177984178, 'rouge_l': 0.22352827426101005},\n",
       "     {'bertscore': 0.6768264224665472, 'rouge_l': 0.23041412571300346}]},\n",
       "   'total': {'test_bertscore': 66.9969136101281,\n",
       "    'test_bertscore_se': 1.0676141595335182,\n",
       "    'test_rouge_l': 22.41242465054059,\n",
       "    'test_rouge_l_se': 1.0550837617100066}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.7950045394309614,\n",
       "      'accuracy': 0.84375},\n",
       "     {'mcc': 0.803244206258117, 'accuracy': 0.8505859375},\n",
       "     {'mcc': 0.8034956659576674, 'accuracy': 0.8515625},\n",
       "     {'mcc': 0.7705512956240499, 'accuracy': 0.826171875},\n",
       "     {'mcc': 0.803237884100883, 'accuracy': 0.8505859375},\n",
       "     {'mcc': 0.8101571491804823, 'accuracy': 0.8564453125},\n",
       "     {'mcc': 0.798017091442238, 'accuracy': 0.8466796875},\n",
       "     {'mcc': 0.808415502598942, 'accuracy': 0.85546875},\n",
       "     {'mcc': 0.8275422856904666, 'accuracy': 0.869140625},\n",
       "     {'mcc': 0.8504727798584701, 'accuracy': 0.88671875}]},\n",
       "   'total': {'test_mcc': 80.70138400142277,\n",
       "    'test_mcc_se': 1.2931163511837744,\n",
       "    'test_accuracy': 85.37109375,\n",
       "    'test_accuracy_se': 0.9842078851202178}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.7918001290725732,\n",
       "      'accuracy': 0.861328125},\n",
       "     {'mcc': 0.7735074475879812, 'accuracy': 0.849609375},\n",
       "     {'mcc': 0.81206213035295, 'accuracy': 0.875},\n",
       "     {'mcc': 0.759132749926082, 'accuracy': 0.83984375},\n",
       "     {'mcc': 0.7372107981979307, 'accuracy': 0.826171875},\n",
       "     {'mcc': 0.7597583452299161, 'accuracy': 0.841796875},\n",
       "     {'mcc': 0.7564410977053475, 'accuracy': 0.837890625},\n",
       "     {'mcc': 0.7331780823618024, 'accuracy': 0.822265625},\n",
       "     {'mcc': 0.7451339799143393, 'accuracy': 0.830078125},\n",
       "     {'mcc': 0.7844493728866097, 'accuracy': 0.857421875}]},\n",
       "   'total': {'test_mcc': 76.52674133235533,\n",
       "    'test_mcc_se': 1.559499688905093,\n",
       "    'test_accuracy': 84.4140625,\n",
       "    'test_accuracy_se': 1.0363469632376048}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'dataset_languages': ['da'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'mcc': 0.7163227528103518,\n",
       "      'accuracy': 0.78564453125},\n",
       "     {'mcc': 0.7358349356794699, 'accuracy': 0.7998046875},\n",
       "     {'mcc': 0.7365937470170191, 'accuracy': 0.80078125},\n",
       "     {'mcc': 0.7367232862615364, 'accuracy': 0.80126953125},\n",
       "     {'mcc': 0.7381605745674457, 'accuracy': 0.8017578125},\n",
       "     {'mcc': 0.7347561940060857, 'accuracy': 0.798828125},\n",
       "     {'mcc': 0.7255357735320027, 'accuracy': 0.7919921875},\n",
       "     {'mcc': 0.7377354208549104, 'accuracy': 0.80029296875},\n",
       "     {'mcc': 0.7688456345231482, 'accuracy': 0.82470703125},\n",
       "     {'mcc': 0.7428090450656385, 'accuracy': 0.8056640625}]},\n",
       "   'total': {'test_mcc': 73.73317364317609,\n",
       "    'test_mcc_se': 0.8300901261562226,\n",
       "    'test_accuracy': 80.107421875,\n",
       "    'test_accuracy_se': 0.6225527309432546}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'dataset_languages': ['ab',\n",
       "   'aa',\n",
       "   'af',\n",
       "   'sq',\n",
       "   'am',\n",
       "   'ar',\n",
       "   'an',\n",
       "   'hy',\n",
       "   'as',\n",
       "   'av',\n",
       "   'ae',\n",
       "   'ay',\n",
       "   'az',\n",
       "   'bm',\n",
       "   'ba',\n",
       "   'eu',\n",
       "   'be',\n",
       "   'bn',\n",
       "   'bi',\n",
       "   'bs',\n",
       "   'br',\n",
       "   'bg',\n",
       "   'my',\n",
       "   'ca',\n",
       "   'ch',\n",
       "   'ce',\n",
       "   'ny',\n",
       "   'zh',\n",
       "   'cu',\n",
       "   'cv',\n",
       "   'kw',\n",
       "   'co',\n",
       "   'cr',\n",
       "   'hr',\n",
       "   'cs',\n",
       "   'da',\n",
       "   'dv',\n",
       "   'nl',\n",
       "   'dz',\n",
       "   'en',\n",
       "   'eo',\n",
       "   'et',\n",
       "   'ee',\n",
       "   'fo',\n",
       "   'fj',\n",
       "   'fi',\n",
       "   'fr',\n",
       "   'fy',\n",
       "   'ff',\n",
       "   'gd',\n",
       "   'gl',\n",
       "   'lg',\n",
       "   'ka',\n",
       "   'de',\n",
       "   'el',\n",
       "   'kl',\n",
       "   'gn',\n",
       "   'gu',\n",
       "   'ht',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hz',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'is',\n",
       "   'io',\n",
       "   'ig',\n",
       "   'id',\n",
       "   'ia',\n",
       "   'ie',\n",
       "   'iu',\n",
       "   'ik',\n",
       "   'ga',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'kn',\n",
       "   'kr',\n",
       "   'ks',\n",
       "   'kk',\n",
       "   'km',\n",
       "   'ki',\n",
       "   'rw',\n",
       "   'ky',\n",
       "   'kv',\n",
       "   'kg',\n",
       "   'ko',\n",
       "   'kj',\n",
       "   'ku',\n",
       "   'lo',\n",
       "   'la',\n",
       "   'lv',\n",
       "   'li',\n",
       "   'ln',\n",
       "   'lt',\n",
       "   'lu',\n",
       "   'lb',\n",
       "   'mk',\n",
       "   'mg',\n",
       "   'ms',\n",
       "   'ml',\n",
       "   'mt',\n",
       "   'gv',\n",
       "   'mi',\n",
       "   'mr',\n",
       "   'mh',\n",
       "   'mn',\n",
       "   'na',\n",
       "   'nv',\n",
       "   'nd',\n",
       "   'nr',\n",
       "   'ng',\n",
       "   'ne',\n",
       "   'no',\n",
       "   'nb',\n",
       "   'nn',\n",
       "   'ii',\n",
       "   'oc',\n",
       "   'oj',\n",
       "   'or',\n",
       "   'om',\n",
       "   'os',\n",
       "   'pi',\n",
       "   'ps',\n",
       "   'fa',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pa',\n",
       "   'qu',\n",
       "   'ro',\n",
       "   'rm',\n",
       "   'rn',\n",
       "   'ru',\n",
       "   'se',\n",
       "   'sm',\n",
       "   'sg',\n",
       "   'sa',\n",
       "   'sc',\n",
       "   'sr',\n",
       "   'sn',\n",
       "   'sd',\n",
       "   'si',\n",
       "   'sk',\n",
       "   'sl',\n",
       "   'so',\n",
       "   'st',\n",
       "   'es',\n",
       "   'su',\n",
       "   'sw',\n",
       "   'ss',\n",
       "   'sv',\n",
       "   'tl',\n",
       "   'ty',\n",
       "   'tg',\n",
       "   'ta',\n",
       "   'tt',\n",
       "   'te',\n",
       "   'th',\n",
       "   'bo',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'ts',\n",
       "   'tn',\n",
       "   'tr',\n",
       "   'tk',\n",
       "   'tw',\n",
       "   'ug',\n",
       "   'uk',\n",
       "   'ur',\n",
       "   'uz',\n",
       "   've',\n",
       "   'vi',\n",
       "   'vo',\n",
       "   'wa',\n",
       "   'cy',\n",
       "   'wo',\n",
       "   'xh',\n",
       "   'yi',\n",
       "   'yo',\n",
       "   'za',\n",
       "   'zu'],\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results': {'raw': {'test': [{'test_speed': 1850.74,\n",
       "      'test_speed_short': 284.6},\n",
       "     {'test_speed': 3559.14, 'test_speed_short': 492.48},\n",
       "     {'test_speed': 5077.16, 'test_speed_short': 927.86},\n",
       "     {'test_speed': 5863.62, 'test_speed_short': 1073.94},\n",
       "     {'test_speed': 6391.8, 'test_speed_short': 1279.0},\n",
       "     {'test_speed': 7432.44, 'test_speed_short': 1616.34},\n",
       "     {'test_speed': 7497.08, 'test_speed_short': 1803.38},\n",
       "     {'test_speed': 7954.38, 'test_speed_short': 1993.4199999999998},\n",
       "     {'test_speed': 8700.1, 'test_speed_short': 2156.4},\n",
       "     {'test_speed': 8541.300000000001, 'test_speed_short': 2401.98}]},\n",
       "   'total': {'test_speed': 6286.776,\n",
       "    'test_speed_se': 1389.57367479149,\n",
       "    'test_speed_short': 1402.94,\n",
       "    'test_speed_short_se': 440.66188771456865}},\n",
       "  'num_model_parameters': 8030261248,\n",
       "  'max_sequence_length': 8192,\n",
       "  'vocabulary_size': 128256,\n",
       "  'generative': True,\n",
       "  'few_shot': True,\n",
       "  'validation_split': False,\n",
       "  'scandeval_version': '13.1.0'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filename = \"scandeval_benchmark_results\"\n",
    "# Input JSONL file path\n",
    "jsonl_file = f\"{filename}.jsonl\"\n",
    "\n",
    "# Read the JSONL file and store each line as a list of dictionaries\n",
    "data = []\n",
    "with open(jsonl_file, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_mcc': 42.768072269496784,\n",
       "   'test_mcc_se': 2.7649398203380207,\n",
       "   'test_macro_f1': 54.697607310450614,\n",
       "   'test_macro_f1_se': 4.187553369717499}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_micro_f1_no_misc': 41.12372184611197,\n",
       "   'test_micro_f1_no_misc_se': 3.390597785070832,\n",
       "   'test_micro_f1': 32.50136664808586,\n",
       "   'test_micro_f1_se': 2.738470519394666}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_mcc': 11.520993276625184,\n",
       "   'test_mcc_se': 3.0105576801811313,\n",
       "   'test_macro_f1': 49.37177878175003,\n",
       "   'test_macro_f1_se': 4.115212254632394}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_em': 51.14109895669001,\n",
       "   'test_em_se': 1.0313931861768566,\n",
       "   'test_f1': 60.17624485150695,\n",
       "   'test_f1_se': 0.5508132314011689}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_bertscore': 65.18536900839536,\n",
       "   'test_bertscore_se': 0.7788711917637351,\n",
       "   'test_rouge_l': 18.335692411425587,\n",
       "   'test_rouge_l_se': 1.2191007697717509}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_mcc': 49.77678992995646,\n",
       "   'test_mcc_se': 1.5195075543924272,\n",
       "   'test_accuracy': 62.28515624999999,\n",
       "   'test_accuracy_se': 1.1366086418130459}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_mcc': 45.880868045001115,\n",
       "   'test_mcc_se': 2.4250805604625025,\n",
       "   'test_accuracy': 63.96484375,\n",
       "   'test_accuracy_se': 1.5919866376749494}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_mcc': 21.88885428766109,\n",
       "   'test_mcc_se': 1.7677577467745245,\n",
       "   'test_accuracy': 41.162109375,\n",
       "   'test_accuracy_se': 1.4254447793144365}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'meta-llama/Llama-3.2-3B-Instruct',\n",
       "  'results_total': {'test_speed': 10423.756,\n",
       "   'test_speed_se': 2640.572186637397,\n",
       "   'test_speed_short': 2080.5299999999997,\n",
       "   'test_speed_short_se': 666.3625683611522}},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_mcc': 46.083053919929654,\n",
       "   'test_mcc_se': 1.0841423969450124,\n",
       "   'test_macro_f1': 55.126394656077714,\n",
       "   'test_macro_f1_se': 1.3689448899330048}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_micro_f1_no_misc': 55.74765892685012,\n",
       "   'test_micro_f1_no_misc_se': 1.7245134864535188,\n",
       "   'test_micro_f1': 36.061632605459835,\n",
       "   'test_micro_f1_se': 1.9145925733527132}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_mcc': 22.174111537674108,\n",
       "   'test_mcc_se': 2.9591314541471165,\n",
       "   'test_macro_f1': 48.34563396000508,\n",
       "   'test_macro_f1_se': 3.363444350545693}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_em': 57.750445255425156,\n",
       "   'test_em_se': 0.6788267145856897,\n",
       "   'test_f1': 63.327124170891125,\n",
       "   'test_f1_se': 0.5482319784284982}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_bertscore': 66.36226724949665,\n",
       "   'test_bertscore_se': 0.7866273486113065,\n",
       "   'test_rouge_l': 21.08184861801275,\n",
       "   'test_rouge_l_se': 0.9881932262855728}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_mcc': 59.81911516939233,\n",
       "   'test_mcc_se': 1.3379041285178823,\n",
       "   'test_accuracy': 69.072265625,\n",
       "   'test_accuracy_se': 1.0319580195888751}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_mcc': 54.085801534972575,\n",
       "   'test_mcc_se': 1.6547937495395109,\n",
       "   'test_accuracy': 69.19921875,\n",
       "   'test_accuracy_se': 1.055418374589436}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_mcc': 40.441368510018286,\n",
       "   'test_mcc_se': 1.6233789038835866,\n",
       "   'test_accuracy': 54.3798828125,\n",
       "   'test_accuracy_se': 1.330013307649838}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT',\n",
       "  'results_total': {'test_speed': 6589.447999999999,\n",
       "   'test_speed_se': 1396.959974435267,\n",
       "   'test_speed_short': 1506.294,\n",
       "   'test_speed_short_se': 472.81236162017854}},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_mcc': 52.02265111068719,\n",
       "   'test_mcc_se': 1.67301420422098,\n",
       "   'test_macro_f1': 66.27252045621765,\n",
       "   'test_macro_f1_se': 1.7675440422275706}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_micro_f1_no_misc': 51.365669052559745,\n",
       "   'test_micro_f1_no_misc_se': 3.829342393679035,\n",
       "   'test_micro_f1': 25.589276260648763,\n",
       "   'test_micro_f1_se': 2.1069781159123466}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_mcc': 18.499420814464482,\n",
       "   'test_mcc_se': 2.4620910957393303,\n",
       "   'test_macro_f1': 52.17865047649873,\n",
       "   'test_macro_f1_se': 4.278771174980301}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_em': 52.437601374239684,\n",
       "   'test_em_se': 1.1900664774077505,\n",
       "   'test_f1': 62.08470487947712,\n",
       "   'test_f1_se': 0.5983599306487652}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_bertscore': 66.17526001296937,\n",
       "   'test_bertscore_se': 0.8473285218049452,\n",
       "   'test_rouge_l': 21.101227619085254,\n",
       "   'test_rouge_l_se': 0.7021661106099834}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_mcc': 41.35251833088594,\n",
       "   'test_mcc_se': 1.1219023189164776,\n",
       "   'test_accuracy': 55.44921874999999,\n",
       "   'test_accuracy_se': 0.8691145926969096}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_mcc': 52.23849745841614,\n",
       "   'test_mcc_se': 1.5520772610806033,\n",
       "   'test_accuracy': 68.0078125,\n",
       "   'test_accuracy_se': 1.0519413837820024}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_mcc': 37.679765066669425,\n",
       "   'test_mcc_se': 0.8045990852383786,\n",
       "   'test_accuracy': 53.26171875,\n",
       "   'test_accuracy_se': 0.5976317680624773}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'CohereForAI/aya-expanse-8b',\n",
       "  'results_total': {'test_speed': 6341.598,\n",
       "   'test_speed_se': 1339.876715978997,\n",
       "   'test_speed_short': 1527.707,\n",
       "   'test_speed_short_se': 490.729158830796}},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_mcc': 56.393023019687206,\n",
       "   'test_mcc_se': 0.8522268784800228,\n",
       "   'test_macro_f1': 69.82914708990407,\n",
       "   'test_macro_f1_se': 1.0777654312545752}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_micro_f1_no_misc': 61.15011766965601,\n",
       "   'test_micro_f1_no_misc_se': 3.1462063606859267,\n",
       "   'test_micro_f1': 40.96198280231917,\n",
       "   'test_micro_f1_se': 2.1948855029981384}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_mcc': 37.75284984224283,\n",
       "   'test_mcc_se': 1.5885028292400456,\n",
       "   'test_macro_f1': 67.36104552509474,\n",
       "   'test_macro_f1_se': 1.4944382323737466}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_em': 58.09367597647266,\n",
       "   'test_em_se': 1.2560106089820373,\n",
       "   'test_f1': 65.86703716017392,\n",
       "   'test_f1_se': 0.6765437970353189}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_bertscore': 67.59507582421065,\n",
       "   'test_bertscore_se': 0.9770906139371104,\n",
       "   'test_rouge_l': 23.64851300973328,\n",
       "   'test_rouge_l_se': 0.8896245200666768}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_mcc': 66.12963947132397,\n",
       "   'test_mcc_se': 1.1894718417774748,\n",
       "   'test_accuracy': 74.3359375,\n",
       "   'test_accuracy_se': 0.8770408058276452}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_mcc': 73.66830392599584,\n",
       "   'test_mcc_se': 1.8061315888363954,\n",
       "   'test_accuracy': 82.51953125,\n",
       "   'test_accuracy_se': 1.1905543971939927}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_mcc': 69.22780174060347,\n",
       "   'test_mcc_se': 1.3279501525741395,\n",
       "   'test_accuracy': 76.77734375,\n",
       "   'test_accuracy_se': 1.0191571525239858}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'CohereForAI/aya-expanse-32b',\n",
       "  'results_total': {'test_speed': 2288.1139999999996,\n",
       "   'test_speed_se': 336.6308078017931,\n",
       "   'test_speed_short': 790.577,\n",
       "   'test_speed_short_se': 252.16400874360798}},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_mcc': 39.65201016987352,\n",
       "   'test_mcc_se': 0.610806532847957,\n",
       "   'test_macro_f1': 44.77785885690462,\n",
       "   'test_macro_f1_se': 0.294309068867731}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_micro_f1_no_misc': 28.930068223250576,\n",
       "   'test_micro_f1_no_misc_se': 3.4731839280874492,\n",
       "   'test_micro_f1': 25.702678874714863,\n",
       "   'test_micro_f1_se': 3.0383034076124344}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_mcc': 10.5607045573433,\n",
       "   'test_mcc_se': 1.571775547246954,\n",
       "   'test_macro_f1': 42.596721194756526,\n",
       "   'test_macro_f1_se': 2.6124327421270124}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_em': 53.253375079403284,\n",
       "   'test_em_se': 0.4870396139496962,\n",
       "   'test_f1': 61.048846056742285,\n",
       "   'test_f1_se': 0.4852475755344001}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_bertscore': 65.95262320595793,\n",
       "   'test_bertscore_se': 0.8537033683733533,\n",
       "   'test_rouge_l': 21.19438221924624,\n",
       "   'test_rouge_l_se': 0.8214294452915314}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_mcc': 54.6202015426465,\n",
       "   'test_mcc_se': 1.3958367240786267,\n",
       "   'test_accuracy': 65.78125,\n",
       "   'test_accuracy_se': 1.0449526945740508}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_mcc': 32.89271129434198,\n",
       "   'test_mcc_se': 2.208040137534972,\n",
       "   'test_accuracy': 55.39062500000001,\n",
       "   'test_accuracy_se': 1.424602085647271}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_mcc': 21.505081476426092,\n",
       "   'test_mcc_se': 1.676247565015713,\n",
       "   'test_accuracy': 39.7705078125,\n",
       "   'test_accuracy_se': 1.3426700875631101}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca',\n",
       "  'results_total': {'test_speed': 6486.856,\n",
       "   'test_speed_se': 1409.6901482265052,\n",
       "   'test_speed_short': 1508.1799999999998,\n",
       "   'test_speed_short_se': 472.9852795231468}},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_mcc': 42.800272577691814,\n",
       "   'test_mcc_se': 0.8819453985487221,\n",
       "   'test_macro_f1': 50.644454306390095,\n",
       "   'test_macro_f1_se': 1.4566067010584074}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_micro_f1_no_misc': 31.65458077573523,\n",
       "   'test_micro_f1_no_misc_se': 2.6264374186768866,\n",
       "   'test_micro_f1': 19.78511006347689,\n",
       "   'test_micro_f1_se': 1.8205611812410185}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_mcc': 9.223352937931939,\n",
       "   'test_mcc_se': 2.232477527396482,\n",
       "   'test_macro_f1': 40.95002813892957,\n",
       "   'test_macro_f1_se': 3.1540676490267705}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_em': 50.97068474965807,\n",
       "   'test_em_se': 0.5815221459593318,\n",
       "   'test_f1': 58.93624374192958,\n",
       "   'test_f1_se': 0.39393515101160603}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_bertscore': 65.02869394927984,\n",
       "   'test_bertscore_se': 1.2635531007374514,\n",
       "   'test_rouge_l': 19.36112183799545,\n",
       "   'test_rouge_l_se': 1.722297636999743}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_mcc': 50.31057353160534,\n",
       "   'test_mcc_se': 1.8996052999039441,\n",
       "   'test_accuracy': 61.06445312499999,\n",
       "   'test_accuracy_se': 1.7124769173680692}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_mcc': 36.84499597542802,\n",
       "   'test_mcc_se': 2.272495351283666,\n",
       "   'test_accuracy': 56.6796875,\n",
       "   'test_accuracy_se': 1.4057323507127084}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_mcc': 25.859507168313968,\n",
       "   'test_mcc_se': 0.9245941857352619,\n",
       "   'test_accuracy': 43.662109375,\n",
       "   'test_accuracy_se': 0.7321688683379249}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSlimOrca-4e',\n",
       "  'results_total': {'test_speed': 6300.938,\n",
       "   'test_speed_se': 1400.1444233782067,\n",
       "   'test_speed_short': 1403.284,\n",
       "   'test_speed_short_se': 445.3130599323848}},\n",
       " {'dataset': 'angry-tweets',\n",
       "  'task': 'sentiment-classification',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_mcc': 54.8559096816583,\n",
       "   'test_mcc_se': 1.2481172523958692,\n",
       "   'test_macro_f1': 68.29112608601291,\n",
       "   'test_macro_f1_se': 1.442025111841886}},\n",
       " {'dataset': 'dansk',\n",
       "  'task': 'named-entity-recognition',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_micro_f1_no_misc': 58.35538418633177,\n",
       "   'test_micro_f1_no_misc_se': 1.6151272650587505,\n",
       "   'test_micro_f1': 46.98538174757102,\n",
       "   'test_micro_f1_se': 1.6735427301813162}},\n",
       " {'dataset': 'scala-da',\n",
       "  'task': 'linguistic-acceptability',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_mcc': 70.71177395309049,\n",
       "   'test_mcc_se': 0.9974075986195828,\n",
       "   'test_macro_f1': 85.22057422931992,\n",
       "   'test_macro_f1_se': 0.5329482481216669}},\n",
       " {'dataset': 'scandiqa-da',\n",
       "  'task': 'reading-comprehension',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_em': 61.11506126041449,\n",
       "   'test_em_se': 0.35648894454895436,\n",
       "   'test_f1': 65.95571723823592,\n",
       "   'test_f1_se': 0.4024825582039535}},\n",
       " {'dataset': 'nordjylland-news',\n",
       "  'task': 'summarization',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_bertscore': 66.9969136101281,\n",
       "   'test_bertscore_se': 1.0676141595335182,\n",
       "   'test_rouge_l': 22.41242465054059,\n",
       "   'test_rouge_l_se': 1.0550837617100066}},\n",
       " {'dataset': 'danske-talemaader',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_mcc': 80.70138400142277,\n",
       "   'test_mcc_se': 1.2931163511837744,\n",
       "   'test_accuracy': 85.37109375,\n",
       "   'test_accuracy_se': 0.9842078851202178}},\n",
       " {'dataset': 'danish-citizen-tests',\n",
       "  'task': 'knowledge',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_mcc': 76.52674133235533,\n",
       "   'test_mcc_se': 1.559499688905093,\n",
       "   'test_accuracy': 84.4140625,\n",
       "   'test_accuracy_se': 1.0363469632376048}},\n",
       " {'dataset': 'hellaswag-da',\n",
       "  'task': 'common-sense-reasoning',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_mcc': 73.73317364317609,\n",
       "   'test_mcc_se': 0.8300901261562226,\n",
       "   'test_accuracy': 80.107421875,\n",
       "   'test_accuracy_se': 0.6225527309432546}},\n",
       " {'dataset': 'speed',\n",
       "  'task': 'speed',\n",
       "  'model': 'AI-Sweden-Models/Llama-3-8B-instruct',\n",
       "  'results_total': {'test_speed': 6286.776,\n",
       "   'test_speed_se': 1389.57367479149,\n",
       "   'test_speed_short': 1402.94,\n",
       "   'test_speed_short_se': 440.66188771456865}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected = []\n",
    "for dic in data:\n",
    "    if \"da\" not in dic[\"dataset_languages\"]:\n",
    "        continue\n",
    "    selected.append({\n",
    "        \"dataset\" : dic[\"dataset\"],\n",
    "        \"task\" : dic[\"task\"],\n",
    "        \"model\" : dic[\"model\"],\n",
    "        \"results_total\" : dic[\"results\"][\"total\"]\n",
    "    })\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>results_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>sentiment-classification</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_mcc': 42.768072269496784, 'test_mcc_se'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dansk</td>\n",
       "      <td>named-entity-recognition</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_micro_f1_no_misc': 41.12372184611197, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scala-da</td>\n",
       "      <td>linguistic-acceptability</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_mcc': 11.520993276625184, 'test_mcc_se'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>reading-comprehension</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_em': 51.14109895669001, 'test_em_se': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>summarization</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_bertscore': 65.18536900839536, 'test_be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>summarization</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_bertscore': 66.9969136101281, 'test_ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_mcc': 80.70138400142277, 'test_mcc_se':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_mcc': 76.52674133235533, 'test_mcc_se':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>common-sense-reasoning</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_mcc': 73.73317364317609, 'test_mcc_se':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>speed</td>\n",
       "      <td>speed</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_speed': 6286.776, 'test_speed_se': 1389...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset                      task  \\\n",
       "0           angry-tweets  sentiment-classification   \n",
       "1                  dansk  named-entity-recognition   \n",
       "2               scala-da  linguistic-acceptability   \n",
       "3            scandiqa-da     reading-comprehension   \n",
       "4       nordjylland-news             summarization   \n",
       "..                   ...                       ...   \n",
       "58      nordjylland-news             summarization   \n",
       "59     danske-talemaader                 knowledge   \n",
       "60  danish-citizen-tests                 knowledge   \n",
       "61          hellaswag-da    common-sense-reasoning   \n",
       "62                 speed                     speed   \n",
       "\n",
       "                                   model  \\\n",
       "0       meta-llama/Llama-3.2-3B-Instruct   \n",
       "1       meta-llama/Llama-3.2-3B-Instruct   \n",
       "2       meta-llama/Llama-3.2-3B-Instruct   \n",
       "3       meta-llama/Llama-3.2-3B-Instruct   \n",
       "4       meta-llama/Llama-3.2-3B-Instruct   \n",
       "..                                   ...   \n",
       "58  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "59  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "60  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "61  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "62  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "\n",
       "                                        results_total  \n",
       "0   {'test_mcc': 42.768072269496784, 'test_mcc_se'...  \n",
       "1   {'test_micro_f1_no_misc': 41.12372184611197, '...  \n",
       "2   {'test_mcc': 11.520993276625184, 'test_mcc_se'...  \n",
       "3   {'test_em': 51.14109895669001, 'test_em_se': 1...  \n",
       "4   {'test_bertscore': 65.18536900839536, 'test_be...  \n",
       "..                                                ...  \n",
       "58  {'test_bertscore': 66.9969136101281, 'test_ber...  \n",
       "59  {'test_mcc': 80.70138400142277, 'test_mcc_se':...  \n",
       "60  {'test_mcc': 76.52674133235533, 'test_mcc_se':...  \n",
       "61  {'test_mcc': 73.73317364317609, 'test_mcc_se':...  \n",
       "62  {'test_speed': 6286.776, 'test_speed_se': 1389...  \n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(selected)\n",
    "normalized_df = pd.json_normalize(df['results_total'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>results_total</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_mcc_se</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_se</th>\n",
       "      <th>test_micro_f1_no_misc</th>\n",
       "      <th>test_micro_f1_no_misc_se</th>\n",
       "      <th>...</th>\n",
       "      <th>test_bertscore</th>\n",
       "      <th>test_bertscore_se</th>\n",
       "      <th>test_rouge_l</th>\n",
       "      <th>test_rouge_l_se</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_se</th>\n",
       "      <th>test_speed</th>\n",
       "      <th>test_speed_se</th>\n",
       "      <th>test_speed_short</th>\n",
       "      <th>test_speed_short_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>sentiment-classification</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_mcc': 42.768072269496784, 'test_mcc_se'...</td>\n",
       "      <td>42.768072</td>\n",
       "      <td>2.764940</td>\n",
       "      <td>54.697607</td>\n",
       "      <td>4.187553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dansk</td>\n",
       "      <td>named-entity-recognition</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_micro_f1_no_misc': 41.12372184611197, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.123722</td>\n",
       "      <td>3.390598</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scala-da</td>\n",
       "      <td>linguistic-acceptability</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_mcc': 11.520993276625184, 'test_mcc_se'...</td>\n",
       "      <td>11.520993</td>\n",
       "      <td>3.010558</td>\n",
       "      <td>49.371779</td>\n",
       "      <td>4.115212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>reading-comprehension</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_em': 51.14109895669001, 'test_em_se': 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>summarization</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>{'test_bertscore': 65.18536900839536, 'test_be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.185369</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>18.335692</td>\n",
       "      <td>1.219101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>summarization</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_bertscore': 66.9969136101281, 'test_ber...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>66.996914</td>\n",
       "      <td>1.067614</td>\n",
       "      <td>22.412425</td>\n",
       "      <td>1.055084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_mcc': 80.70138400142277, 'test_mcc_se':...</td>\n",
       "      <td>80.701384</td>\n",
       "      <td>1.293116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.371094</td>\n",
       "      <td>0.984208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_mcc': 76.52674133235533, 'test_mcc_se':...</td>\n",
       "      <td>76.526741</td>\n",
       "      <td>1.559500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.414062</td>\n",
       "      <td>1.036347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>common-sense-reasoning</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_mcc': 73.73317364317609, 'test_mcc_se':...</td>\n",
       "      <td>73.733174</td>\n",
       "      <td>0.830090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.107422</td>\n",
       "      <td>0.622553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>speed</td>\n",
       "      <td>speed</td>\n",
       "      <td>AI-Sweden-Models/Llama-3-8B-instruct</td>\n",
       "      <td>{'test_speed': 6286.776, 'test_speed_se': 1389...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6286.776</td>\n",
       "      <td>1389.573675</td>\n",
       "      <td>1402.94</td>\n",
       "      <td>440.661888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset                      task  \\\n",
       "0           angry-tweets  sentiment-classification   \n",
       "1                  dansk  named-entity-recognition   \n",
       "2               scala-da  linguistic-acceptability   \n",
       "3            scandiqa-da     reading-comprehension   \n",
       "4       nordjylland-news             summarization   \n",
       "..                   ...                       ...   \n",
       "58      nordjylland-news             summarization   \n",
       "59     danske-talemaader                 knowledge   \n",
       "60  danish-citizen-tests                 knowledge   \n",
       "61          hellaswag-da    common-sense-reasoning   \n",
       "62                 speed                     speed   \n",
       "\n",
       "                                   model  \\\n",
       "0       meta-llama/Llama-3.2-3B-Instruct   \n",
       "1       meta-llama/Llama-3.2-3B-Instruct   \n",
       "2       meta-llama/Llama-3.2-3B-Instruct   \n",
       "3       meta-llama/Llama-3.2-3B-Instruct   \n",
       "4       meta-llama/Llama-3.2-3B-Instruct   \n",
       "..                                   ...   \n",
       "58  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "59  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "60  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "61  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "62  AI-Sweden-Models/Llama-3-8B-instruct   \n",
       "\n",
       "                                        results_total   test_mcc  test_mcc_se  \\\n",
       "0   {'test_mcc': 42.768072269496784, 'test_mcc_se'...  42.768072     2.764940   \n",
       "1   {'test_micro_f1_no_misc': 41.12372184611197, '...        NaN          NaN   \n",
       "2   {'test_mcc': 11.520993276625184, 'test_mcc_se'...  11.520993     3.010558   \n",
       "3   {'test_em': 51.14109895669001, 'test_em_se': 1...        NaN          NaN   \n",
       "4   {'test_bertscore': 65.18536900839536, 'test_be...        NaN          NaN   \n",
       "..                                                ...        ...          ...   \n",
       "58  {'test_bertscore': 66.9969136101281, 'test_ber...        NaN          NaN   \n",
       "59  {'test_mcc': 80.70138400142277, 'test_mcc_se':...  80.701384     1.293116   \n",
       "60  {'test_mcc': 76.52674133235533, 'test_mcc_se':...  76.526741     1.559500   \n",
       "61  {'test_mcc': 73.73317364317609, 'test_mcc_se':...  73.733174     0.830090   \n",
       "62  {'test_speed': 6286.776, 'test_speed_se': 1389...        NaN          NaN   \n",
       "\n",
       "    test_macro_f1  test_macro_f1_se  test_micro_f1_no_misc  \\\n",
       "0       54.697607          4.187553                    NaN   \n",
       "1             NaN               NaN              41.123722   \n",
       "2       49.371779          4.115212                    NaN   \n",
       "3             NaN               NaN                    NaN   \n",
       "4             NaN               NaN                    NaN   \n",
       "..            ...               ...                    ...   \n",
       "58            NaN               NaN                    NaN   \n",
       "59            NaN               NaN                    NaN   \n",
       "60            NaN               NaN                    NaN   \n",
       "61            NaN               NaN                    NaN   \n",
       "62            NaN               NaN                    NaN   \n",
       "\n",
       "    test_micro_f1_no_misc_se  ...  test_bertscore  test_bertscore_se  \\\n",
       "0                        NaN  ...             NaN                NaN   \n",
       "1                   3.390598  ...             NaN                NaN   \n",
       "2                        NaN  ...             NaN                NaN   \n",
       "3                        NaN  ...             NaN                NaN   \n",
       "4                        NaN  ...       65.185369           0.778871   \n",
       "..                       ...  ...             ...                ...   \n",
       "58                       NaN  ...       66.996914           1.067614   \n",
       "59                       NaN  ...             NaN                NaN   \n",
       "60                       NaN  ...             NaN                NaN   \n",
       "61                       NaN  ...             NaN                NaN   \n",
       "62                       NaN  ...             NaN                NaN   \n",
       "\n",
       "    test_rouge_l  test_rouge_l_se  test_accuracy  test_accuracy_se  \\\n",
       "0            NaN              NaN            NaN               NaN   \n",
       "1            NaN              NaN            NaN               NaN   \n",
       "2            NaN              NaN            NaN               NaN   \n",
       "3            NaN              NaN            NaN               NaN   \n",
       "4      18.335692         1.219101            NaN               NaN   \n",
       "..           ...              ...            ...               ...   \n",
       "58     22.412425         1.055084            NaN               NaN   \n",
       "59           NaN              NaN      85.371094          0.984208   \n",
       "60           NaN              NaN      84.414062          1.036347   \n",
       "61           NaN              NaN      80.107422          0.622553   \n",
       "62           NaN              NaN            NaN               NaN   \n",
       "\n",
       "    test_speed  test_speed_se  test_speed_short  test_speed_short_se  \n",
       "0          NaN            NaN               NaN                  NaN  \n",
       "1          NaN            NaN               NaN                  NaN  \n",
       "2          NaN            NaN               NaN                  NaN  \n",
       "3          NaN            NaN               NaN                  NaN  \n",
       "4          NaN            NaN               NaN                  NaN  \n",
       "..         ...            ...               ...                  ...  \n",
       "58         NaN            NaN               NaN                  NaN  \n",
       "59         NaN            NaN               NaN                  NaN  \n",
       "60         NaN            NaN               NaN                  NaN  \n",
       "61         NaN            NaN               NaN                  NaN  \n",
       "62    6286.776    1389.573675           1402.94           440.661888  \n",
       "\n",
       "[63 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, normalized_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_mcc_se</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_se</th>\n",
       "      <th>test_micro_f1_no_misc</th>\n",
       "      <th>test_micro_f1_no_misc_se</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_micro_f1_se</th>\n",
       "      <th>...</th>\n",
       "      <th>test_bertscore</th>\n",
       "      <th>test_bertscore_se</th>\n",
       "      <th>test_rouge_l</th>\n",
       "      <th>test_rouge_l_se</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_se</th>\n",
       "      <th>test_speed</th>\n",
       "      <th>test_speed_se</th>\n",
       "      <th>test_speed_short</th>\n",
       "      <th>test_speed_short_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>56.393023</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>69.829147</td>\n",
       "      <td>1.077765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>73.668304</td>\n",
       "      <td>1.806132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.519531</td>\n",
       "      <td>1.190554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.150118</td>\n",
       "      <td>3.146206</td>\n",
       "      <td>40.961983</td>\n",
       "      <td>2.194886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>66.129639</td>\n",
       "      <td>1.189472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.335938</td>\n",
       "      <td>0.877041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>69.227802</td>\n",
       "      <td>1.327950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.777344</td>\n",
       "      <td>1.019157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>67.595076</td>\n",
       "      <td>0.977091</td>\n",
       "      <td>23.648513</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>37.752850</td>\n",
       "      <td>1.588503</td>\n",
       "      <td>67.361046</td>\n",
       "      <td>1.494438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2288.114</td>\n",
       "      <td>336.630808</td>\n",
       "      <td>790.577</td>\n",
       "      <td>252.164009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>52.022651</td>\n",
       "      <td>1.673014</td>\n",
       "      <td>66.272520</td>\n",
       "      <td>1.767544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>52.238497</td>\n",
       "      <td>1.552077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.007812</td>\n",
       "      <td>1.051941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.365669</td>\n",
       "      <td>3.829342</td>\n",
       "      <td>25.589276</td>\n",
       "      <td>2.106978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>41.352518</td>\n",
       "      <td>1.121902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.449219</td>\n",
       "      <td>0.869115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>37.679765</td>\n",
       "      <td>0.804599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.261719</td>\n",
       "      <td>0.597632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>66.175260</td>\n",
       "      <td>0.847329</td>\n",
       "      <td>21.101228</td>\n",
       "      <td>0.702166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>18.499421</td>\n",
       "      <td>2.462091</td>\n",
       "      <td>52.178650</td>\n",
       "      <td>4.278771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6341.598</td>\n",
       "      <td>1339.876716</td>\n",
       "      <td>1527.707</td>\n",
       "      <td>490.729159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>46.083054</td>\n",
       "      <td>1.084142</td>\n",
       "      <td>55.126395</td>\n",
       "      <td>1.368945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>54.085802</td>\n",
       "      <td>1.654794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.199219</td>\n",
       "      <td>1.055418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.747659</td>\n",
       "      <td>1.724513</td>\n",
       "      <td>36.061633</td>\n",
       "      <td>1.914593</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>59.819115</td>\n",
       "      <td>1.337904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.072266</td>\n",
       "      <td>1.031958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>40.441369</td>\n",
       "      <td>1.623379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.379883</td>\n",
       "      <td>1.330013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>66.362267</td>\n",
       "      <td>0.786627</td>\n",
       "      <td>21.081849</td>\n",
       "      <td>0.988193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>22.174112</td>\n",
       "      <td>2.959131</td>\n",
       "      <td>48.345634</td>\n",
       "      <td>3.363444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6589.448</td>\n",
       "      <td>1396.959974</td>\n",
       "      <td>1506.294</td>\n",
       "      <td>472.812362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>39.652010</td>\n",
       "      <td>0.610807</td>\n",
       "      <td>44.777859</td>\n",
       "      <td>0.294309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>32.892711</td>\n",
       "      <td>2.208040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.390625</td>\n",
       "      <td>1.424602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.930068</td>\n",
       "      <td>3.473184</td>\n",
       "      <td>25.702679</td>\n",
       "      <td>3.038303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>54.620202</td>\n",
       "      <td>1.395837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.781250</td>\n",
       "      <td>1.044953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>21.505081</td>\n",
       "      <td>1.676248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.770508</td>\n",
       "      <td>1.342670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.952623</td>\n",
       "      <td>0.853703</td>\n",
       "      <td>21.194382</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>10.560705</td>\n",
       "      <td>1.571776</td>\n",
       "      <td>42.596721</td>\n",
       "      <td>2.612433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6486.856</td>\n",
       "      <td>1409.690148</td>\n",
       "      <td>1508.180</td>\n",
       "      <td>472.985280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>42.800273</td>\n",
       "      <td>0.881945</td>\n",
       "      <td>50.644454</td>\n",
       "      <td>1.456607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>36.844996</td>\n",
       "      <td>2.272495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.679688</td>\n",
       "      <td>1.405732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.654581</td>\n",
       "      <td>2.626437</td>\n",
       "      <td>19.785110</td>\n",
       "      <td>1.820561</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>50.310574</td>\n",
       "      <td>1.899605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.064453</td>\n",
       "      <td>1.712477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>25.859507</td>\n",
       "      <td>0.924594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.662109</td>\n",
       "      <td>0.732169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.028694</td>\n",
       "      <td>1.263553</td>\n",
       "      <td>19.361122</td>\n",
       "      <td>1.722298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>9.223353</td>\n",
       "      <td>2.232478</td>\n",
       "      <td>40.950028</td>\n",
       "      <td>3.154068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6300.938</td>\n",
       "      <td>1400.144423</td>\n",
       "      <td>1403.284</td>\n",
       "      <td>445.313060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>angry-tweets</td>\n",
       "      <td>42.768072</td>\n",
       "      <td>2.764940</td>\n",
       "      <td>54.697607</td>\n",
       "      <td>4.187553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>45.880868</td>\n",
       "      <td>2.425081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.964844</td>\n",
       "      <td>1.591987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.123722</td>\n",
       "      <td>3.390598</td>\n",
       "      <td>32.501367</td>\n",
       "      <td>2.738471</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>danske-talemaader</td>\n",
       "      <td>49.776790</td>\n",
       "      <td>1.519508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.285156</td>\n",
       "      <td>1.136609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>hellaswag-da</td>\n",
       "      <td>21.888854</td>\n",
       "      <td>1.767758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.162109</td>\n",
       "      <td>1.425445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.185369</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>18.335692</td>\n",
       "      <td>1.219101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>11.520993</td>\n",
       "      <td>3.010558</td>\n",
       "      <td>49.371779</td>\n",
       "      <td>4.115212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>scandiqa-da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10423.756</td>\n",
       "      <td>2640.572187</td>\n",
       "      <td>2080.530</td>\n",
       "      <td>666.362568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model               dataset  \\\n",
       "0                         CohereForAI/aya-expanse-32b          angry-tweets   \n",
       "1                         CohereForAI/aya-expanse-32b  danish-citizen-tests   \n",
       "2                         CohereForAI/aya-expanse-32b                 dansk   \n",
       "3                         CohereForAI/aya-expanse-32b     danske-talemaader   \n",
       "4                         CohereForAI/aya-expanse-32b          hellaswag-da   \n",
       "5                         CohereForAI/aya-expanse-32b      nordjylland-news   \n",
       "6                         CohereForAI/aya-expanse-32b              scala-da   \n",
       "7                         CohereForAI/aya-expanse-32b           scandiqa-da   \n",
       "8                         CohereForAI/aya-expanse-32b                 speed   \n",
       "9                          CohereForAI/aya-expanse-8b          angry-tweets   \n",
       "10                         CohereForAI/aya-expanse-8b  danish-citizen-tests   \n",
       "11                         CohereForAI/aya-expanse-8b                 dansk   \n",
       "12                         CohereForAI/aya-expanse-8b     danske-talemaader   \n",
       "13                         CohereForAI/aya-expanse-8b          hellaswag-da   \n",
       "14                         CohereForAI/aya-expanse-8b      nordjylland-news   \n",
       "15                         CohereForAI/aya-expanse-8b              scala-da   \n",
       "16                         CohereForAI/aya-expanse-8b           scandiqa-da   \n",
       "17                         CohereForAI/aya-expanse-8b                 speed   \n",
       "18  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT          angry-tweets   \n",
       "19  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT  danish-citizen-tests   \n",
       "20  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT                 dansk   \n",
       "21  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT     danske-talemaader   \n",
       "22  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT          hellaswag-da   \n",
       "23  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT      nordjylland-news   \n",
       "24  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT              scala-da   \n",
       "25  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT           scandiqa-da   \n",
       "26  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT                 speed   \n",
       "27  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...          angry-tweets   \n",
       "28  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  danish-citizen-tests   \n",
       "29  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...                 dansk   \n",
       "30  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...     danske-talemaader   \n",
       "31  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...          hellaswag-da   \n",
       "32  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...      nordjylland-news   \n",
       "33  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...              scala-da   \n",
       "34  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...           scandiqa-da   \n",
       "35  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...                 speed   \n",
       "36  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...          angry-tweets   \n",
       "37  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  danish-citizen-tests   \n",
       "38  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...                 dansk   \n",
       "39  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...     danske-talemaader   \n",
       "40  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...          hellaswag-da   \n",
       "41  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...      nordjylland-news   \n",
       "42  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...              scala-da   \n",
       "43  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...           scandiqa-da   \n",
       "44  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...                 speed   \n",
       "45                   meta-llama/Llama-3.2-3B-Instruct          angry-tweets   \n",
       "46                   meta-llama/Llama-3.2-3B-Instruct  danish-citizen-tests   \n",
       "47                   meta-llama/Llama-3.2-3B-Instruct                 dansk   \n",
       "48                   meta-llama/Llama-3.2-3B-Instruct     danske-talemaader   \n",
       "49                   meta-llama/Llama-3.2-3B-Instruct          hellaswag-da   \n",
       "50                   meta-llama/Llama-3.2-3B-Instruct      nordjylland-news   \n",
       "51                   meta-llama/Llama-3.2-3B-Instruct              scala-da   \n",
       "52                   meta-llama/Llama-3.2-3B-Instruct           scandiqa-da   \n",
       "53                   meta-llama/Llama-3.2-3B-Instruct                 speed   \n",
       "\n",
       "     test_mcc  test_mcc_se  test_macro_f1  test_macro_f1_se  \\\n",
       "0   56.393023     0.852227      69.829147          1.077765   \n",
       "1   73.668304     1.806132            NaN               NaN   \n",
       "2         NaN          NaN            NaN               NaN   \n",
       "3   66.129639     1.189472            NaN               NaN   \n",
       "4   69.227802     1.327950            NaN               NaN   \n",
       "5         NaN          NaN            NaN               NaN   \n",
       "6   37.752850     1.588503      67.361046          1.494438   \n",
       "7         NaN          NaN            NaN               NaN   \n",
       "8         NaN          NaN            NaN               NaN   \n",
       "9   52.022651     1.673014      66.272520          1.767544   \n",
       "10  52.238497     1.552077            NaN               NaN   \n",
       "11        NaN          NaN            NaN               NaN   \n",
       "12  41.352518     1.121902            NaN               NaN   \n",
       "13  37.679765     0.804599            NaN               NaN   \n",
       "14        NaN          NaN            NaN               NaN   \n",
       "15  18.499421     2.462091      52.178650          4.278771   \n",
       "16        NaN          NaN            NaN               NaN   \n",
       "17        NaN          NaN            NaN               NaN   \n",
       "18  46.083054     1.084142      55.126395          1.368945   \n",
       "19  54.085802     1.654794            NaN               NaN   \n",
       "20        NaN          NaN            NaN               NaN   \n",
       "21  59.819115     1.337904            NaN               NaN   \n",
       "22  40.441369     1.623379            NaN               NaN   \n",
       "23        NaN          NaN            NaN               NaN   \n",
       "24  22.174112     2.959131      48.345634          3.363444   \n",
       "25        NaN          NaN            NaN               NaN   \n",
       "26        NaN          NaN            NaN               NaN   \n",
       "27  39.652010     0.610807      44.777859          0.294309   \n",
       "28  32.892711     2.208040            NaN               NaN   \n",
       "29        NaN          NaN            NaN               NaN   \n",
       "30  54.620202     1.395837            NaN               NaN   \n",
       "31  21.505081     1.676248            NaN               NaN   \n",
       "32        NaN          NaN            NaN               NaN   \n",
       "33  10.560705     1.571776      42.596721          2.612433   \n",
       "34        NaN          NaN            NaN               NaN   \n",
       "35        NaN          NaN            NaN               NaN   \n",
       "36  42.800273     0.881945      50.644454          1.456607   \n",
       "37  36.844996     2.272495            NaN               NaN   \n",
       "38        NaN          NaN            NaN               NaN   \n",
       "39  50.310574     1.899605            NaN               NaN   \n",
       "40  25.859507     0.924594            NaN               NaN   \n",
       "41        NaN          NaN            NaN               NaN   \n",
       "42   9.223353     2.232478      40.950028          3.154068   \n",
       "43        NaN          NaN            NaN               NaN   \n",
       "44        NaN          NaN            NaN               NaN   \n",
       "45  42.768072     2.764940      54.697607          4.187553   \n",
       "46  45.880868     2.425081            NaN               NaN   \n",
       "47        NaN          NaN            NaN               NaN   \n",
       "48  49.776790     1.519508            NaN               NaN   \n",
       "49  21.888854     1.767758            NaN               NaN   \n",
       "50        NaN          NaN            NaN               NaN   \n",
       "51  11.520993     3.010558      49.371779          4.115212   \n",
       "52        NaN          NaN            NaN               NaN   \n",
       "53        NaN          NaN            NaN               NaN   \n",
       "\n",
       "    test_micro_f1_no_misc  test_micro_f1_no_misc_se  test_micro_f1  \\\n",
       "0                     NaN                       NaN            NaN   \n",
       "1                     NaN                       NaN            NaN   \n",
       "2               61.150118                  3.146206      40.961983   \n",
       "3                     NaN                       NaN            NaN   \n",
       "4                     NaN                       NaN            NaN   \n",
       "5                     NaN                       NaN            NaN   \n",
       "6                     NaN                       NaN            NaN   \n",
       "7                     NaN                       NaN            NaN   \n",
       "8                     NaN                       NaN            NaN   \n",
       "9                     NaN                       NaN            NaN   \n",
       "10                    NaN                       NaN            NaN   \n",
       "11              51.365669                  3.829342      25.589276   \n",
       "12                    NaN                       NaN            NaN   \n",
       "13                    NaN                       NaN            NaN   \n",
       "14                    NaN                       NaN            NaN   \n",
       "15                    NaN                       NaN            NaN   \n",
       "16                    NaN                       NaN            NaN   \n",
       "17                    NaN                       NaN            NaN   \n",
       "18                    NaN                       NaN            NaN   \n",
       "19                    NaN                       NaN            NaN   \n",
       "20              55.747659                  1.724513      36.061633   \n",
       "21                    NaN                       NaN            NaN   \n",
       "22                    NaN                       NaN            NaN   \n",
       "23                    NaN                       NaN            NaN   \n",
       "24                    NaN                       NaN            NaN   \n",
       "25                    NaN                       NaN            NaN   \n",
       "26                    NaN                       NaN            NaN   \n",
       "27                    NaN                       NaN            NaN   \n",
       "28                    NaN                       NaN            NaN   \n",
       "29              28.930068                  3.473184      25.702679   \n",
       "30                    NaN                       NaN            NaN   \n",
       "31                    NaN                       NaN            NaN   \n",
       "32                    NaN                       NaN            NaN   \n",
       "33                    NaN                       NaN            NaN   \n",
       "34                    NaN                       NaN            NaN   \n",
       "35                    NaN                       NaN            NaN   \n",
       "36                    NaN                       NaN            NaN   \n",
       "37                    NaN                       NaN            NaN   \n",
       "38              31.654581                  2.626437      19.785110   \n",
       "39                    NaN                       NaN            NaN   \n",
       "40                    NaN                       NaN            NaN   \n",
       "41                    NaN                       NaN            NaN   \n",
       "42                    NaN                       NaN            NaN   \n",
       "43                    NaN                       NaN            NaN   \n",
       "44                    NaN                       NaN            NaN   \n",
       "45                    NaN                       NaN            NaN   \n",
       "46                    NaN                       NaN            NaN   \n",
       "47              41.123722                  3.390598      32.501367   \n",
       "48                    NaN                       NaN            NaN   \n",
       "49                    NaN                       NaN            NaN   \n",
       "50                    NaN                       NaN            NaN   \n",
       "51                    NaN                       NaN            NaN   \n",
       "52                    NaN                       NaN            NaN   \n",
       "53                    NaN                       NaN            NaN   \n",
       "\n",
       "    test_micro_f1_se  ...  test_bertscore  test_bertscore_se  test_rouge_l  \\\n",
       "0                NaN  ...             NaN                NaN           NaN   \n",
       "1                NaN  ...             NaN                NaN           NaN   \n",
       "2           2.194886  ...             NaN                NaN           NaN   \n",
       "3                NaN  ...             NaN                NaN           NaN   \n",
       "4                NaN  ...             NaN                NaN           NaN   \n",
       "5                NaN  ...       67.595076           0.977091     23.648513   \n",
       "6                NaN  ...             NaN                NaN           NaN   \n",
       "7                NaN  ...             NaN                NaN           NaN   \n",
       "8                NaN  ...             NaN                NaN           NaN   \n",
       "9                NaN  ...             NaN                NaN           NaN   \n",
       "10               NaN  ...             NaN                NaN           NaN   \n",
       "11          2.106978  ...             NaN                NaN           NaN   \n",
       "12               NaN  ...             NaN                NaN           NaN   \n",
       "13               NaN  ...             NaN                NaN           NaN   \n",
       "14               NaN  ...       66.175260           0.847329     21.101228   \n",
       "15               NaN  ...             NaN                NaN           NaN   \n",
       "16               NaN  ...             NaN                NaN           NaN   \n",
       "17               NaN  ...             NaN                NaN           NaN   \n",
       "18               NaN  ...             NaN                NaN           NaN   \n",
       "19               NaN  ...             NaN                NaN           NaN   \n",
       "20          1.914593  ...             NaN                NaN           NaN   \n",
       "21               NaN  ...             NaN                NaN           NaN   \n",
       "22               NaN  ...             NaN                NaN           NaN   \n",
       "23               NaN  ...       66.362267           0.786627     21.081849   \n",
       "24               NaN  ...             NaN                NaN           NaN   \n",
       "25               NaN  ...             NaN                NaN           NaN   \n",
       "26               NaN  ...             NaN                NaN           NaN   \n",
       "27               NaN  ...             NaN                NaN           NaN   \n",
       "28               NaN  ...             NaN                NaN           NaN   \n",
       "29          3.038303  ...             NaN                NaN           NaN   \n",
       "30               NaN  ...             NaN                NaN           NaN   \n",
       "31               NaN  ...             NaN                NaN           NaN   \n",
       "32               NaN  ...       65.952623           0.853703     21.194382   \n",
       "33               NaN  ...             NaN                NaN           NaN   \n",
       "34               NaN  ...             NaN                NaN           NaN   \n",
       "35               NaN  ...             NaN                NaN           NaN   \n",
       "36               NaN  ...             NaN                NaN           NaN   \n",
       "37               NaN  ...             NaN                NaN           NaN   \n",
       "38          1.820561  ...             NaN                NaN           NaN   \n",
       "39               NaN  ...             NaN                NaN           NaN   \n",
       "40               NaN  ...             NaN                NaN           NaN   \n",
       "41               NaN  ...       65.028694           1.263553     19.361122   \n",
       "42               NaN  ...             NaN                NaN           NaN   \n",
       "43               NaN  ...             NaN                NaN           NaN   \n",
       "44               NaN  ...             NaN                NaN           NaN   \n",
       "45               NaN  ...             NaN                NaN           NaN   \n",
       "46               NaN  ...             NaN                NaN           NaN   \n",
       "47          2.738471  ...             NaN                NaN           NaN   \n",
       "48               NaN  ...             NaN                NaN           NaN   \n",
       "49               NaN  ...             NaN                NaN           NaN   \n",
       "50               NaN  ...       65.185369           0.778871     18.335692   \n",
       "51               NaN  ...             NaN                NaN           NaN   \n",
       "52               NaN  ...             NaN                NaN           NaN   \n",
       "53               NaN  ...             NaN                NaN           NaN   \n",
       "\n",
       "    test_rouge_l_se  test_accuracy  test_accuracy_se  test_speed  \\\n",
       "0               NaN            NaN               NaN         NaN   \n",
       "1               NaN      82.519531          1.190554         NaN   \n",
       "2               NaN            NaN               NaN         NaN   \n",
       "3               NaN      74.335938          0.877041         NaN   \n",
       "4               NaN      76.777344          1.019157         NaN   \n",
       "5          0.889625            NaN               NaN         NaN   \n",
       "6               NaN            NaN               NaN         NaN   \n",
       "7               NaN            NaN               NaN         NaN   \n",
       "8               NaN            NaN               NaN    2288.114   \n",
       "9               NaN            NaN               NaN         NaN   \n",
       "10              NaN      68.007812          1.051941         NaN   \n",
       "11              NaN            NaN               NaN         NaN   \n",
       "12              NaN      55.449219          0.869115         NaN   \n",
       "13              NaN      53.261719          0.597632         NaN   \n",
       "14         0.702166            NaN               NaN         NaN   \n",
       "15              NaN            NaN               NaN         NaN   \n",
       "16              NaN            NaN               NaN         NaN   \n",
       "17              NaN            NaN               NaN    6341.598   \n",
       "18              NaN            NaN               NaN         NaN   \n",
       "19              NaN      69.199219          1.055418         NaN   \n",
       "20              NaN            NaN               NaN         NaN   \n",
       "21              NaN      69.072266          1.031958         NaN   \n",
       "22              NaN      54.379883          1.330013         NaN   \n",
       "23         0.988193            NaN               NaN         NaN   \n",
       "24              NaN            NaN               NaN         NaN   \n",
       "25              NaN            NaN               NaN         NaN   \n",
       "26              NaN            NaN               NaN    6589.448   \n",
       "27              NaN            NaN               NaN         NaN   \n",
       "28              NaN      55.390625          1.424602         NaN   \n",
       "29              NaN            NaN               NaN         NaN   \n",
       "30              NaN      65.781250          1.044953         NaN   \n",
       "31              NaN      39.770508          1.342670         NaN   \n",
       "32         0.821429            NaN               NaN         NaN   \n",
       "33              NaN            NaN               NaN         NaN   \n",
       "34              NaN            NaN               NaN         NaN   \n",
       "35              NaN            NaN               NaN    6486.856   \n",
       "36              NaN            NaN               NaN         NaN   \n",
       "37              NaN      56.679688          1.405732         NaN   \n",
       "38              NaN            NaN               NaN         NaN   \n",
       "39              NaN      61.064453          1.712477         NaN   \n",
       "40              NaN      43.662109          0.732169         NaN   \n",
       "41         1.722298            NaN               NaN         NaN   \n",
       "42              NaN            NaN               NaN         NaN   \n",
       "43              NaN            NaN               NaN         NaN   \n",
       "44              NaN            NaN               NaN    6300.938   \n",
       "45              NaN            NaN               NaN         NaN   \n",
       "46              NaN      63.964844          1.591987         NaN   \n",
       "47              NaN            NaN               NaN         NaN   \n",
       "48              NaN      62.285156          1.136609         NaN   \n",
       "49              NaN      41.162109          1.425445         NaN   \n",
       "50         1.219101            NaN               NaN         NaN   \n",
       "51              NaN            NaN               NaN         NaN   \n",
       "52              NaN            NaN               NaN         NaN   \n",
       "53              NaN            NaN               NaN   10423.756   \n",
       "\n",
       "    test_speed_se  test_speed_short  test_speed_short_se  \n",
       "0             NaN               NaN                  NaN  \n",
       "1             NaN               NaN                  NaN  \n",
       "2             NaN               NaN                  NaN  \n",
       "3             NaN               NaN                  NaN  \n",
       "4             NaN               NaN                  NaN  \n",
       "5             NaN               NaN                  NaN  \n",
       "6             NaN               NaN                  NaN  \n",
       "7             NaN               NaN                  NaN  \n",
       "8      336.630808           790.577           252.164009  \n",
       "9             NaN               NaN                  NaN  \n",
       "10            NaN               NaN                  NaN  \n",
       "11            NaN               NaN                  NaN  \n",
       "12            NaN               NaN                  NaN  \n",
       "13            NaN               NaN                  NaN  \n",
       "14            NaN               NaN                  NaN  \n",
       "15            NaN               NaN                  NaN  \n",
       "16            NaN               NaN                  NaN  \n",
       "17    1339.876716          1527.707           490.729159  \n",
       "18            NaN               NaN                  NaN  \n",
       "19            NaN               NaN                  NaN  \n",
       "20            NaN               NaN                  NaN  \n",
       "21            NaN               NaN                  NaN  \n",
       "22            NaN               NaN                  NaN  \n",
       "23            NaN               NaN                  NaN  \n",
       "24            NaN               NaN                  NaN  \n",
       "25            NaN               NaN                  NaN  \n",
       "26    1396.959974          1506.294           472.812362  \n",
       "27            NaN               NaN                  NaN  \n",
       "28            NaN               NaN                  NaN  \n",
       "29            NaN               NaN                  NaN  \n",
       "30            NaN               NaN                  NaN  \n",
       "31            NaN               NaN                  NaN  \n",
       "32            NaN               NaN                  NaN  \n",
       "33            NaN               NaN                  NaN  \n",
       "34            NaN               NaN                  NaN  \n",
       "35    1409.690148          1508.180           472.985280  \n",
       "36            NaN               NaN                  NaN  \n",
       "37            NaN               NaN                  NaN  \n",
       "38            NaN               NaN                  NaN  \n",
       "39            NaN               NaN                  NaN  \n",
       "40            NaN               NaN                  NaN  \n",
       "41            NaN               NaN                  NaN  \n",
       "42            NaN               NaN                  NaN  \n",
       "43            NaN               NaN                  NaN  \n",
       "44    1400.144423          1403.284           445.313060  \n",
       "45            NaN               NaN                  NaN  \n",
       "46            NaN               NaN                  NaN  \n",
       "47            NaN               NaN                  NaN  \n",
       "48            NaN               NaN                  NaN  \n",
       "49            NaN               NaN                  NaN  \n",
       "50            NaN               NaN                  NaN  \n",
       "51            NaN               NaN                  NaN  \n",
       "52            NaN               NaN                  NaN  \n",
       "53    2640.572187          2080.530           666.362568  \n",
       "\n",
       "[54 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = df.groupby(['model', 'dataset']).mean(numeric_only=True).reset_index()\n",
    "#mean_df = mean_df.drop(columns=['task', 'results_total'], errors='ignore')\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_mcc_se</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_se</th>\n",
       "      <th>test_micro_f1_no_misc</th>\n",
       "      <th>test_micro_f1_no_misc_se</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_micro_f1_se</th>\n",
       "      <th>...</th>\n",
       "      <th>test_bertscore</th>\n",
       "      <th>test_bertscore_se</th>\n",
       "      <th>test_rouge_l</th>\n",
       "      <th>test_rouge_l_se</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_se</th>\n",
       "      <th>test_speed</th>\n",
       "      <th>test_speed_se</th>\n",
       "      <th>test_speed_short</th>\n",
       "      <th>test_speed_short_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>73.668304</td>\n",
       "      <td>1.806132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.519531</td>\n",
       "      <td>1.190554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>52.238497</td>\n",
       "      <td>1.552077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.007812</td>\n",
       "      <td>1.051941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>54.085802</td>\n",
       "      <td>1.654794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.199219</td>\n",
       "      <td>1.055418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>32.892711</td>\n",
       "      <td>2.208040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.390625</td>\n",
       "      <td>1.424602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>36.844996</td>\n",
       "      <td>2.272495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.679688</td>\n",
       "      <td>1.405732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>danish-citizen-tests</td>\n",
       "      <td>45.880868</td>\n",
       "      <td>2.425081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.964844</td>\n",
       "      <td>1.591987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model               dataset  \\\n",
       "1                         CohereForAI/aya-expanse-32b  danish-citizen-tests   \n",
       "10                         CohereForAI/aya-expanse-8b  danish-citizen-tests   \n",
       "19  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT  danish-citizen-tests   \n",
       "28  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  danish-citizen-tests   \n",
       "37  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  danish-citizen-tests   \n",
       "46                   meta-llama/Llama-3.2-3B-Instruct  danish-citizen-tests   \n",
       "\n",
       "     test_mcc  test_mcc_se  test_macro_f1  test_macro_f1_se  \\\n",
       "1   73.668304     1.806132            NaN               NaN   \n",
       "10  52.238497     1.552077            NaN               NaN   \n",
       "19  54.085802     1.654794            NaN               NaN   \n",
       "28  32.892711     2.208040            NaN               NaN   \n",
       "37  36.844996     2.272495            NaN               NaN   \n",
       "46  45.880868     2.425081            NaN               NaN   \n",
       "\n",
       "    test_micro_f1_no_misc  test_micro_f1_no_misc_se  test_micro_f1  \\\n",
       "1                     NaN                       NaN            NaN   \n",
       "10                    NaN                       NaN            NaN   \n",
       "19                    NaN                       NaN            NaN   \n",
       "28                    NaN                       NaN            NaN   \n",
       "37                    NaN                       NaN            NaN   \n",
       "46                    NaN                       NaN            NaN   \n",
       "\n",
       "    test_micro_f1_se  ...  test_bertscore  test_bertscore_se  test_rouge_l  \\\n",
       "1                NaN  ...             NaN                NaN           NaN   \n",
       "10               NaN  ...             NaN                NaN           NaN   \n",
       "19               NaN  ...             NaN                NaN           NaN   \n",
       "28               NaN  ...             NaN                NaN           NaN   \n",
       "37               NaN  ...             NaN                NaN           NaN   \n",
       "46               NaN  ...             NaN                NaN           NaN   \n",
       "\n",
       "    test_rouge_l_se  test_accuracy  test_accuracy_se  test_speed  \\\n",
       "1               NaN      82.519531          1.190554         NaN   \n",
       "10              NaN      68.007812          1.051941         NaN   \n",
       "19              NaN      69.199219          1.055418         NaN   \n",
       "28              NaN      55.390625          1.424602         NaN   \n",
       "37              NaN      56.679688          1.405732         NaN   \n",
       "46              NaN      63.964844          1.591987         NaN   \n",
       "\n",
       "    test_speed_se  test_speed_short  test_speed_short_se  \n",
       "1             NaN               NaN                  NaN  \n",
       "10            NaN               NaN                  NaN  \n",
       "19            NaN               NaN                  NaN  \n",
       "28            NaN               NaN                  NaN  \n",
       "37            NaN               NaN                  NaN  \n",
       "46            NaN               NaN                  NaN  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df[df[\"dataset\"] == \"dansk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_mcc_se</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_se</th>\n",
       "      <th>test_micro_f1_no_misc</th>\n",
       "      <th>test_micro_f1_no_misc_se</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_micro_f1_se</th>\n",
       "      <th>...</th>\n",
       "      <th>test_bertscore</th>\n",
       "      <th>test_bertscore_se</th>\n",
       "      <th>test_rouge_l</th>\n",
       "      <th>test_rouge_l_se</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_se</th>\n",
       "      <th>test_speed</th>\n",
       "      <th>test_speed_se</th>\n",
       "      <th>test_speed_short</th>\n",
       "      <th>test_speed_short_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>67.595076</td>\n",
       "      <td>0.977091</td>\n",
       "      <td>23.648513</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>66.175260</td>\n",
       "      <td>0.847329</td>\n",
       "      <td>21.101228</td>\n",
       "      <td>0.702166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>66.362267</td>\n",
       "      <td>0.786627</td>\n",
       "      <td>21.081849</td>\n",
       "      <td>0.988193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.952623</td>\n",
       "      <td>0.853703</td>\n",
       "      <td>21.194382</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.028694</td>\n",
       "      <td>1.263553</td>\n",
       "      <td>19.361122</td>\n",
       "      <td>1.722298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>nordjylland-news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.185369</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>18.335692</td>\n",
       "      <td>1.219101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model           dataset  \\\n",
       "5                         CohereForAI/aya-expanse-32b  nordjylland-news   \n",
       "14                         CohereForAI/aya-expanse-8b  nordjylland-news   \n",
       "23  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT  nordjylland-news   \n",
       "32  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  nordjylland-news   \n",
       "41  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  nordjylland-news   \n",
       "50                   meta-llama/Llama-3.2-3B-Instruct  nordjylland-news   \n",
       "\n",
       "    test_mcc  test_mcc_se  test_macro_f1  test_macro_f1_se  \\\n",
       "5        NaN          NaN            NaN               NaN   \n",
       "14       NaN          NaN            NaN               NaN   \n",
       "23       NaN          NaN            NaN               NaN   \n",
       "32       NaN          NaN            NaN               NaN   \n",
       "41       NaN          NaN            NaN               NaN   \n",
       "50       NaN          NaN            NaN               NaN   \n",
       "\n",
       "    test_micro_f1_no_misc  test_micro_f1_no_misc_se  test_micro_f1  \\\n",
       "5                     NaN                       NaN            NaN   \n",
       "14                    NaN                       NaN            NaN   \n",
       "23                    NaN                       NaN            NaN   \n",
       "32                    NaN                       NaN            NaN   \n",
       "41                    NaN                       NaN            NaN   \n",
       "50                    NaN                       NaN            NaN   \n",
       "\n",
       "    test_micro_f1_se  ...  test_bertscore  test_bertscore_se  test_rouge_l  \\\n",
       "5                NaN  ...       67.595076           0.977091     23.648513   \n",
       "14               NaN  ...       66.175260           0.847329     21.101228   \n",
       "23               NaN  ...       66.362267           0.786627     21.081849   \n",
       "32               NaN  ...       65.952623           0.853703     21.194382   \n",
       "41               NaN  ...       65.028694           1.263553     19.361122   \n",
       "50               NaN  ...       65.185369           0.778871     18.335692   \n",
       "\n",
       "    test_rouge_l_se  test_accuracy  test_accuracy_se  test_speed  \\\n",
       "5          0.889625            NaN               NaN         NaN   \n",
       "14         0.702166            NaN               NaN         NaN   \n",
       "23         0.988193            NaN               NaN         NaN   \n",
       "32         0.821429            NaN               NaN         NaN   \n",
       "41         1.722298            NaN               NaN         NaN   \n",
       "50         1.219101            NaN               NaN         NaN   \n",
       "\n",
       "    test_speed_se  test_speed_short  test_speed_short_se  \n",
       "5             NaN               NaN                  NaN  \n",
       "14            NaN               NaN                  NaN  \n",
       "23            NaN               NaN                  NaN  \n",
       "32            NaN               NaN                  NaN  \n",
       "41            NaN               NaN                  NaN  \n",
       "50            NaN               NaN                  NaN  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df[mean_df[\"dataset\"] == \"nordjylland-news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_mcc_se</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_se</th>\n",
       "      <th>test_micro_f1_no_misc</th>\n",
       "      <th>test_micro_f1_no_misc_se</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_micro_f1_se</th>\n",
       "      <th>...</th>\n",
       "      <th>test_bertscore</th>\n",
       "      <th>test_bertscore_se</th>\n",
       "      <th>test_rouge_l</th>\n",
       "      <th>test_rouge_l_se</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_se</th>\n",
       "      <th>test_speed</th>\n",
       "      <th>test_speed_se</th>\n",
       "      <th>test_speed_short</th>\n",
       "      <th>test_speed_short_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.150118</td>\n",
       "      <td>3.146206</td>\n",
       "      <td>40.961983</td>\n",
       "      <td>2.194886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.365669</td>\n",
       "      <td>3.829342</td>\n",
       "      <td>25.589276</td>\n",
       "      <td>2.106978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.747659</td>\n",
       "      <td>1.724513</td>\n",
       "      <td>36.061633</td>\n",
       "      <td>1.914593</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.930068</td>\n",
       "      <td>3.473184</td>\n",
       "      <td>25.702679</td>\n",
       "      <td>3.038303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.654581</td>\n",
       "      <td>2.626437</td>\n",
       "      <td>19.785110</td>\n",
       "      <td>1.820561</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>dansk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.123722</td>\n",
       "      <td>3.390598</td>\n",
       "      <td>32.501367</td>\n",
       "      <td>2.738471</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model dataset  test_mcc  \\\n",
       "2                         CohereForAI/aya-expanse-32b   dansk       NaN   \n",
       "11                         CohereForAI/aya-expanse-8b   dansk       NaN   \n",
       "20  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT   dansk       NaN   \n",
       "29  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...   dansk       NaN   \n",
       "38  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...   dansk       NaN   \n",
       "47                   meta-llama/Llama-3.2-3B-Instruct   dansk       NaN   \n",
       "\n",
       "    test_mcc_se  test_macro_f1  test_macro_f1_se  test_micro_f1_no_misc  \\\n",
       "2           NaN            NaN               NaN              61.150118   \n",
       "11          NaN            NaN               NaN              51.365669   \n",
       "20          NaN            NaN               NaN              55.747659   \n",
       "29          NaN            NaN               NaN              28.930068   \n",
       "38          NaN            NaN               NaN              31.654581   \n",
       "47          NaN            NaN               NaN              41.123722   \n",
       "\n",
       "    test_micro_f1_no_misc_se  test_micro_f1  test_micro_f1_se  ...  \\\n",
       "2                   3.146206      40.961983          2.194886  ...   \n",
       "11                  3.829342      25.589276          2.106978  ...   \n",
       "20                  1.724513      36.061633          1.914593  ...   \n",
       "29                  3.473184      25.702679          3.038303  ...   \n",
       "38                  2.626437      19.785110          1.820561  ...   \n",
       "47                  3.390598      32.501367          2.738471  ...   \n",
       "\n",
       "    test_bertscore  test_bertscore_se  test_rouge_l  test_rouge_l_se  \\\n",
       "2              NaN                NaN           NaN              NaN   \n",
       "11             NaN                NaN           NaN              NaN   \n",
       "20             NaN                NaN           NaN              NaN   \n",
       "29             NaN                NaN           NaN              NaN   \n",
       "38             NaN                NaN           NaN              NaN   \n",
       "47             NaN                NaN           NaN              NaN   \n",
       "\n",
       "    test_accuracy  test_accuracy_se  test_speed  test_speed_se  \\\n",
       "2             NaN               NaN         NaN            NaN   \n",
       "11            NaN               NaN         NaN            NaN   \n",
       "20            NaN               NaN         NaN            NaN   \n",
       "29            NaN               NaN         NaN            NaN   \n",
       "38            NaN               NaN         NaN            NaN   \n",
       "47            NaN               NaN         NaN            NaN   \n",
       "\n",
       "    test_speed_short  test_speed_short_se  \n",
       "2                NaN                  NaN  \n",
       "11               NaN                  NaN  \n",
       "20               NaN                  NaN  \n",
       "29               NaN                  NaN  \n",
       "38               NaN                  NaN  \n",
       "47               NaN                  NaN  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df[mean_df[\"dataset\"] == \"dansk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_mcc_se</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_se</th>\n",
       "      <th>test_micro_f1_no_misc</th>\n",
       "      <th>test_micro_f1_no_misc_se</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_micro_f1_se</th>\n",
       "      <th>...</th>\n",
       "      <th>test_bertscore</th>\n",
       "      <th>test_bertscore_se</th>\n",
       "      <th>test_rouge_l</th>\n",
       "      <th>test_rouge_l_se</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_se</th>\n",
       "      <th>test_speed</th>\n",
       "      <th>test_speed_se</th>\n",
       "      <th>test_speed_short</th>\n",
       "      <th>test_speed_short_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CohereForAI/aya-expanse-32b</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>37.752850</td>\n",
       "      <td>1.588503</td>\n",
       "      <td>67.361046</td>\n",
       "      <td>1.494438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>18.499421</td>\n",
       "      <td>2.462091</td>\n",
       "      <td>52.178650</td>\n",
       "      <td>4.278771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>22.174112</td>\n",
       "      <td>2.959131</td>\n",
       "      <td>48.345634</td>\n",
       "      <td>3.363444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>10.560705</td>\n",
       "      <td>1.571776</td>\n",
       "      <td>42.596721</td>\n",
       "      <td>2.612433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>9.223353</td>\n",
       "      <td>2.232478</td>\n",
       "      <td>40.950028</td>\n",
       "      <td>3.154068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>scala-da</td>\n",
       "      <td>11.520993</td>\n",
       "      <td>3.010558</td>\n",
       "      <td>49.371779</td>\n",
       "      <td>4.115212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model   dataset   test_mcc  \\\n",
       "6                         CohereForAI/aya-expanse-32b  scala-da  37.752850   \n",
       "15                         CohereForAI/aya-expanse-8b  scala-da  18.499421   \n",
       "24  ThatsGroes/Llama-3-8B-instruct-AI-Sweden-SkoleGPT  scala-da  22.174112   \n",
       "33  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  scala-da  10.560705   \n",
       "42  ThatsGroes/Llama-3.1-8B-Instruct-SkoleGPT-DaSl...  scala-da   9.223353   \n",
       "51                   meta-llama/Llama-3.2-3B-Instruct  scala-da  11.520993   \n",
       "\n",
       "    test_mcc_se  test_macro_f1  test_macro_f1_se  test_micro_f1_no_misc  \\\n",
       "6      1.588503      67.361046          1.494438                    NaN   \n",
       "15     2.462091      52.178650          4.278771                    NaN   \n",
       "24     2.959131      48.345634          3.363444                    NaN   \n",
       "33     1.571776      42.596721          2.612433                    NaN   \n",
       "42     2.232478      40.950028          3.154068                    NaN   \n",
       "51     3.010558      49.371779          4.115212                    NaN   \n",
       "\n",
       "    test_micro_f1_no_misc_se  test_micro_f1  test_micro_f1_se  ...  \\\n",
       "6                        NaN            NaN               NaN  ...   \n",
       "15                       NaN            NaN               NaN  ...   \n",
       "24                       NaN            NaN               NaN  ...   \n",
       "33                       NaN            NaN               NaN  ...   \n",
       "42                       NaN            NaN               NaN  ...   \n",
       "51                       NaN            NaN               NaN  ...   \n",
       "\n",
       "    test_bertscore  test_bertscore_se  test_rouge_l  test_rouge_l_se  \\\n",
       "6              NaN                NaN           NaN              NaN   \n",
       "15             NaN                NaN           NaN              NaN   \n",
       "24             NaN                NaN           NaN              NaN   \n",
       "33             NaN                NaN           NaN              NaN   \n",
       "42             NaN                NaN           NaN              NaN   \n",
       "51             NaN                NaN           NaN              NaN   \n",
       "\n",
       "    test_accuracy  test_accuracy_se  test_speed  test_speed_se  \\\n",
       "6             NaN               NaN         NaN            NaN   \n",
       "15            NaN               NaN         NaN            NaN   \n",
       "24            NaN               NaN         NaN            NaN   \n",
       "33            NaN               NaN         NaN            NaN   \n",
       "42            NaN               NaN         NaN            NaN   \n",
       "51            NaN               NaN         NaN            NaN   \n",
       "\n",
       "    test_speed_short  test_speed_short_se  \n",
       "6                NaN                  NaN  \n",
       "15               NaN                  NaN  \n",
       "24               NaN                  NaN  \n",
       "33               NaN                  NaN  \n",
       "42               NaN                  NaN  \n",
       "51               NaN                  NaN  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df[mean_df[\"dataset\"] == \"scala-da\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
